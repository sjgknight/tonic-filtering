## Ethical action <a id="introduction"></a>

How we interact with each other has ethical dimensions in both interactions that are direct  (e.g. in face-to-face communication), and indirect(e.g., through the ways our decisions impact people at a distance to us in how we use technology, shop, or conduct particular research projects). *Ethical conduct* involves a responsiveness to these ethical dimensions in acting to respect others. It thus goes beyond rule following; ethical principles and other ethical concepts are intended to provide tools to support shared consideration of human values in fostering respect for persons.

**Ethical issues can be rendered invisible, static, or simple** (in the sense of unambiguous, straightforward, or uninvolved) in many contexts. This may occur because ethical reflection is not embedded in proefessional practice and learning contexts, sometimes only considered in stand-alone courses or events, or/and abstracted from the practical contexts we may face in working and living in society.

However, *ethical issues are complex*. That complexity arises due to plurality in the values and principles held within and across contexts, norms regarding practices to navigate ethical issues, and the inherent complexity of navigating tensions in values. Ethical action involves ongoing consideration of these issues.

### Ethics vocabulary

Reflection on ethical issues has a long history across societies, reflected in scholarly and cultural materials from religious teachings, scholarly and fiction writings, and plays, slam poetry, paintings, etc. All of these works can form part of our ethical vocabulary, providing shared language, metaphors, or reference points in discussing issues.

> Consider creative works such as movies that reflect ethical issues in educational settings and the use of AI in society

"There has, however, been increased attention to ethical reflection about human research since the Second World War. The judgment of the Nuremberg military tribunal included ten principles about permissible medical experiments, since referred to as the Nuremberg Code. Discussion of these principles led the World Medical Assembly in 1964 to adopt what came to be known as the Helsinki Declaration, revised several times since then. The various international human rights instruments that have also emerged since the Second World War emphasise the importance of protecting human beings in many spheres of community life. During this period, written ethical guidelines have also been generated in many areas of research practice as an expression of professional responsibility."

“The challenge of creating a culture of responsible innovation begins with the task of building an accessible moral vocabulary that will allow team members to explore and discuss the ethical stakes of the AI projects that they are involved in or are considering taking on. In the field of AI ethics, this moral vocabulary draws primarily on two traditions of moral thinking: (1) bioethics and (2) human rights discourse. Bioethics is the study of the ethical impacts of biomedicine and the applied life sciences. Human rights discourse draws inspiration from the UN Declaration of Human Rights. It is anchored in a set of universal principles that build upon the idea that all humans have an equal moral status as bearers of intrinsic human dignity.” (Leslie, 2019, p. 8)

“Whereas bioethics largely stresses the normative values that underlie the safeguarding of individuals in instances where technological practices affect their interests and wellbeing, human rights discourse mainly focuses on the set of social, political, and legal entitlements that are due to all human beings under a universal framework of juridical protection and the rule of law. The main principles of bioethics include respecting the autonomy of the individual, protecting people from harm, looking after the well-being of others, and treating all individuals equitably and justly. The main tenets of human rights include the entitlement to equal freedom and dignity under the law, the protection of civil, political, and social rights, the universal recognition of personhood, and the right to free and unencumbered participation in the life of the community.” (Leslie, 2019, p. 9)

## Research and ethics

"Human research is research conducted with or about people, or their data or tissue. It has contributed enormously to human good. Much human research carries little risk and [...] the vast majority of human research has been carried out in a safe and ethically responsible manner. But human research can involve significant risks and it is possible for things to go wrong. Sometimes risks are realised despite the best of intentions and care in planning and practice. Sometimes they are realised because of technical error or ethical insensitivity, neglect or disregard. On rare occasions the practice of research has even involved the deliberate and appalling violation of human beings – notoriously, the Second World War experiments in detention and concentration camps." (NS)

"This range of possibilities can give rise to important and sometimes difficult ethical questions about research participation. Two considerations give further weight to those questions. First, research participants may enter into a relationship with researchers whom they may not know but need to trust. This trust adds to the ethical responsibility borne by those in whom it is placed. Secondly, many who contribute as participants in human research do so altruistically, for the common good, without thought of recompense for their time and effort. This underscores the importance of protecting research patients." (NS)

“It is sometimes argued that since unethical research is not widespread, the present form of regulation constitutes an over-reaction to rare scandalous behaviour in the conduct of research. While it is true that over-regulation may be an obstacle to the pursuit of (ethically and scientifically) good research, it should be pointed out that ethical decision-making is complex, and because of this complexity individual researchers may not be best placed to decide about the ethical issues a project raises. Instead it may need a group of experts, both scientific and ethical, to make a good decision. Likewise, given the plurality of ethical views that are available, a committee decision can be representative in ways that an individual decision about the ethical legitimacy of a course of action cannot.” ([European Commission. Directorate-General for Research, 2010, p. 11](zotero://select/groups/4907410/items/JYVSIUCE)) ([pdf](zotero://open-pdf/groups/4907410/items/JJP2HGB3?page=13&annotation=2KXKEKIN))

*Guidelines* are intended to provide support to those involved with research in navigating the ethical dimensions of that research, including:

* researchers (and where relevant their supervisors)
* Research Ethics Committees (RECs) and others conducting ethical review of research
* institutions that set up the processes of ethical review, and whose employees, resources and facilities are involved in research
* funding organisations
* agencies that set standards
* governments.

"Research often involves public interaction between people that serves a public good. There is, therefore, a public responsibility for seeing that these interactions are ethically acceptable [...]."

"Multiple judgments are possible, and ambiguity and uncertainty are part of the process. We advocate guidelines rather than a code of practice so that ethical research can remain flexible, be responsive to diverse contexts, and be adaptable to continually changing technologies. When one considers that ethical assessments are always operationalized via some sort of practice (method), and also contextualized institutionally and/or geographically, it becomes clearer that an adaptive, inductive approach can yield potentially more ethically legitimate outcomes than a simple adherence to a set of instantiated rules. The emphasis on a process approach highlights the researcher’s responsibility for making such judgments and decisions within specific contexts and, more narrowly, within a specific research project.” (Markham and Buchanan, 2012, p. 5)

### What is research?

There is no generally agreed definition of research, however, it is widely understood to include at least investigation undertaken to gain knowledge and understanding or to train researchers. The British Research Assessment Exercise (RAE) definition of research is somewhat wider:

*Research* includes work of direct relevance to the needs of commerce, industry, and to the public and voluntary sectors; scholarship; the invention and generation of ideas, images, performances, artefacts including design, where these lead to new or substantially improved insights; and the use of existing knowledge in experimental development to produce new or substantially improved materials, devices, products and processes, including design and construction. It excludes routine testing and routine analysis of materials, components and processes such as for the maintenance of national standards, as distinct from the development of new analytical techniques. It also excludes the development of teaching materials that do not embody original research.

To enable comparative assessment of academic activity, this definition sought to include the widest range of creative and experimental activities. Many items in the definition are uncontentious, but there may be disagreement about some – for example, "the invention and generation of new ... images, performances, artefacts...where these lead to new or substantially improved insights" – since this could count poetry, painting and performing arts as research.

Here we are particularly interested in the further questions:

* What is human research?
* What is the scope of \'quality assurance\' activities and their level of ethics oversight particularly with respect to use of AI and in educational contexts
* When is research involving \'AI\' human research?


### What is human research?

Human research is conducted with or about people, or their data or tissue. Human participation in research is therefore to be understood broadly, to include the involvement of human beings through:

* taking part in surveys, interviews or focus groups
* undergoing psychological, physiological or medical testing or treatment
* being observed by researchers
* researchers having access to their personal documents or other materials
* the collection and use of their body organs, tissues or fluids (for example, skin, blood, urine, saliva, hair, bones, tumour and other biopsy specimens) or their exhaled breath
* access to their information (in individually identifiable, re-identifiable or non-identifiable form) as part of an existing published or unpublished source or database. (You may find this resource from [Future of Priacy Forum useful on the distinction between identifiable, re-identifiable, and anonymous data (pdf)](https://fpf.org/wp-content/uploads/2016/04/FPF_Visual-Guide-to-Practical-Data-DeID.pdf) )

The term _participants_ is, therefore, used very broadly in this National Statement to include those who may not even know they are the subjects of research, for example, where the need for their consent for the use of their tissue or data has been waived by a Human Research Ethics Committee (HREC).

In addition, the conduct of human research often has an impact on the lives of others who are not participants. When this impact is reasonably foreseeable, it may raise ethical questions for researchers and for those ethically reviewing research.

### Emerging technologies and research

“The scope and contexts of internet research have been dramatically expanded through the continuing global diffusion of the internet into nearly every country in the world, as facilitated through a growing array of devices (including game consoles, internet-enabled phones and other mobile devices) and ever-increasing bandwidth; rapidly expanding suites of new communication applications; and the increasingly seamless interweaving of online and offline activities and experiences. Alongside these developments, the literature of internet research ethics has grown considerably, providing us with a far more extensive range of theoretical resources and practical examples to help recognize and guide ethical reflection.” (Markham and Buchanan, 2012, p. 2)

“The internet is a social phenomenon, a tool, and also a (field) site for research. Depending on the role the internet plays in the research project or how it is conceptualized by the researcher, different epistemological, logistical and ethical considerations will come into play. The term “Internet” originally described a network of computers that made possible the decentralized transmission of information. Now, the term serves as an umbrella for innumerable technologies, devices, capacities, uses, and social spaces. Within these technologies, many ethical and methodological issues arise and as such, internet research calls for new models of ethical evaluation and consideration. Because the types of interaction and information transmission made possible by the internet vary so widely, researchers find it necessary to define the concept more narrowly within individual studies. This is complicated by the fact that studies of and on the internet cut across all academic disciplines. This document uses the following working definitions: Internet research encompasses inquiry that: (a) utilizes the internet to collect data or information, e.g., through online interviews, surveys, archiving, or automated means of data scraping; (b) studies how people use and access the internet, e.g., through collecting and observing activities or participating on social network sites, listservs, web sites, blogs, games, virtual worlds, or other online environments or contexts; (c) utilizes or engages in data processing, analysis, or storage of datasets, databanks, and/or repositories available via the. (d) studies software, code, and internet technologies (e) examines the design or structures of systems, interfaces, pages, and elements (f) employs visual and textual analysis, semiotic analysis, content analysis, or other methods of analysis to study the web and/or internet-facilitated images, writings, and media forms. (g) studies large scale production, use, and regulation of the internet by governments, industries, corporations, and military forces. Internet research is not machine specific or dependent, and we recognize the impact of smart devices and increased mobility on internet activities. It is important to note that definitions of and experiences with these contexts vary widely. Technological convergence collapses many contexts and categories in evolving and sometimes surprising ways. The internet mediates everyday life in industrialized and developing cultures, whether or not we are actively accessing the web. Thus, internet research should be considered in its broadest sense.” (Markham and Buchanan, 2012, p. 3-4)

"This prospect that progress in AI will help humanity to confront some of its most urgent challenges is exciting, but legitimate worries still abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will inevitably occur. AI is no exception. In order to manage these impacts responsibly and to direct the development of AI systems toward optimal public benefit, you will have to make considerations of AI ethics and safety a first priority. This will involve integrating considerations of the social and ethical implications of the design and use of AI systems into every stage of the delivery of your AI project. It will also involve a collaborative effort between the data scientists, product managers, data engineers, domain experts, and delivery managers on your team to align the development of artificial intelligence technologies with ethical values and principles that safeguard and promote the wellbeing of the communities that these technologies affect. By including a primer on AI ethics with the Guide, we are providing you with the conceptual resources and practical tools that will enable you to steward the responsible design and implementation of AI projects. AI ethics is a set of values, principles, and techniques that employ widely accepted standards of right and wrong to guide moral conduct in the development and use of AI technologies.” ([Leslie, 2019, p. 3](zotero://select/groups/4907410/items/6QAK3ZN5)) ([pdf](zotero://open-pdf/groups/4907410/items/FFHN69EG?page=4&annotation=HU6DJMXI))

“• You will have to ensure that your AI project is ethically permissible by considering the impacts it may have on the wellbeing of affected stakeholders and communities. • You will have to ensure that your AI project is fair and non-discriminatory by accounting for its potential to have discriminatory effects on individuals and social groups, by mitigating biases that may influence your model’s outputs, and by being aware of the issues surrounding fairness that come into play at every phase of the design and implementation pipeline. • You will have to ensure that your AI project is worthy of public trust by guaranteeing to the extent possible the safety, accuracy, reliability, security, and robustness of its product. • You will have to ensure that your AI project is justifiable by prioritising both the transparency of the process by which your model is designed and implemented, and the transparency and interpretability of its decisions and behaviours. We call this governance architecture an ethical platform for two important reasons. First, it is intended to provide you with a solid, processed-based footing of values, principles, and protocolsan ethical platform to stand on—so that you and your team are better able to design and implement AI systems ethically, equitably, and safely. Secondly, it is intended to help you facilitate a culture of responsible AI innovation—to help you provide an ethical platform to stand for—so that your project team can be united in a collaborative spirit to develop AI technologies for the public good.” ([Leslie, 2019, p. 6](zotero://select/groups/4907410/items/6QAK3ZN5)) ([pdf](zotero://open-pdf/groups/4907410/items/FFHN69EG?page=7&annotation=KSF6QPE2))


### education and research

“What is Artificial Intelligence? Throughout Europe, learners and educators increasingly use Artificial Intelligence (AI) systems, sometimes without realising it. Search engines, smart assistants, chatbots, language translation, navigation apps, online videogames and many other applications use Artificial Intelligence in our everyday lives. AI systems rely on data, which is collected in different modalities (e.g. sound, images, text, posts, clicks) and all together form our digital traces. AI has great potential to enhance education and training for learners, educators and school leaders. AI systems are currently helping some educators to identify specific learning needs, providing learners with personalised learning experiences, and helping some schools to make better decisions, so that they can more effectively use the teaching resources available to them. As AI systems continue to evolve and data usage increases, it is of utmost importance to develop a better understanding of their impact on the world around us, particularly in education and training. Educators and school leaders need to have at least a basic knowledge of AI and data usage in order to be able to engage positively, critically, and ethically with this technology and to properly use it to exploit its full potential. The definition of an Artificial Intelligence system (AI system) proposed in the draft AI Act is “software that is developed with one or more of the techniques and approaches (listed below) and can, for a given set of human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments it interacts with”. The listed AI techniques and approaches are: a) Machine learning approaches, including supervised, unsupervised and reinforcement learning, using a wide variety of methods including deep learning; b) Logic and knowledge-based approaches, including knowledge representation, inductive (logic) programming, knowledge bases, inference and deductive engines, (symbolic) reasoning and expert systems; c) Statistical approaches, Bayesian estimation, search and optimisation methods.” ([European Commission, 2022, p. 10](zotero://select/groups/4907410/items/3BCJVLT9)) ([pdf](zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=10&annotation=JLYJ6P7P))

“What do we mean by AI and data use in Education? Schools typically process substantial amounts of educational data including personal information about students, parents, staff, management and suppliers. Data collected, used, and processed in education is often referred to as “educational data”. These consist of data recorded in student information systems for example, educational achievements, parent names, assessment grades, as well as micro-level data generated when digital tools are used. When students interact with digital devices, they generate digital traces such as mouse clicks, data on opened pages, the timing of interaction events, or key presses. In the same way when using intelligent tutoring systems (ITS) in classrooms, learning mathematics or modern languages produce learning activity traces. All this data can be combined to capture each student’s online behaviour. This type of trace data (digital usage and learning activity traces) is often used for learning analytics (LA). Data in student information systems can be further used for resource and course planning and to predict dropout and guidance.” ([European Commission, 2022, p. 11](zotero://select/groups/4907410/items/3BCJVLT9)) ([pdf](zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=11&annotation=M6BIZHPT))

“Why do we need these guidelines? The use of AI systems can potentially enhance teaching, learning and assessment, provide better learning outcomes and help schools to operate more efficiently. However, if those same AI applications are not properly designed or used carelessly, this could lead to harmful consequences. Educators need to be aware and ask questions whether AI systems they are using are reliable, fair, safe and trustworthy and that the management of educational data is secure, protects the privacy of individuals and is used for the common good. “Ethical AI” is used to indicate the development, deployment and use of AI that ensures compliance with ethical norms, ethical principles and related core values.” ([European Commission, 2022, p. 11](zotero://select/groups/4907410/items/3BCJVLT9)) ([pdf](zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=11&annotation=5FHZZAZJ))

“Because Instructors typically conduct SoTL in their classrooms (current or former), SoTL practitioners frequently find themselves in the dual role of instructor and researcher. Ultimately, the instructor-researcher in SoTL is an instructor first. As MacLean and Poole (2010, pg. 3) explain, “The teacher’s responsibility to hold students’ educational interests paramount provides an important perspective when considering ethical issues for research in teaching and learning.” This dual role can raise a set of specific ethical dilemmas that require instructor-researchers to plan parts of the research carefully and to ask themselves challenging questions. Potential ethical dilemmas can arise concerning the following areas of ethical consideration. In the table below, we articulate several core principles for ethical practice that respond to these potentially dilemmatic areas of consideration and elaborate on them in the remainder of the document.” ([Fedoruk, 2017, p. 4](zotero://select/groups/4907410/items/DHREGI82)) ([pdf](zotero://open-pdf/groups/4907410/items/43L7TRPP?page=8&annotation=ZINFJT2X))

“We will consider “educational technology” (edtech) to include both (a) technologies specifically designed for educational use, as well as (b) general technologies that are widely used in educational settings.” (Cardona et al., 2023, p. 1)
“AI can be defined as “automation based on associations.” When computers automate reasoning based on associations in data (or associations deduced from expert knowledge), two shifts fundamental to AI occur and shift computing beyond conventional edtech: (1) from capturing data to detecting patterns in data and (2) from providing access to instructional resources to automating decisions about instruction and other educational processes. Detecting patterns and automating decisions are leaps in the level of responsibilities that can be delegated to a computer system. The process of developing an AI system may lead to bias in how patterns are detected and unfairness in how decisions are automated. Thus, educational systems must govern their use of AI systems.” (Cardona et al., 2023, p. 1)
“Understanding that AI increases automation and allows machines to do some tasks that only people did in the past leads us to a pair of bold, overarching questions: 1. What is our collective vision of a desirable and achievable educational system that leverages automation to advance learning while protecting and centering human agency? 2. How and on what timeline will we be ready with necessary guidelines and guardrails, as well as convincing evidence of positive impacts, so that constituents can ethically and equitably implement this vision widely?” (Cardona et al., 2023, p. 6)
“Below we address three additional perspectives on what constitutes AI. Educators will find these different perspectives arise in the marketing of AI functionality and are important to understand when evaluating edtech systems that incorporate AI. One useful glossary of AI for Education terms is the CIRCLS Glossary of Artificial Intelligence Terms for Educators.11 AI is not one thing but an umbrella term for a growing set of modeling capabilities, as visualized in Figure 3. Figure3:Components,types,andsubfieldsofAIbasedonRegonaetal(2022).12” (Cardona et al., 2023, p. 11)

![Components, types, and subfields of AI, from (Cardona et al., 2023, p. 11) based on Regona et al (2002)](/AI-cardona-p11.png "Components, types, and subfields of AI, from (Cardona et al., 2023, p. 11) based on Regona et al (2002)")


“12 Regona, Massimo & Yigitcanlar, Tan & Xia, Bo & Li, R.Y.M. (2022). Opportunities and adoption challenges of AI in the construction industry: A PRISMA review. Journal of Open Innovation Technology Market and Complexity, 8(45). https://doi.org/10.3390/joitmc8010045” (Cardona et al., 2023, p. 11)
Human-Like Reasoning: “The idea of “human-like” is helpful because it can be a shorthand for the idea that computers now have capabilities that are very different from the capabilities of early edtech applications. Educational applications will be able to converse with students and teachers, co-pilot how activities unfold in classrooms, and take actions that impact students and teachers more broadly. There will be both opportunities to do things much better than we do today and risks that must be anticipated and addressed. The “human-like” shorthand is not always useful, however, because AI processes information differently from how people process information. When we gloss over the differences between people and computers, we may frame policies for AI in education that miss the mark.” (Cardona et al., 2023, p. 12)
An Algorithm that Pursues a Goal: 
“This second definition emphasizes that AI systems and tools identify patterns and choose actions to achieve a given goal. These pattern recognition capabilities and automated recommendations will be used in ways that impact the educational process, including student learning and teacher instructional decision making. For example, today’s personalized learning systems may recognize signs that a student is struggling and may recommend an alternative instructional sequence.” (Cardona et al., 2023, p. 12)
“Although this perspective can be useful, it can be misleading. A human view of agency, pursuing goals, and reasoning includes our human abilities to make sense of multiple contexts. For example, a teacher may see three students each make the same mathematical error but recognize that one student has an Individualized Education Program to address vision issues, another misunderstands a mathematical concept, and a third just experienced a frustrating interaction on the playground; the same instructional decision is therefore not appropriate. However, AI systems often lack data and judgement to appropriately include context as they detect patterns and automate decisions. Further, case studies show that technology has the potential to quickly derail from safe to unsafe or from effective to ineffective when the context shifts even slightly. For this and other reasons, people must be involved in goal setting, pattern analysis, and decision-making.15” (Cardona et al., 2023, p. 13)
Intelligence Augmentation: 
““Intelligence Augmentation” (IA)17 centers “intelligence” and “decision making” in humans but recognizes that people sometimes are overburdened and benefit from assistive tools. AI may help teachers make better decisions because computers notice patterns that teachers can miss. For example, when a teacher and student agree that the student needs reminders, an AI system may provide reminders in whatever form a student likes without adding to the teacher’s workload. Intelligence Automation (IA) uses the same basic capabilities of AI, employing associations in data to notice patterns, and, through automation, takes actions based on those patterns. However, IA squarely focuses on helping people in human activities of teaching and learning, whereas AI tends to focus attention on what computers can do.” (Cardona et al., 2023, p. 14)



## Situating Ethics in Legal and Human Context

Across the national statement, and the review materials (Fjeld, Schiff, and High-Level Exper Group on AI), it is acknowledged that ethical action respects fundamental human rights, seeking to promote thse rights throughout the research endeavour.

Ethical action, and the particular activities we engage in - including teaching, research, and data processing - are governed by legal and contractual obligations. These are not the focus of this guideline, and you should ensure you are familiar with and clear about these considerations.

"

“All governmental power in constitutional democracies must be legally authorised and limited by law. AI systems should serve to maintain and foster democratic processes and respect the plurality of values and life choices of individuals. AI systems must not undermine democratic processes, human deliberation or democratic voting systems. AI systems must also embed a commitment to ensure that they do not operate in ways that undermine the foundational commitments upon which the rule of law is founded, mandatory laws and regulation, and to ensure due process and equality before the law.” (High-Level Expert Group on AI, 2019, p. 11)" /reckb3cgfedh1eeup

## Research Ethics and the Researcher-Participant relationship

Traditionally, research ethics is framed in terms of researcher-participant interaction. In this context, the fundamental principles of research ethics are intended to ground those relationships in respect for persons.



## Principles overview

There are well established principles for research ethics, with many commonalities across principles produced in different communities. Underpinning research ethics are three principles of respect for persons, beneficence (and non-maleficence), and justice. A fourth principle of ‘Merit and Integrity’ - I.e., that research should be conducted that is worthwhile and rigorous, and executed with integrity - is implicit in many guidelines and made explicit in the Australian National Statement on research ethics with human participants.

This guideline is not intended to offer a prescriptive model of ethics principles, and so although particular principles are highlighted throughout, readers may wish to consider how the principles in this guideline related to those from their research context. For example, the excellent BERA guidelines largely parallel the principles in this guideline, although different language is used in places. The BERA guidelines also provide helpful overview of the responsibilities of different stakeholders, and thus act as an excellent supplement. 

Although these principles are broadly common across research ethics systems, it is worth highlighting that (1) implementation varies, and what is acceptable in one context may not be in another; (2) local values and cultures of research and ethics must be considered in navigating ethical action, and there may be ethical concepts with important nuances in interpretation; and (3) there are differences in ethical and legal context internationally which have an impact on the kind of research conducted or the expression of research ethics in that work. A key variation internationally regards the way in which long-range impacts are considered, 






At all stages, human research requires ethical reflection that is informed by ethical principles. 

Research merit and integrity are discussed first. Unless proposed research has merit, and the researchers who are to carry out the research have integrity, the involvement of human participants in the research cannot be ethically justifiable.

At a profound level, justice involves a regard for the human sameness that each person shares with every other. Human beings have a deep need to be treated in accordance with such justice, which includes distributive justice and procedural justice. In the research context, distributive justice will be expressed in the fair distribution of the benefits and burdens of research, and procedural justice in _fair treatment_ in the recruitment of participants and the review of research. While benefit to humankind is an important result of research, it also matters that benefits of research are achieved through just means, are distributed fairly, and involve no unjust burdens.

Researchers exercise beneficence in several ways:

* in assessing and taking account of the risks of harm and the potential benefits of research to participants and to the wider community
* in being sensitive to the welfare and interests of people involved in their research
* in reflecting on the social and cultural implications of their work.

Respect for human beings is the common thread through all the discussions of ethical values. Turning to it as the final value is a reminder that it draws together all of the ethical deliberation that has preceded it.

The design, review and conduct of research must reflect each of these values.

"

“Societal and environmental wellbeing including sustainability and environmental friendliness, social impact, society, and democracy.” (European Commission, 2022, p. 18)" (/recqdghz7l1cgnqeu)

"## BackgroundFor A/IS technologies to demonstrably advance benefit for humanity, we need to be able to define and measure the benefit we wish to increase. But often the only indicators utilized in determining success for A/IS are avoiding negative unintended consequences and increasing productivity and economic growth for customers and society. Today, these are largely measured by gross domestic product (GDP), profit, or consumption levels.Well-being, for the purpose of Ethically Aligned Design, is based on the Organization for Economic Co-operation and Development’s (OECD) ”Guidelines on Measuring Subjective Well-being” perspective that, “Being able to measure people’s quality of life is fundamental when assessing the progress of societies.” There is now widespread acknowledgement that measuring subjective well-being is an essential part of measuring quality of life alongside other social and economic dimensions as identified within Nassbaum-Sen’s capability approach whereby well-being is objectively defined in terms of human capabilities necessary for functioning and flourishing.Since modern societies will be largely constituted of A/IS users, we believe these considerations to be relevant for A/IS creators. A/IS technologies can be narrowly conceived from an ethical standpoint. They can be legal, profitable, and safe in their usage, yet not positively contribute to human and environmental well-being. This means technologies created with the best intentions, but without considering well-being, can still have dramatic negative consequences on people’s mental health, emotions, sense of themselves, their autonomy, their ability to achieve their goals, and other dimensions of well-being."[(IEEE, 2019, p.23-24)](/recefm7cgashwpjzo)

> Is this worthwhile? ’Worthwhile’ can mean both that:
1.	they produce outcomes we that address our shared values (they have ‘worth’),
2.	they can reliably produce our target outcomes, they are an activity that  evidence indicates is worth doing if want to achieve these goals.


Environmental and social sustainability
And prosperity

