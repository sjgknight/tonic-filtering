- Challenges:
  - recCpTJXuuowqsqQa
  - recHHr97jsyNDnlsJ
  - recgZrgA8K7MmIzdF
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recJQF6QfQGlcSzDm
  - reczG9x5YfScZJdCo
  - recY9yr9vYcOAUSEA
  - recmhwo8kmYkBZ7Sy
  - recgswAsiepwEclOd
  - recNzXJwCfbwBLmVU
  - recAhcg8OdusJvk43
  - recB7MF7TeUKH3chO
  - recgNdOlcMTiussUk
  - rec55h8FhGKyGPNgw
  - reclplj55gpqdYGTr
  - recOo7Pmo4FBYcu7P
  - rec4oGONFgYMu3JGf
  - recAMa23XxDLEzMn8
  - recBUdrJ8n1tIJLTz
  - rec95I69E1YcGg0Sa
  - recTjwhqfrJoaRxYo
  - recq6GeKNegFQdzS9
  - recJyzFLE9ry4YEbb
  - reccAKmFQRH7IiuJi
  - recaTTvWN1olqx608
  airtable_createdTime: '2023-05-18T14:25:20.000Z'
  airtable_id: rec42P8U9usfYCtv9
  childOf:
  - recmzjcGKv3yNOxbl
  title: Minimise risks of harms
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:39:12.000Z'
  airtable_id: rec5216SybPPylYdD
  childOf:
  - recImuZ3T4iDiNP2B
  equivalentTo:
  - recsvi4LnhEEPyQ1h
  title: Ensure their abilities to make free and informed decisions about their own
    lives
- Description: "**Creators and operators shall provide evidence of the effectiveness\
    \ and fitness for purpose of A/IS.**\n## Background\nThe responsible adoption\
    \ and deployment of A/IS are essential if such systems are to realize their many\
    \ potential benefits to the well-being of both individuals and societies. A/IS\
    \ will not be trusted unless they can be shown to be effective in use. Harms caused\
    \ by A/IS, from harm to an individual through to systemic damage, can undermine\
    \ the perceived value of A/IS and delay or prevent its adoption.\nOperators and\
    \ other users will therefore benefit from measurement of the effectiveness of\
    \ the A/IS in question. To be adequate, effective measurements need to be both\
    \ valid and accurate, as well as meaningful and actionable. And such measurements\
    \ must be accompanied by practical guidance on how to interpret and respond to\
    \ them.\n## Recommendations\n1\\.\_\_\_Creators engaged in the development of\
    \ A/IS should seek to define metrics or benchmarks that will serve as valid and\
    \ meaningful gauges of the effectiveness of the system in meeting its objectives,\
    \ adhering to standards and remaining within risk tolerances. Creators building\
    \ A/IS should ensure that the results when the defined metrics are applied are\
    \ readily obtainable by all interested parties, e.g., users, safety certifiers,\
    \ and regulators\_of the system.\n2\\.\_\_\_Creators of A/IS should provide guidance\
    \ on how to interpret and respond to the metrics generated by the systems.\n3\\\
    .\_\_\_To the extent warranted by specific circumstances, operators of A/IS should\
    \ follow the guidance on measurement provided with the systems, i.e., which metrics\
    \ to obtain,\_how and when to obtain them, how to respond to given results, and\
    \ so on.\_\_\n4\\.\_\_\_To the extent that measurements are sample based, measurements\
    \ should account for the scope of sampling error, e.g., the reporting of confidence\
    \ intervals associated with the measurements. Operators should be advised how\
    \ to interpret the results.\n5\\.\_\_\_Creators of A/IS should design their systems\
    \ such that metrics on specific deployments of the system can be aggregated to\
    \ provide information on the effectiveness of the system across multiple deployments.\
    \ For example, in the case of autonomous vehicles, metrics should be generated\
    \ both for a specific instance of a vehicle and for a fleet of many instances\
    \ of the same kind of vehicle.\n6\\.\_\_\_In interpreting and responding to measurements,\
    \ allowance should be made for variation in the specific objectives and circumstances\
    \ of a given deployment of A/IS. should work toward developing standards for the\
    \ measurement and reporting on the effectiveness of A/IS.\_\n## Further Resources\n\
    \u2022\_\_\_\_\_R. Dillmann, [KA 1.10 Benchmarks for Robotics Research](https://www.researchgate.net/publication/250861011_KA_110_Benchmarks_for_Robotics_Research),\
    \ 2010. \n\u2022\_\_\_\_\_A. Steinfeld, T.W. Fong, D. Kaber, J. Scholtz, \nA.\
    \ Schultz, and M. Goodrich, \u201C[Common Metrics for Human-Robot Interaction](https://www.ri.cmu.edu/publications/common-metrics-for-human-robot-interaction/)\u201D\
    , 2006 Human-Robot Interaction Conference, March, 2006. \n\u2022\_\_\_\_\_R. Madhavan,\
    \ E. Messina, and E. Tunstel, Eds., [Performance Evaluation and Benchmarking of\
    \ Intelligent Systems](https://link.springer.com/book/10.1007%2F978-1-4419-0492-8),\
    \ Boston, MA: Springer, 2009.\u2022\_\_\_\_\__IEEE Robotics & Automation Magazine_,\
    \ [Special Issue on Replicable and Measurable Robotics Research](https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7254280),\
    \ Volume 22, No. 3, September 2015.\n\u2022\_\_\_\_\_C. Flanagin, [A Survey on\
    \ Robotics Systems and Performance Analysis](https://www.cse.wustl.edu/~jain/cse567-11/ftp/robots/index.html),\
    \ 2011.\n\u2022\_\_\_\_\_[Transaction Processing Performance Council ](https://www.businesswire.com/news/home/20171212005281/en/Transaction-Processing-Performance-Council-TPC-Establishes-Artificial)\n\
    [(TPC) Establishes Artificial Intelligence Working Group (TPC-AI)](https://www.businesswire.com/news/home/20171212005281/en/Transaction-Processing-Performance-Council-TPC-Establishes-Artificial)\
    \ tasked with developing industry standard benchmarks for both hardware and software\
    \ platforms associated with running Artificial Intelligence (AI) based workloads,\
    \ 2017\n\np.26-27\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:23:44.000Z'
  airtable_id: rec5N7PaVEFRs2o8R
  childOf:
  - recuQpwelm0FwdAib
  title: Effectiveness
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recKDgUEDD2f1egyd
  - rec55h8FhGKyGPNgw
  - reclplj55gpqdYGTr
  airtable_createdTime: '2023-05-18T14:25:53.000Z'
  airtable_id: rec6O9e1nYBJtQUTj
  childOf:
  - recmzjcGKv3yNOxbl
  title: Maximise potential for benefits
- Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - rec0GhefNkhJqW0c2
  - recNHvwgyFPXERuJ8
  - recQPwyiQbPcN0G47
  airtable_createdTime: '2023-05-19T09:39:25.000Z'
  airtable_id: rec6tz9Phzck0hvT8
  childOf:
  - recImuZ3T4iDiNP2B
  equivalentTo:
  - recU6u0AZbcNj1ik9
  title: Safeguard their autonomy, their power to express themselves, and their right
    to be heard
- Description: "\u201C\u2022 Design and deploy AI systems to foster and to cultivate\
    \ the welfare of all stakeholders whose interests are affected by their use \u2022\
    \ Do no harm with these technologies and minimise the risks of their misuse or\
    \ abuse\u201D (Leslie, 2019, p. 10)\n\u201C\u2022 Prioritise the safety and the\
    \ mental and physical integrity of people when scanning horizons of technological\
    \ possibility and when conceiving of and deploying AI applications\u201D (Leslie,\
    \ 2019, p. 11)\n"
  Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - recmhwo8kmYkBZ7Sy
  - recgswAsiepwEclOd
  - recNzXJwCfbwBLmVU
  - recAhcg8OdusJvk43
  airtable_createdTime: '2023-05-19T10:57:44.000Z'
  airtable_id: rec7n2TGrH9RHYpQj
  equivalentTo:
  - recmzjcGKv3yNOxbl
  title: CARE for the wellbeing of each and all
- Description: "\"A/IS\u2014if designed and implemented properly\u2014 have a great\
    \ potential to nurture political freedom and democracy, in accordance with the\
    \ cultural precepts of individual societies, when people have access to and control\
    \ over the data constituting and representing their identity. These systems can\
    \ improve government effectiveness and accountability, foster trust, and protect\
    \ our private sphere, but only when people have agency over their digital identity\
    \ and their data is provably protected.\" p.7\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:26:38.000Z'
  airtable_id: rec9uueW1gq31CcBo
  equivalentTo:
  - recKdujFoPJr4ZAhZ
  - rec6tz9Phzck0hvT8
  - recQEiU22Qy1E0YuA
  title: 'Pillar of the Ethically Aligned Design Conceptual Framework: Political Self-Determination
    and Data Agency'
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:42:36.000Z'
  airtable_id: recArMNCiaj832hZ1
  childOf:
  - rectPrYetyr4YIuq8
  title: Use the advancement and proliferation of AI technologies to strengthen the
    developmentally essential relationship between interacting human beings.
- Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - recQPwyiQbPcN0G47
  airtable_createdTime: '2023-05-19T09:41:36.000Z'
  airtable_id: recB9JaNSRmLbD8eE
  childOf:
  - rectPrYetyr4YIuq8
  title: Prioritise diversity, participation, and inclusion at all points in the design,
    development, and deployment processes of AI innovation.
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:57:01.000Z'
  airtable_id: recC49LlmCoNq2Svy
  childOf:
  - rectPrYetyr4YIuq8
  title: Use AI technologies to foster this capacity to connect so as to reinforce
    the edifice of trust, empathy, reciprocal responsibility, and mutual understanding
    upon which all ethically wellfounded social orders rest
- Description: "**Creators shall guard against all potential misuses and risks of\
    \ A/IS in operation.**\n## Background\nNew technologies give rise to greater risk\
    \ of deliberate or accidental misuse, and this is especially true for A/IS. A/IS\
    \ increases the impact of risks such as hacking, misuse of personal data, system\
    \ manipulation, or exploitation of vulnerable users by unscrupulous parties. Cases\
    \ of A/IS hacking have already been widely reported, with [driverless cars](https://www.wired.com/2016/08/hackers-fool-tesla-ss-autopilot-hide-spoof-obstacles/),[\
    \ ](https://www.wired.com/2016/08/hackers-fool-tesla-ss-autopilot-hide-spoof-obstacles/)for\
    \ example. The [Microsoft Tay AI chatbot](https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/)\
    \ was famously manipulated when it mimicked deliberately offensive users. In an\
    \ age where these powerful tools are easily available, there is a need for a new\
    \ kind of education for citizens to be sensitized to risks associated with the\
    \ misuse of A/IS. The EU\u2019s General Data Protection Regulation (GDPR) provides\
    \ measures to remedy the misuse of personal data.\nResponsible innovation requires\
    \ A/IS creators to anticipate, reflect, and engage with users of A/IS. Thus, citizens,\
    \ lawyers, governments, etc., all have a role to play through education and awareness\
    \ in developing accountability structures (see Principle 6), in addition to guiding\
    \ new technology proactively toward beneficial ends.\n## Recommendations\n1\\\
    .\_\_\_Creators should be aware of methods of misuse, and they should design A/IS\
    \ in ways to minimize the opportunity for these.\n2\\.\_\_\_Raise public awareness\
    \ around the issues of potential A/IS technology misuse in an informed and measured\
    \ way by:\n\u2022\_\_\_\_\_Providing ethics education and security awareness that\
    \ sensitizes society to the potential risks of misuse of A/IS. For example, provide\
    \ \u201Cdata privacy warnings\u201D that some smart devices will collect their\
    \ users\u2019\_personal data.\n\u2022\_\_\_\_\_Delivering this education in scalable\
    \ and effective ways, including having experts with the greatest credibility and\
    \ impact who can minimize unwarranted fear about A/IS.\n\u2022\_\_\_\_\_Educating\
    \ government, lawmakers, and enforcement agencies about these issues of A/IS so\
    \ citizens can work collaboratively with these agencies to understand safe use\
    \ of A/IS. For example, the same way police officers give public safety lectures\
    \ in schools, they could provide workshops on safe use and interaction with A/IS.\n\
    ## Further Resources\n\u2022\_\_\_\_\_A. Greenberg, \u201C[Hackers Fool Tesla\
    \ S\u2019s\\_Autopilot to Hide and Spoof Obstacles](https://www.wired.com/2016/08/hackers-fool-tesla-ss-autopilot-hide-spoof-obstacles/),\u201D\
    \_Wired, August 2016.\n\u2022\_\_\_\_\_C. Wilkinson and E. Weitkamp, _[Creative\
    \ Research and Communication: Theory and Practice](http://www.manchesteruniversitypress.co.uk/9780719096518/)_,\
    \ Manchester, UK: Manchester University Press, 2016 (in relation to Recommendation\
    \ #2).\n\u2022\_\_\_\_\_Engineering and Physical Sciences Research Council, \u201C\
    [Anticipate, Reflect, Engage and Act (AREA)](https://epsrc.ukri.org/research/framework/area/),\u201D\
    \ Framework for Responsible Research and Innovation, Accessed 2018.\n\np.32-33\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:24:55.000Z'
  airtable_id: recCFSnZpjvw0PcUE
  childOf:
  - recuQpwelm0FwdAib
  title: Awareness of misuse
- Description: "**A/IS creators shall empower individuals with the ability to access\
    \ and securely share their data, to maintain people\u2019s capacity to have control\
    \ over their identity.**\n## Background\nDigital consent is a misnomer in its\
    \ current manifestation. Terms and conditions or privacy policies are largely\
    \ designed to provide legally accurate information regarding the usage of people\u2019\
    s data to safeguard institutional and corporate interests, while often neglecting\
    \ the needs of the people whose data they process. \u201CConsent fatigue\u201D\
    , the constant request for agreement to sets of long and unreadable data handling\
    \ conditions, causes a majority of users to simply click and accept terms in order\
    \ to access the services they wish to use. General obfuscation regarding privacy\
    \ policies, and scenarios like the [Cambridge Analytica scandal](https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html)\
    \ in 2018, demonstrate that even when individuals provide consent, the understanding\
    \ of the value regarding their data and its safety is out of an individual\u2019\
    s control.\nThis existing model of data exchange has eroded human agency in the\
    \ algorithmic age. People don\u2019t know how their data is being used at all\
    \ times or when predictive messaging is honoring their existing preferences or\
    \ manipulating them to create new behaviors.\nRegulations like the [EU General\
    \ Data Protection Regulation ](https://eugdpr.org/)(GDPR) will help improve this\
    \ lack of clarity regarding the exchange of personal data. But compliance with\
    \ existing models of consent is not enough to safeguard people\u2019s agency regarding\
    \ their personal information. In an era where A/IS are already pervasive in society,\
    \ governments must recognize that limiting the misuse of personal data is not\
    \ enough.\nSociety must also recognize that human rights in the digital sphere\
    \ don\u2019t exist until individuals globally are empowered with means\u2014including\
    \ tools and policies\u2014that ensure their dignity through some form of sovereignty,\
    \ agency, symmetry, or control regarding their identity and personal data. These\
    \ rights rely on individuals being able to make their choices, outside of the\
    \ potential influence of biased algorithmic messaging or bad actors. Society also\
    \ needs to be confident that those who are unable to provide legal informed consent,\
    \ including minors and people with diminished capacity to make informed decisions,\
    \ do not lose their dignity due to this.\n## Recommendation\nOrganizations, including\
    \ governments, should immediately explore, test, and implement technologies and\
    \ policies that let individuals specify their online agent for case-by-case authorization\
    \ decisions as to who can process what personal data for what purpose. For minors\
    \ and those with diminished capacity to make informed decisions, current guardianship\
    \ approaches should be viewed to determine their suitability in this context.\n\
    The general solution to give agency to the individual is meant to anticipate and\
    \ enable individuals to own and fully control autonomous and intelligent (as in\
    \ capable of learning) technology that can evaluate data use requests by external\
    \ parties and service providers. This technology would then provide a form of\
    \ \u201Cdigital sovereignty\u201D and could issue limited and specific authorizations\
    \ for processing of the individual\u2019s personal data wherever it is held in\
    \ a\_compatible system.\n## Further Resources\nThe following resources are designed\
    \ to provide governments and other organizations\u2014corporate, for-profit, not-for-profit,\
    \ B Corp, or any form of public institution\u2014basic information on services\
    \ designed to provide user agency and/or sovereignty over their personal data.\n\
    \u2022\_\_\_\_\_The European Data Protection Supervisor [defines personal information\
    \ management systems](https://edps.europa.eu/data-protection/our-work/subjects/personal-information-management-system_en)\
    \ (PIMS) as:\n\u2022\_\_\_\u201C...systems that help give individuals more control\
    \ over their personal data...allowing individuals to manage their personal data\
    \ in secure, local or online storage systems and share them when and with whom\
    \ they choose. Providers of online services and advertisers will need to interact\
    \ with the PIMS if they plan to process individuals\u2019 data. This can enable\
    \ a human centric approach to personal information and new business models.\u201D\
    \ For further information and ongoing research regarding PIMS, visit [Crtl-Shift\u2019\
    s PIMS monthly archive](https://www.ctrl-shift.co.uk/tag/pims/). \n\u2022\_\_\_\
    \_\_IEEE P7006\u2122, IEEE [Standards Project for Personal Data Artificial Intelligence\
    \ (AI) Agent](https://standards.ieee.org/develop/project/7006.html) [describes\
    \ the technical elements required to create and grant access to a personalized\
    \ Artificial Intelligence that will comprise inputs, learning, ethics, rules,\
    \ and values controlled by individuals. ](https://standards.ieee.org/develop/project/7006.html)\n\
    IEEE P7012\u2122, [IEEE Standards Project for Machine Readable Personal Privacy\
    \ Terms](https://standards.ieee.org/project/7012.html) is designed to provide\
    \ individuals with a means to proffer their own terms respecting personal privacy\
    \ in ways that can be read, acknowledged, and be agreed to by machines operated\
    \ by others in the networked world\n\np.25-26\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:19:32.000Z'
  airtable_id: recD6uFlCKFiHl414
  childOf:
  - recSwTdeEk6XbEgXU
  - rec9uueW1gq31CcBo
  - recuQpwelm0FwdAib
  title: Data agency
- Challenges:
  - recHHr97jsyNDnlsJ
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:59:36.000Z'
  airtable_id: recDRQE1qQQNI65Xn
  childOf:
  - recZToVrPeFlFq0Aw
  title: Treat all individuals equally and protect social equity
- Description: "**The basis of a particular A/IS decision should always be discoverable.**\n\
    ## Background\nA key concern over autonomous and intelligent systems is that their\
    \ operation must be transparent to a wide range of stakeholders for different\
    \ reasons, noting that the level of transparency will necessarily be different\
    \ for each stakeholder. Transparent A/IS are ones in which it is possible to discover\
    \ how and why a system made a particular decision,\_or in the case of a robot,\
    \ acted the way it did. The term \u201Ctransparency\u201D in the context of\_\
    A/IS also addresses the concepts of traceability, explainability, and interpretability.\n\
    \ A/IS will perform tasks that are far more complex and have more effect on our\
    \ world than prior generations of technology. Where the task is undertaken in\
    \ a non-deterministic manner, it may defy simple explanation. This reality will\
    \ be particularly acute with systems that interact with the physical world, thus\
    \ raising the potential level of harm that such a system could cause. For example,\
    \ some A/IS already have real consequences to human safety or well-being, such\
    \ as medical diagnosis or driverless car autopilots. Systems such as these are\
    \ safetycritical_ _systems. At the same time, the complexity of A/IS technology\
    \ and the non-intuitive way in which it may operate will make it difficult for\
    \ users of those systems to understand the actions of the A/IS that they use,\
    \ or with which they interact. This opacity, combined with the often distributed\
    \ manner in which the A/IS are developed, will complicate efforts to determine\
    \ and allocate responsibility when something goes wrong. Thus, lack of transparency\
    \ increases the risk and magnitude of harm when users do not understand the systems\
    \ they are using, or there is a failure to fix faults and improve systems following\
    \ accidents. Lack of transparency also increases the difficulty of ensuring accountability\
    \ (see Principle 6\u2014 Accountability).\nAchieving transparency, which may involve\
    \ a significant portion of the resources required to develop the A/IS, is important\
    \ to each stakeholder group for the following reasons:\n1\\.\_\_\_For users, what\
    \ the system is doing and why.\n2\\.\_\_\_For creators, including those undertaking\
    \ the validation and certification of A/IS, the systems\u2019 processes and input\
    \ data.\n3\\.\_\_\_For an accident investigator, if accidents occur.\n4\\.\_\_\
    \_For those in the legal process, to inform evidence and decision-making.\n5\\\
    .\_\_\_For the public, to build confidence in\_the technology.\nDevelop new standards\
    \ that describe measurable, testable levels of transparency, so that systems can\
    \ be objectively assessed and levels of compliance determined. For designers,\
    \ such standards will provide a guide for self-assessing transparency during development\
    \ and suggest mechanisms for improving transparency. The mechanisms by which transparency\
    \ is provided will vary significantly, including but not limited to, the following\
    \ use cases:\n1\\.\_\_\_For users of care or domestic robots, a \u201Cwhydid-you-do-that\
    \ button\u201D which, when pressed, causes the robot to explain the action it\_\
    just took.\n2\\.\_\_\_For validation or certification agencies, the algorithms\
    \ underlying the A/IS and how they have been verified.\n3\\.\_\_\_For accident\
    \ investigators, secure storage of sensor and internal state data comparable to\
    \ a flight data recorder or black box. IEEE P7001\u2122, [IEEE Standard for Transparency\
    \ of Autonomous Systems](https://standards.ieee.org/project/7001.html) is one\
    \ such standard, developed in response to this recommendation\n\np.28-29\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:24:07.000Z'
  airtable_id: recFVLYl0cMH88Lzv
  childOf:
  - recSwTdeEk6XbEgXU
  - rec9uueW1gq31CcBo
  - recuQpwelm0FwdAib
  title: Transparency
- Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - recEHwRaLD44KPk8v
  airtable_createdTime: '2023-05-19T09:39:33.000Z'
  airtable_id: recGb4WZzr34RXKr0
  childOf:
  - recImuZ3T4iDiNP2B
  equivalentTo:
  - recU6u0AZbcNj1ik9
  title: Secure their capacities to make well-considered and independent contributions
    to the life of the community
- Description: "\u201C\u2022 Ensure their abilities to make free and informed decisions\
    \ about their own lives \u2022 Safeguard their autonomy, their power to express\
    \ themselves, and their right to be heard \u2022 Secure their capacities to make\
    \ well-considered and independent contributions to the life of the community \u2022\
    \ Support their abilities to flourish, to fully develop themselves, and to pursue\
    \ their passions and talents according to their own freely determined life plans\u201D\
    \ (Leslie, 2019, p. 10)\n"
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:38:40.000Z'
  airtable_id: recImuZ3T4iDiNP2B
  equivalentTo:
  - recLHILkx2JDFsLbX
  title: RESPECT the dignity of individual persons
- Challenges:
  - recHHr97jsyNDnlsJ
  Description: "\u201CThe development, deployment and use of AI systems must be fair.\
    \ While we acknowledge that there are many different interpretations of fairness,\
    \ we believe that fairness has both a substantive and a procedural dimension.\
    \ The substantive dimension implies a commitment to: ensuring equal and just distribution\
    \ of both benefits and costs, and ensuring that individuals and groups are free\
    \ from unfair bias, discrimination and stigmatisation. If unfair biases can be\
    \ avoided, AI systems could even increase societal fairness. Equal opportunity\
    \ in terms of access to education, goods, services and technology should also\
    \ be fostered. Moreover, the use of AI systems should never lead to people being\
    \ deceived or unjustifiably impaired in their freedom of choice. Additionally,\
    \ fairness implies that AI practitioners should respect the principle of proportionality\
    \ between means and ends, and consider carefully how to \u201Cbalance competing\
    \ interests and objectives.31 The procedural dimension of fairness entails the\
    \ ability to contest and seek effective redress against decisions made by AI systems\
    \ and by the humans operating them.32 In order to do so, the entity accountable\
    \ for the decision must be identifiable, and the decision-making processes should\
    \ be explicable.\u201D (High-Level Expert Group on AI, 2019, p. 13-14)\n"
  Sources:
  - recnCULdYQ36cpZR7
  airtable_createdTime: '2023-05-25T18:06:39.000Z'
  airtable_id: recK5zFiq18A3wHAE
  equivalentTo:
  - recSqx6wklVpDzx3s
  title: Fairness
- Description: "**Creators shall specify and operators shall adhere to the knowledge\
    \ and skill required for **\_**safe and effective operation.**\n## Background\n\
    A/IS can and often do make decisions that previously required human knowledge,\
    \ expertise, and reason. Algorithms potentially can make even better decisions,\
    \ by accessing more information, more quickly, and without the error, inconsistency,\
    \ and bias that can plague human decision-making. As the use of algorithms becomes\
    \ common and the decisions they make become more complex, however, the more normal\
    \ and natural such decisions appear.\nOperators of A/IS can become less likely\
    \ to question and potentially less able to question the decisions that algorithms\
    \ make. Operators will not necessarily know the sources, scale, accuracy, and\
    \ uncertainty that are implicit in applications of A/IS. As the use of A/IS expands,\
    \ more systems will rely on machine learning where actions are not preprogrammed\
    \ and that might not leave a clear record of the steps that led the system to\
    \ its current state. Even if those records do exist, operators might not have\
    \ access to them or the expertise necessary to decipher those records.\nStandards\
    \ for the operators are essential.\nOperators should be able to understand how\_\
    \nA/IS reach their decisions, the information and logic on which the A/IS rely,\
    \ and the effects of those decisions. Even more crucially, operators should know\
    \ when they need to question A/IS and when they need to overrule them.\nCreators\
    \ of A/IS should take an active role in ensuring that operators of their technologies\
    \ have the knowledge, experience, and skill necessary not only to use A/IS, but\
    \ also to use it safely and appropriately, towards their intended ends. Creators\
    \ should make provisions for the operators to override A/IS in appropriate circumstances.\n\
    While standards for operator competence are necessary to ensure the effective,\
    \ safe, and ethical application of A/IS, these standards are not the same for\
    \ all forms of A/IS. The level of competence required for the safe and effective\
    \ operation of A/IS will range from elementary, such as \u201Cintuitive\u201D\
    \ use guided by design, to advanced, such as fluency in statistics.\n## Recommendations\n\
    1\\.\_\_\_Creators of A/IS should specify the types and levels of knowledge necessary\
    \ to understand and operate any given application of A/IS. In specifying the requisite\
    \ types and levels of expertise, creators should do so for the individual components\
    \ of A/IS and for the entire systems.\n2\\.\_\_\_Creators of A/IS should integrate\
    \ safeguards against the incompetent operation of their systems. Safeguards could\
    \ include issuing notifications/warnings to operators in certain conditions, limiting\
    \ functionalities for different levels of operators (e.g., novice vs. advanced),\
    \ system shut-down in potentially risky conditions, etc.\n3\\.\_\_\_Creators of\
    \ A/IS should provide the parties affected by the output of A/IS with information\
    \ on the role of the operator, the competencies required, and the implications\
    \ of operator error. Such documentation should be accessible\_and understandable\
    \ to both experts and the general public.\n4\\.\_Entities that operate A/IS should\
    \ create documented policies to govern how A/IS should be operated. These policies\
    \ should include the real-world applications for such\_A/IS, any preconditions\
    \ for their effective use, who is qualified to operate them, what training is\
    \ required for operators, how to measure the performance of the A/IS, and what\
    \ should be expected from the A/IS. The policies should also include specification\
    \ of circumstances\_in which it might be necessary for the\_operator to override\
    \ the A/IS.5.\_\_\_Operators of A/IS should, before operating a system, make sure\
    \ that they have access to the requisite competencies. The operator need not be\
    \ an expert in all the pertinent domains but should have access to individuals\
    \ with the requisite kinds of expertise.\n## Further Resources\n\u2022\_\_\_\_\
    \_S. Barocas and A.D. Selbst, [The Intuitive Appeal of Explainable Machines](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3126971),\
    \ Fordham Law Review, 2018.\nW. Smart, C. Grimm, and W. Hartzog, \u201C[An Education\
    \ Theory of Fault for Autonomous Systems](http://www.werobot2017.com/wp-content/uploads/2017/03/Smart-Grimm-Hartzog-Education-We-Robot.pdf)\u201D\
    , 2017. \n\np.33-34\n"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - reck6xeMUc9jtmLr3
  airtable_createdTime: '2023-06-03T18:25:02.000Z'
  airtable_id: recKWrfJzX52AXSIf
  childOf:
  - recuQpwelm0FwdAib
  title: Competence
- Challenges:
  - recdmBNNa98cN8Sda
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recN2Lw4yXDBWLSYv
  - recf50wvya0NXxdxz
  - recELo3u36oZuujxN
  - recI5BV6v0BCK03VN
  - recOo7Pmo4FBYcu7P
  - recRTVqtvPcBS6zps
  - recNHvwgyFPXERuJ8
  - reczFKqCos9f1opXO
  - recJyzFLE9ry4YEbb
  - reccAKmFQRH7IiuJi
  - recaTTvWN1olqx608
  - recX4wcNFSw9YljDD
  - recWm6C6wOuVr6UCX
  airtable_createdTime: '2023-05-18T13:40:06.000Z'
  airtable_id: recKdujFoPJr4ZAhZ
  childOf:
  - recLHILkx2JDFsLbX
  title: Autonomy
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:58:11.000Z'
  airtable_id: recL7CrHMutQEBBu7
  childOf:
  - rec7n2TGrH9RHYpQj
  title: Prioritise the safety and the mental and physical integrity of people when
    scanning horizons of technological possibility and when conceiving of and deploying
    AI applications
- Description: |
    "1.10 Respect for human beings is a recognition of their intrinsic value. In human research, this recognition includes abiding by the values of research merit and integrity, justice and beneficence. Respect also requires having due regard for the welfare, beliefs, perceptions, customs and cultural heritage, both individual and collective, of those involved in research.
    1.11 Researchers and their institutions should respect the privacy, confidentiality and cultural sensitivities of the participants and, where relevant, of their communities. Any specific agreements made with the participants or the community should be fulfilled.
    1.12 Respect for human beings involves giving due scope, throughout the research process, to the capacity of human beings to make their own decisions.
    1.13 Where participants are unable to make their own decisions or have diminished capacity to do so, respect for them involves empowering them where possible and providing for their protection as necessary." (NS 1.10-1.13)
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recgn2UvSD4OhzGI4
  - recnFHf9V2VtAVJMx
  - recinajIdAe7hRxjN
  - recegTm800wJXGjO1
  - rechaQXedBh3OsMjZ
  airtable_createdTime: '2023-05-18T13:40:06.000Z'
  airtable_id: recLHILkx2JDFsLbX
  equivalentTo:
  - recImuZ3T4iDiNP2B
  - recRbUmCzD09d6KZS
  - recSwTdeEk6XbEgXU
  title: Respect for persons
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recKDgUEDD2f1egyd
  - rec55h8FhGKyGPNgw
  - reclplj55gpqdYGTr
  airtable_createdTime: '2023-05-18T14:26:57.000Z'
  airtable_id: recMGB4iC5oaCtr5x
  childOf:
  - recSqx6wklVpDzx3s
  title: Fairness in distribution of burden and benefits of research
- Challenges:
  - recOpn4I30te1qiKl
  airtable_createdTime: '2023-06-05T05:32:52.000Z'
  airtable_id: recNB5h9bK4gEE9uc
  title: Consider long-range and indirect impacts
- Challenges:
  - recdmBNNa98cN8Sda
  Description: |
    "Unless proposed research has merit, and the researchers who are to carry out the research have integrity, the involvement of human participants in the research cannot be ethically justifiable." (NS, preamble)
    "1.1 Research that has merit is:
    1. (a) justifiable by its potential benefit, which may include its contribution to knowledge and understanding, to improved social welfare and individual wellbeing, and to the skill and expertise of researchers. What constitutes potential benefit and whether it justifies research may sometimes require consultation with the relevant communities
    2. (b) designed or developed using methods appropriate for achieving the aims of the proposal
    3. (c) based on a thorough study of the current literature, as well as previous studies. This does not exclude the possibility of novel research for which there is little or no literature available, or research requiring a quick response to an unforeseen situation
    4. (d) designed to ensure that respect for the participants is not compromised by the aims of the research, by the way it is carried out, or by the results
    5. (e) conducted or supervised by persons or teams with experience, qualifications and competence that are appropriate for the research
    6. (f ) conducted using facilities and resources appropriate for the research.
    1.2 Where prior peer review has judged that a project has research merit, the question of its research merit is no longer subject to the judgement of those ethically reviewing the research.
    1.3 Research that is conducted with integrity is carried out by researchers with a commitment to:
    1. (a) searching for knowledge and understanding
    2. (b) following recognised principles of research conduct
    3. (c) conducting research honestly
    4. (d) disseminating and communicating results, whether favourable or unfavourable, in ways that permit scrutiny and contribute to public knowledge and understanding."
    (NS 1.1-1.3)
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - rec0GhefNkhJqW0c2
  - recGS9OVQ7qAjvIYE
  - recKWkdYO98PeEKDz
  - recZPU5yTmrjPXlF2
  - recAnT7HDpWYvdJ1V
  - recnFHf9V2VtAVJMx
  - recvVsXM40mlnmhqP
  - rec81gtnlFS5W2BBF
  - rec8dLtyDCwvjMWge
  - rec8cNT8sPSFtMSAc
  - recRTVqtvPcBS6zps
  - rec03QV2RUJkP3dfo
  - recBUdrJ8n1tIJLTz
  - rec95I69E1YcGg0Sa
  - reciw4r1bRvx6A6Fq
  - rec7m69DQyCw3rlFg
  - recqY2lEigz82Xmh5
  airtable_createdTime: '2023-05-18T14:26:57.000Z'
  airtable_id: recOHnq45Fq7YWsRO
  title: Merit and Integrity
- Challenges:
  - recO1L6GoFMkA6Lt4
  - recAoyMGCCLhaSqEb
  Description: |
    "respect the privacy, confidentiality and cultural sensitivities of the participants and, where relevant, of their communities."
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recpUrzG3GpRiwqnz
  - recgWFCdfcVaeaPQO
  - reczG9x5YfScZJdCo
  - recJQF6QfQGlcSzDm
  - recY9yr9vYcOAUSEA
  - recypFGFqJzmgFmWV
  - reciw4r1bRvx6A6Fq
  - rec7m69DQyCw3rlFg
  - recwWov6KzmwU0FQW
  - recG86YsfXnKY9kNc
  airtable_createdTime: '2023-05-19T07:41:54.000Z'
  airtable_id: recPg7Ov0priGGtLm
  childOf:
  - recLHILkx2JDFsLbX
  title: Privacy
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recinajIdAe7hRxjN
  - recELo3u36oZuujxN
  - recI5BV6v0BCK03VN
  - recTWhZ88TbQLcNaQ
  - reck6xeMUc9jtmLr3
  airtable_createdTime: '2023-05-18T14:28:05.000Z'
  airtable_id: recQ9DIFEsOEkCx3O
  childOf:
  - recOHnq45Fq7YWsRO
  title: ensuring respect for persons is maintained in the design
- Description: "\u201Crespect for human autonomy The fundamental rights upon which\
    \ the EU is founded are directed towards ensuring respect for the freedom and\
    \ autonomy of human beings. Humans interacting with AI systems must be able to\
    \ keep full and effective self-determination over themselves, and be able to partake\
    \ in the democratic process. AI systems should not unjustifiably subordinate,\
    \ coerce, deceive, manipulate, condition or herd humans. Instead, they should\
    \ be designed to augment, complement and empower human cognitive, social and cultural\
    \ skills. The allocation of functions between humans and AI systems should follow\
    \ human-centric design principles and leave meaningful opportunity for human choice.\
    \ This means securing human oversight28 over work processes in AI systems. AI\
    \ systems may also fundamentally change the work sphere. It should support humans\
    \ in the working environment, and aim for the creation of meaningful work.\u201D\
    \ (High-Level Expert Group on AI, 2019, p. 12)\n"
  Sources:
  - recnCULdYQ36cpZR7
  Strategies:
  - recNHvwgyFPXERuJ8
  - recdtW2BdWmY6WSP5
  - recEHwRaLD44KPk8v
  - rec81gtnlFS5W2BBF
  airtable_createdTime: '2023-05-25T18:05:56.000Z'
  airtable_id: recQEiU22Qy1E0YuA
  equivalentTo:
  - recKdujFoPJr4ZAhZ
  - rec6tz9Phzck0hvT8
  title: Respect for human autonomy
- Description: "\u201CHuman beings should remain free to make life decisions for themselves.\
    \ This entails freedom from sovereign intrusion, but also requires intervention\
    \ from government and non-governmental organisations to ensure that individuals\
    \ or people at risk of exclusion have equal access to AI\u2019s benefits and opportunities.\
    \ In an AI context, freedom of the individual for instance requires mitigation\
    \ of (in)direct illegitimate coercion, threats to mental autonomy and mental health,\
    \ unjustified surveillance, deception and unfair manipulation. In fact, freedom\
    \ of the individual means a commitment to enabling individuals to wield even higher\
    \ control over their lives, including (among other rights) protection of the freedom\
    \ to conduct a business, the freedom of the arts and science, freedom of expression,\
    \ the right to private life and privacy, and freedom of assembly and association\u201D\
    \ (High-Level Expert Group on AI, 2019, p. 10)\n"
  Sources:
  - recnCULdYQ36cpZR7
  airtable_createdTime: '2023-05-25T18:03:04.000Z'
  airtable_id: recRBt2kSianfxfwe
  equivalentTo:
  - recKdujFoPJr4ZAhZ
  title: Freedom of the individual
- Description: "\u201CHuman dignity encompasses the idea that every human being possesses\
    \ an \u201Cintrinsic worth\u201D, which should never be diminished, compromised\
    \ or repressed by others \u2013 nor by new technologies like AI systems.19 In\
    \ this context, respect for human dignity entails that all people are treated\
    \ with respect due to them as moral subjects, rather than merely as objects to\
    \ be sifted, sorted, scored, herded, conditioned or manipulated. AI systems should\
    \ hence be developed in a manner that respects, serves and protects humans\u2019\
    \ physical and mental integrity, personal and cultural sense of identity, and\
    \ satisfaction of their essential needs.20\u201D (High-Level Expert Group on AI,\
    \ 2019, p. 10)\n"
  Sources:
  - recnCULdYQ36cpZR7
  airtable_createdTime: '2023-05-25T18:01:03.000Z'
  airtable_id: recRbUmCzD09d6KZS
  equivalentTo:
  - recLHILkx2JDFsLbX
  title: Respect for human dignity
- Challenges:
  - recHHr97jsyNDnlsJ
  Description: "\u201CEquality, non-discrimination and solidarity - including the\
    \ rights of persons at risk of exclusion. Equal respect for the moral worth and\
    \ dignity of all human beings must be ensured. This goes beyond non-discrimination,\
    \ which tolerates the drawing of distinctions between dissimilar situations based\
    \ on objective justifications. In an AI context, equality entails that the system\u2019\
    s operations cannot generate unfairly biased outputs (e.g. the data used to train\
    \ AI systems should be as inclusive as possible, representing different population\
    \ groups). This also requires adequate respect for potentially vulnerable persons\
    \ and groups,21 such as workers, women, persons with disabilities, ethnic minorities,\
    \ children, consumers or others at risk of exclusion.\u201D (High-Level Expert\
    \ Group on AI, 2019, p. 11)\n"
  Sources:
  - recnCULdYQ36cpZR7
  Strategies:
  - recTjwhqfrJoaRxYo
  - recq6GeKNegFQdzS9
  airtable_createdTime: '2023-05-25T18:04:46.000Z'
  airtable_id: recScYLR2TNiv7iKf
  equivalentTo:
  - reczVPIH1y2OMpAJH
  - recKdujFoPJr4ZAhZ
  title: Equality, non-discrimination and solidarity
- Description: |
    "1.4 In research that is just:
    1. (a) taking into account the scope and objectives of the proposed research, the selection, exclusion and inclusion of categories of research participants is fair, and is accurately described in the results of the research
    2. (b) the process of recruiting participants is fair
    3. (c) there is no unfair burden of participation in research on particular groups
    4. (d) there is fair distribution of the benefits of participation in research
    5. (e) there is no exploitation of participants in the conduct of research
    6. (f) there is fair access to the benefits of research.
    1.5 Research outcomes should be made accessible to research participants in a way that is timely and clear." (NS 1.4-1.5)
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recJQF6QfQGlcSzDm
  - recnFHf9V2VtAVJMx
  - recq6GeKNegFQdzS9
  - reccAKmFQRH7IiuJi
  airtable_createdTime: '2023-05-18T14:26:19.000Z'
  airtable_id: recSqx6wklVpDzx3s
  equivalentTo:
  - recZToVrPeFlFq0Aw
  title: Justice
- Description: |
    "A/IS can be an enormous force for good in society provided they are designed to respect human rights, align with human values, and holistically increase well-being while empowering as many people as possible. They should also be designed to safeguard our environment and natural resources. These values should guide policy makers as well as engineers, designers, and developers. Advances in A/IS should be in the service of all people, rather than benefiting solely small groups, a single nation, or a corporation." p.7
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:26:10.000Z'
  airtable_id: recSwTdeEk6XbEgXU
  equivalentTo:
  - recLHILkx2JDFsLbX
  - recImuZ3T4iDiNP2B
  - reckb3cgfeDh1EeUP
  title: 'Pillar of the Ethically Aligned Design Conceptual Framework: Universal Human
    Values'
- Description: "\u201CCitizens benefit from a wide array of rights, including the\
    \ right to vote, the right to good administration or access to public documents,\
    \ and the right to petition the administration. AI systems offer substantial potential\
    \ to improve the scale and efficiency of government in the provision of public\
    \ goods and services to society. At the same time, citizens\u2019 rights could\
    \ also be negatively impacted by AI systems and should be safeguarded. When the\
    \ term \u201Ccitizens\u2019 rights\u201D is used here, this is not to deny or\
    \ neglect the rights of third-country nationals and irregular (or illegal) persons\
    \ in the EU who also have rights under international law, and \u2013 therefore\
    \ in the area of AI systems.\u201D (High-Level Expert Group on AI, 2019, p. 11)\n"
  Sources:
  - recnCULdYQ36cpZR7
  airtable_createdTime: '2023-05-25T18:05:21.000Z'
  airtable_id: recTLqwMltPHHQDxH
  title: Citizens' rights
- Challenges:
  - recCpTJXuuowqsqQa
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recobVSYWj9jYvbgF
  - recY9yr9vYcOAUSEA
  - rec3q0xKZABgZf9Dg
  - rec09f7Nm4RTf6WjE
  - rec03QV2RUJkP3dfo
  - recspvYTySr0ANH6j
  - recEHwRaLD44KPk8v
  - recQPwyiQbPcN0G47
  airtable_createdTime: '2023-05-18T14:19:44.000Z'
  airtable_id: recU6u0AZbcNj1ik9
  childOf:
  - recKdujFoPJr4ZAhZ
  title: Agency (including respect for views, opportunity to be heard (participation,
    input into research, fair representation)
- Cases:
  - recrVkbG0XGe2Ca0v
  - recSXcY4cnofb4zTP
  - recskjpMFnQ0emSKI
  - recAlOHJhEy5nDwA6
  Description: "\u201CPrivacy and data governance including respect for privacy, quality\
    \ and integrity of data, and access to data.\u201D (European Commission, 2022,\
    \ p. 18)\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - recOo7Pmo4FBYcu7P
  airtable_createdTime: '2023-06-08T06:30:26.000Z'
  airtable_id: recUYS0TFpk2MhVD7
  title: Privacy and data governance
- Cases:
  - recOOmVQviRyJGvea
  - recAlOHJhEy5nDwA6
  Description: "\u201CTechnical robustness and safety including resilience to attack,\
    \ security and general safety, accuracy, reliability, and reproducibility.\u201D\
    \ (European Commission, 2022, p. 19)\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - recTWhZ88TbQLcNaQ
  airtable_createdTime: '2023-06-08T06:34:37.000Z'
  airtable_id: recWLcMWDPE9Fd1pE
  title: Technical robustness and safety
- Description: "**A/IS shall be created and operated to provide an unambiguous rationale\
    \ for decisions made.**\n## Background\nThe programming, output, and purpose of\
    \ A/IS are often not discernible by the general public. Based on the cultural\
    \ context, application, and use of A/IS, people and institutions need clarity\
    \ around the manufacture and deployment of these systems to establish responsibility\
    \ and accountability, and to avoid potential harm. Additionally, manufacturers\
    \ of these systems must be accountable in order to address legal issues of culpability.\
    \ It should, if necessary, be possible to apportion culpability among responsible\
    \ creators (designers and manufacturers) and operators to avoid confusion or fear\
    \ within the general public.\nAccountability and partial accountability are not\
    \ possible without transparency, thus this principle is closely linked with Principle\
    \ 5\u2013Transparency.\n## Recommendations\nTo best address issues of responsibility\
    \ and accountability:\n1\\.\_\_\_Legislatures/courts should clarify responsibility,\
    \ culpability, liability, and accountability for\_A/IS, where possible, prior\
    \ to development and deployment so that manufacturers and users understand their\
    \ rights and obligations.\n2\\.\_\_\_Designers and developers of A/IS should remain\
    \ aware of, and take into account, the diversity of existing cultural norms among\
    \ the groups of users of these A/IS.\n3\\.\_\_\_Multi-stakeholder ecosystems including\
    \ creators, and government, civil, and commercial stakeholders, should be developed\
    \ to help establish norms where they do not exist because A/IS-oriented technology\
    \ and their impacts are too new. These ecosystems would include, but not be limited\
    \ to, representatives of civil society, law enforcement, insurers, investors,\
    \ manufacturers, engineers, lawyers, and users. The norms can mature into best\
    \ practices\_and laws.\n\_4\\.\_\_\_Systems for registration and record-keeping\
    \ should be established so that it is always possible to find out who is legally\
    \ responsible for a particular A/IS. Creators, including manufacturers, along\
    \ with operators,\_of A/IS should register key, high-level parameters, including:\n\
    \u2022\_\_\_\_\_Intended use,\n\u2022\_\_\_\_\_Training data and training environment,\_\
    if applicable,\n\u2022\_\_\_\_\_Sensors and real world data sources,\n\u2022\_\
    \_\_\_\_Algorithms,\n\u2022\_\_\_\_\_Process graphs,\n\u2022\_\_\_\_\_Model features,\
    \ at various levels,\n\u2022\_\_\_\_\_User interfaces,\n\u2022\_\_\_\_\_Actuators\
    \ and outputs, and\n\u2022\_\_\_\_\_Optimization goals, loss functions,\_and reward\
    \ functions.\n\n\u2022\_\_\_\_\_B. Shneiderman, \u201C[Human Responsibility for\
    \ Autonomous Agents,\u201D](https://ieeexplore.ieee.org/abstract/document/4136860)\
    \ _IEEE Intelligent Systems _22, no. 2, pp. 60\u201361, 2007.\n\u2022\_\_\_\_\_\
    A. Matthias, \u201C[The Responsibility Gap: Ascribing Responsibility for the Actions\
    \ of Learning Automata.\u201D](https://link.springer.com/article/10.1007%2Fs10676-004-3422-1)\
    \ _Ethics and Information Technology _6, no. 3, pp. 175\u2013183, 2004.\n\u2022\
    \_\_\_\_\_A. Hevelke and J. Nida-R\xFCmelin, \u201C[Responsibility for Crashes\
    \ of Autonomous Vehicles: An Ethical Analysis,\u201D](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4430591/)\
    \ _Science and Engineering Ethics _21, no. 3, pp. 619\u2013630, 2015.\n\u2022\_\
    \_\_\_\_An example of good practice (in relation to Recommendation #3) can be\
    \ found in [Sciencewise](http://www.sciencewise-erc.org.uk/)\u2014the U.K. national\
    \ center for public dialogue in policy-making involving science and technology\
    \ issues.\n\np.29-30\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:24:44.000Z'
  airtable_id: recWlipA3L9QTydWS
  childOf:
  - recSwTdeEk6XbEgXU
  - rec9uueW1gq31CcBo
  - recuQpwelm0FwdAib
  title: Accountability
- Description: "\u201C\u2022 Treat all individuals equally and protect social equity\
    \ \u2022 Use digital technologies as an essential support for the protection of\
    \ fair and equal treatment under the law \u2022 Prioritise social welfare, public\
    \ interest, and the consideration of the social and ethical impacts of innovation\
    \ in determining the legitimacy and desirability of AI technologies \u2022 Use\
    \ AI to empower and to advance the interests and well-being of as many individuals\
    \ as possible \u2022 Think big-picture about the wider impacts of the AI technologies\
    \ you are conceiving and developing. Think about the ramifications of their effects\
    \ and externalities for others around the globe, for future generations, and for\
    \ the biosphere as a whole\u201D (Leslie, 2019, p. 11)\n"
  Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - recGS9OVQ7qAjvIYE
  - recZPU5yTmrjPXlF2
  airtable_createdTime: '2023-05-19T10:59:26.000Z'
  airtable_id: recZToVrPeFlFq0Aw
  equivalentTo:
  - recSqx6wklVpDzx3s
  title: PROTECT the priorities of social values, justice, and the public interest
- Challenges:
  - recHHr97jsyNDnlsJ
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:59:55.000Z'
  airtable_id: recZbEXiEs1AlDdn3
  childOf:
  - recZToVrPeFlFq0Aw
  title: Use digital technologies as an essential support for the protection of fair
    and equal treatment under the law
- Cases:
  - reciNqxyfUgE5XM7t
  - recmS3zSMbR3ofAR5
  Description: "\u201CDiversity, non-discrimination, and fairness including accessibility,\
    \ universal design, the avoidance of unfair bias, and stakeholder participation,\
    \ which allows use regardless of age, gender, abilities, or characteristics -\
    \ with a particular focus for students with special needs.\u201D (\\[European\
    \ Commission, 2022, p. 18]\\(zotero://select/groups/4907410/items/3BCJVLT9)) (\\\
    [pdf]\\(zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=18&annotation=WFTMSW2T))\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - rec35PeHdUmtalypk
  airtable_createdTime: '2023-06-08T06:31:50.000Z'
  airtable_id: recaMsksKInFYbnCL
  title: Diversity, non-discrimination, and fairness
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T11:00:14.000Z'
  airtable_id: recduyDUAsQdJ4EMy
  childOf:
  - recZToVrPeFlFq0Aw
  equivalentTo:
  - recNB5h9bK4gEE9uc
  title: Think big-picture about the wider impacts of the AI technologies you are
    conceiving and developing. Think about the ramifications of their effects and
    externalities for others around the globe, for future generations, and for the
    biosphere as a whole
- Challenges:
  - rec1QZHHMARBQcZoo
  Description: "**A/IS creators shall adopt increased human well-being as a primary\
    \ success criterion for development.**\n## Background\nFor A/IS technologies to\
    \ demonstrably advance benefit for humanity, we need to be able to define and\
    \ measure the benefit we wish to increase. But often the only indicators utilized\
    \ in determining success for A/IS are avoiding negative unintended consequences\
    \ and increasing productivity and economic growth for customers and society. Today,\
    \ these are largely measured by gross domestic product (GDP), profit, or consumption\
    \ levels.\nWell-being, for the purpose of _Ethically Aligned Design_, is based\
    \ on the Organization for Economic Co-operation and Development\u2019s (OECD)\
    \ [\u201DGuidelines on Measuring Subjective Well-being\u201D p](http://www.oecd.org/statistics/oecd-guidelines-on-measuring-subjective-well-being-9789264191655-en.htm)erspective\
    \ that, \u201CBeing able to measure people\u2019s quality of life is fundamental\
    \ when assessing the progress of societies.\u201D There is now widespread acknowledgement\
    \ that measuring subjective well-being is an essential part of measuring quality\
    \ of life alongside other social and economic dimensions as identified within\
    \ [Nassbaum-Sen\u2019s capability approach ](https://link.springer.com/article/10.1007/s11205-005-6518-z)whereby\
    \ well-being is objectively defined in terms of human capabilities necessary for\
    \ functioning and flourishing.\nSince modern societies will be largely constituted\
    \ of A/IS users, we believe these considerations to be relevant for A/IS creators.\
    \ A/IS technologies can be narrowly conceived from an ethical standpoint. They\
    \ can be legal, profitable, and safe in their usage, yet not positively contribute\
    \ to human and environmental well-being. This means technologies created with\
    \ the best intentions, but without considering well-being, can still have dramatic\
    \ negative consequences on people\u2019s mental health, emotions, sense of themselves,\
    \ their autonomy, their ability to achieve their goals, and other dimensions of\
    \ well-being.\n## Recommendation\nA/IS should prioritize human well-being as an\
    \ outcome in all system designs, using the best available and widely accepted\
    \ well-being metrics as their reference point.\n## Further Resources\n\u2022\_\
    \_\_\_\_IEEE P7010\u2122, [Well-being Metric for Autonomous and Intelligent Systems](https://standards.ieee.org/project/7010.html).\n\
    \u2022\_\_\_\_\_[The Measurement of Economic Performance and Social Progress n](http://www.stat.si/doc/drzstat/Stiglitz%20report.pdf)ow\
    \ commonly referred to as \u201CThe Stiglitz Report\u201D, commissioned by the\
    \ then President of the French Republic, 2009. From the report: \u201C\u2026the\
    \ time is ripe for our measurement system to shift emphasis from measuring economic\
    \ production to measuring people\u2019s well-being \u2026 emphasizing well-being\
    \ is important because there appears to be an increasing gap between the information\
    \ contained in aggregate GDP data and what counts for common people\u2019s well-being.\u201D\
    \n\u2022\_\_\_\_\_[OECD Guidelines on Measuring Subjective Well-being,](https://www.oecd-ilibrary.org/economics/oecd-guidelines-on-measuring-subjective-well-being_9789264191655-en)\
    \ 2013.\n\u2022\_\_\_\_\_[OECD Better Life Index,](http://www.oecdbetterlifeindex.org/)\
    \ 2017.\n\u2022\_\_\_\_\_[World Happiness Reports](http://worldhappiness.report/),\
    \ 2012 \u2013 2018.\n\u2022\_\_\_\_\_United Nations [Sustainable Development Goal](https://unstats.un.org/sdgs/)\
    \ (SDG) [Indicators,](https://unstats.un.org/sdgs/indicators/indicators-list/)\
    \ 2018.\n\u2022\_\_\_[Beyond GDP,](http://ec.europa.eu/environment/beyond_gdp/index_en.html)\
    \ European Commission, 2018.[ ](http://ec.europa.eu/environment/beyond_gdp/index_en.html)From\
    \ the site: \u201CThe Beyond GDP initiative is about developing indicators that\
    \ are as clear and appealing as GDP, but more inclusive of environmental and social\
    \ aspects of progress.\u201D\u2022\_\_\_\_\_[Genuine Progress Indicator,](http://dnr.maryland.gov/mdgpi/Pages/default.aspx)\
    \ State of Maryland (first developed by Redefining Progress), 2015.\n\u2022\_\_\
    \_\_\_The International Panel on Social Progress, [Social Justice, Well-Being\
    \ and Economic Organization,](https://comment.ipsp.org/chapter/chapter-8-social-justice-well-being-and-economic-organization)\
    \ 2018.\n\u2022\_\_\_\_\_R. Veenhoven, World Database of Happiness, Erasmus University\
    \ Rotterdam, The Netherlands, Accessed 2018 at: [http:// worlddatabaseofhappiness.eur.nl.](http://worlddatabaseofhappiness.eur.nl/)\n\
    Royal Government of Bhutan, [The Report of the High-Level Meeting on Wellbeing\
    \ and Happiness: Defining a New Economic Paradigm](https://sustainabledevelopment.un.org/content/documents/617BhutanReport_WEB_F.pdf),\
    \ New York: The Permanent Mission of the Kingdom of Bhutan to the United Nations,\
    \ 2012\"\np.\t23-24\n"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  airtable_createdTime: '2023-05-28T19:19:19.000Z'
  airtable_id: receFm7cGasHwpJZO
  childOf:
  - recSwTdeEk6XbEgXU
  - rec9uueW1gq31CcBo
  title: Wellbeing
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recKDgUEDD2f1egyd
  - recsAAZKwCyesrHK6
  - recpvGxQzTNQS1smH
  - rechaQXedBh3OsMjZ
  - recTWhZ88TbQLcNaQ
  airtable_createdTime: '2023-05-18T14:28:03.000Z'
  airtable_id: recgDkzdE9dfpTxCK
  childOf:
  - recOHnq45Fq7YWsRO
  title: that is designed to achieve its aims rigorously
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:59:56.000Z'
  airtable_id: recgEYKqzkCYqPmXW
  childOf:
  - recZToVrPeFlFq0Aw
  equivalentTo:
  - recNB5h9bK4gEE9uc
  title: Prioritise social welfare, public interest, and the consideration of the
    social and ethical impacts of innovation in determining the legitimacy and desirability
    of AI technologies
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T10:57:48.000Z'
  airtable_id: rechB1SCdOpa940OZ
  childOf:
  - rec7n2TGrH9RHYpQj
  title: Design and deploy AI systems to foster and to cultivate the welfare of all
    stakeholders whose interests are affected by their use
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recpvGxQzTNQS1smH
  airtable_createdTime: '2023-05-18T14:28:06.000Z'
  airtable_id: recheWZC64aZRgmpo
  childOf:
  - recOHnq45Fq7YWsRO
  title: and with suitable resources to conduct the work as proposed
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recpvGxQzTNQS1smH
  - recinajIdAe7hRxjN
  - recTWhZ88TbQLcNaQ
  airtable_createdTime: '2023-05-18T14:27:54.000Z'
  airtable_id: recint2IxoR8aILCp
  childOf:
  - recOHnq45Fq7YWsRO
  title: do research that is justifiable by potential benefit
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recY9yr9vYcOAUSEA
  - recDOGXIsqtXrCuSz
  - recsonQhKLmX4D1ao
  airtable_createdTime: '2023-05-18T14:28:05.000Z'
  airtable_id: recjViPnz3atRIOpD
  childOf:
  - recOHnq45Fq7YWsRO
  title: and that the work is carried out with suitable expertise
- Description: "\u201CAll governmental power in constitutional democracies must be\
    \ legally authorised and limited by law. AI systems should serve to maintain and\
    \ foster democratic processes and respect the plurality of values and life choices\
    \ of individuals. AI systems must not undermine democratic processes, human deliberation\
    \ or democratic voting systems. AI systems must also embed a commitment to ensure\
    \ that they do not operate in ways that undermine the foundational commitments\
    \ upon which the rule of law is founded, mandatory laws and regulation, and to\
    \ ensure due process and equality before the law.\u201D (High-Level Expert Group\
    \ on AI, 2019, p. 11)\n"
  Sources:
  - recnCULdYQ36cpZR7
  Strategies:
  - recHEUOqkzQTNsAMw
  - rec03QV2RUJkP3dfo
  - recffbHgJO0d179DG
  airtable_createdTime: '2023-05-25T18:04:04.000Z'
  airtable_id: reckb3cgfeDh1EeUP
  title: Respect for democracy, justice and the rule of law
- Description: "\u201CAI systems should neither cause nor exacerbate harm29 or otherwise\
    \ adversely affect human beings.30 This entails the protection of human dignity\
    \ as well as mental and physical integrity. AI systems and the environments in\
    \ which they operate must be safe and secure. They must be technically robust\
    \ and it should be ensured that they are not open to malicious use. Vulnerable\
    \ persons should receive greater attention and be included in the development,\
    \ deployment and use of AI systems. Particular attention must also be paid to\
    \ situations where AI systems can cause or exacerbate adverse impacts due to asymmetries\
    \ of power or information, such as between employers and employees, businesses\
    \ and consumers or governments and citizens. Preventing harm also entails consideration\
    \ of the natural environment and all living beings.\u201D (High-Level Expert Group\
    \ on AI, 2019, p. 12)\n"
  Sources:
  - recnCULdYQ36cpZR7
  Strategies:
  - rec4oGONFgYMu3JGf
  - recAMa23XxDLEzMn8
  - recBUdrJ8n1tIJLTz
  - rec95I69E1YcGg0Sa
  - recTjwhqfrJoaRxYo
  - recq6GeKNegFQdzS9
  - recaTTvWN1olqx608
  airtable_createdTime: '2023-05-25T18:06:18.000Z'
  airtable_id: reclPiw2VvNOSTzv5
  equivalentTo:
  - recmzjcGKv3yNOxbl
  title: Prevention of harm
- Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - rec0GhefNkhJqW0c2
  airtable_createdTime: '2023-05-19T09:41:35.000Z'
  airtable_id: reclur1ImQFlLyYof
  childOf:
  - rectPrYetyr4YIuq8
  title: Safeguard the integrity of interpersonal dialogue, meaningful human connection,
    and social cohesion
- Description: |
    "1.6 The likely benefit of the research must justify any risks of harm or discomfort to participants. The likely benefit may be to the participants, to the wider community, or to both.
    1.7 Researchers are responsible for:
    1. (a) designing the research to minimise the risks of harm or discomfort to participants
    2. (b) clarifying for participants the potential benefits and risks of the research
    3. (c) the welfare of the participants in the research context.
    1.8 Where there are no likely benefits to participants, the risk to participants should be lower than would be ethically acceptable where there are such likely benefits.
    1.9 Where the risks to participants are no longer justified by the potential benefits of the research, the research must be suspended to allow time to consider whether it should be discontinued or at least modified. This decision may require consultation between researchers, participants, the relevant ethical review body, and the institution. The review body must be notified promptly of such suspension, and of any decisions following it (see paragraphs 5.5.7 to 5.5.10)." (NS 1.6-1.9)
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - rec0GhefNkhJqW0c2
  - recGS9OVQ7qAjvIYE
  - recAnT7HDpWYvdJ1V
  - recnFHf9V2VtAVJMx
  - rec8dLtyDCwvjMWge
  - rechaQXedBh3OsMjZ
  - rec7daqDHSCuc70yS
  - recRTVqtvPcBS6zps
  - recTjwhqfrJoaRxYo
  - recq6GeKNegFQdzS9
  - rec0WScLo6sUnoOQN
  - recJMrMEZnz9rYlnD
  - reccAKmFQRH7IiuJi
  airtable_createdTime: '2023-05-18T14:25:01.000Z'
  airtable_id: recmzjcGKv3yNOxbl
  equivalentTo:
  - rec7n2TGrH9RHYpQj
  - reclPiw2VvNOSTzv5
  title: Beneficence
- Cases:
  - reciNqxyfUgE5XM7t
  - recOOmVQviRyJGvea
  Description: "\u201CHuman agency and oversight including fundamental rights, children\u2019\
    s rights, human agency, and human oversight.\u201D (\\[European Commission, 2022,\
    \ p. 18]\\(zotero://select/groups/4907410/items/3BCJVLT9)) (\\[pdf]\\(zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=18&annotation=YBKGBYD4))\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - recegTm800wJXGjO1
  airtable_createdTime: '2023-06-08T06:32:23.000Z'
  airtable_id: reco4DUa3rsjP0hyg
  title: Human agency and oversight
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:41:37.000Z'
  airtable_id: recoXK4tOGqoh2nE3
  childOf:
  - rectPrYetyr4YIuq8
  title: Encourage all voices to be heard and all opinions to be weighed seriously
    and sincerely throughout the production and use lifecycle
- Cases:
  - recrVkbG0XGe2Ca0v
  - recAlOHJhEy5nDwA6
  Description: "\u201CSocietal and environmental wellbeing including sustainability\
    \ and environmental friendliness, social impact, society, and democracy.\u201D\
    \ (European Commission, 2022, p. 18)\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - rec7daqDHSCuc70yS
  airtable_createdTime: '2023-06-08T06:31:30.000Z'
  airtable_id: recqdGhz7l1cGnQeU
  title: Societal and environmental wellbeing
- Challenges:
  - recYHYaeqVHR93Kuo
  - recO1L6GoFMkA6Lt4
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recpUrzG3GpRiwqnz
  - recgWFCdfcVaeaPQO
  - reczG9x5YfScZJdCo
  - recazD3B5XpqgOCGV
  - rec09f7Nm4RTf6WjE
  airtable_createdTime: '2023-05-18T13:40:06.000Z'
  airtable_id: recsvi4LnhEEPyQ1h
  childOf:
  - recKdujFoPJr4ZAhZ
  title: Informed consent
- Description: "\u201C\u2022 Safeguard the integrity of interpersonal dialogue, meaningful\
    \ human connection, and social cohesion \u2022 Prioritise diversity, participation,\
    \ and inclusion at all points in the design, development, and deployment processes\
    \ of AI innovation. \u2022 Encourage all voices to be heard and all opinions to\
    \ be weighed seriously and sincerely throughout the production and use lifecycle\
    \ \u2022 Use the advancement and proliferation of AI technologies to strengthen\
    \ the developmentally essential relationship between interacting human beings.\
    \ \u2022 Utilise AI innovations pro-socially so as to enable bonds of interpersonal\
    \ solidarity to form and individuals to be socialised and recognised by each other\
    \ \u2022 Use AI technologies to foster this capacity to connect so as to reinforce\
    \ the edifice of trust, empathy, reciprocal responsibility, and mutual understanding\
    \ upon which all ethically wellfounded social orders rest\u201D (Leslie, 2019,\
    \ p. 10)\n"
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:39:45.000Z'
  airtable_id: rectPrYetyr4YIuq8
  equivalentTo:
  - recLHILkx2JDFsLbX
  title: CONNECT with each other sincerely, openly, and inclusively
- Description: |
    "**Technical Dependability: **Ultimately, A/IS should deliver services that can be trusted.2 This trust means that A/IS will reliably, safely, and actively accomplish the objectives for which they were designed while advancing the human-driven values they were intended to reflect. Technologies should be monitored to ensure that their operation meets predetermined ethical objectives aligning with human values and respecting codified rights. In addition, validation and verification processes, including aspects of explainability, should be developed that could lead to better auditability and to certification of A/IS" p.7
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-06-03T18:27:42.000Z'
  airtable_id: recuQpwelm0FwdAib
  equivalentTo:
  - recOHnq45Fq7YWsRO
  title: 'Pillar of the Ethically Aligned Design Conceptual Framework: Technical Dependability'
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:39:38.000Z'
  airtable_id: recv9z5lu6zZspHYA
  childOf:
  - recImuZ3T4iDiNP2B
  equivalentTo:
  - recU6u0AZbcNj1ik9
  title: Support their abilities to flourish, to fully develop themselves, and to
    pursue their passions and talents according to their own freely determined life
    plans
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:42:38.000Z'
  airtable_id: recvLGtdSLYOV3Azw
  childOf:
  - rectPrYetyr4YIuq8
  title: Utilise AI innovations pro-socially so as to enable bonds of interpersonal
    solidarity to form and individuals to be socialised and recognised by each other
- Cases:
  - reciNqxyfUgE5XM7t
  - recmS3zSMbR3ofAR5
  Description: "\u201CTransparency including traceability, explainability and communication.\u201D\
    \ (\\[European Commission, 2022, p. 18]\\(zotero://select/groups/4907410/items/3BCJVLT9))\
    \ (\\[pdf]\\(zotero://open-pdf/groups/4907410/items/6A6DKVJ2?page=18&annotation=GKNH3GVZ))\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - rechaQXedBh3OsMjZ
  airtable_createdTime: '2023-06-08T06:32:12.000Z'
  airtable_id: recwjv8IMAZFWfMSr
  title: Transparency
- Description: "\"**A/IS shall be created and operated to respect, promote, and protect\
    \ internationally recognized human rights.**\n## Background\nHuman benefit is\
    \ a crucial goal of A/IS, as is respect for human rights set out in works including,\
    \ but not limited to: [The](http://www.un.org/en/universal-declaration-human-rights/)\
    \ [Universal Declaration of Human Rights,](http://www.un.org/en/universal-declaration-human-rights/)\
    \ the [International Covenant on Civil and Political Rights,](http://www.ohchr.org/en/professionalinterest/pages/ccpr.aspx)\
    \ the [Convention on the Rights of the Child,](http://www.ohchr.org/en/professionalinterest/pages/crc.aspx)\
    \ the [Convention on the Elimination of all forms of Discrimination against Women,](http://www.un.org/womenwatch/daw/cedaw/)\
    \ the [Convention on the Rights of Persons with Disabilities,](https://www.un.org/development/desa/disabilities/convention-on-the-rights-of-persons-with-disabilities.html)\
    \ and the [Geneva Conventions.](https://www.icrc.org/en/war-and-law/treaties-customary-law/geneva-conventions)\n\
    Such rights need to be fully taken into consideration by individuals, companies,\
    \ professional bodies, research institutions, and governments alike to reflect\
    \ the principle that\_A/IS should be designed and operated in a way that both\
    \ respects and fulfills human rights, freedoms, human dignity, and cultural diversity.\n\
    \    \nWhile their interpretation may change over time, \u201Chuman rights\u201D\
    , as defined by international law, provide a unilateral basis for creating any\
    \ A/IS, as these systems affect humans, their emotions, data, or agency. While\
    \ the direct coding of human rights in A/IS may be difficult or impossible based\
    \ on contextual use, newer guidelines from The United Nations provide methods\
    \ to pragmatically implement human rights ideals within business or corporate\
    \ contexts that could be adapted for engineers and technologists. In this way,\
    \ technologists can take into account human rights in the way A/IS are developed,\
    \ operated, tested, and validated. In short, human rights should be part of the\
    \ ethical risk assessment of A/IS.\n## Recommendations\nTo best respect human\
    \ rights, society must assure the safety and security of A/IS so that they are\
    \ designed and operated in a way that benefits humans. Specifically:\n\u2022\_\
    \_\_\_\_Governance frameworks, including standards and regulatory bodies, should\
    \ be established to oversee processes which ensure that the use of A/IS does not\
    \ infringe upon human rights, freedoms, dignity, and privacy, and which ensure\
    \ traceability. This will contribute to building public trust in A/IS.\n\u2022\
    \_\_\_\_\_A way to translate existing and forthcoming legal obligations into informed\
    \ policy and technical considerations is needed. Such a method should allow for\
    \ diverse cultural norms as well as differing legal and regulatory frameworks.\n\
    \u2022\_\_\_\_\_A/IS should always be subordinate to human judgment and control.\n\
    \u2022\_\_\_\_\_For the foreseeable future, A/IS should not be granted rights\
    \ and privileges equal to human rights.\n## Further Resources\nThe following documents\
    \ and organizations are provided both as references and examples of the types\
    \ of work that can be emulated, adapted, and proliferated regarding ethical best\
    \ practices around A/IS to best honor human rights:\n\u2022\_\_\_\_\_[The Universal\
    \ Declaration of Human Rights](http://www.ohchr.org/EN/UDHR/Pages/Language.aspx?LangID=eng),\
    \ 1947.\n\u2022\_\_\_\_\_N. Wiener, _The Human Use of Human Beings_, New York:\
    \ Houghton Mifflin, 1954.\n\u2022\_\_\_\_\_[The International Covenant on Civil\
    \ and Political Rights](http://www.ohchr.org/EN/ProfessionalInterest/Pages/CCPR.aspx),\
    \ 1966.\n\u2022\_\_\_\_[The International Covenant on Economic, Social and Cultural\
    \ Rights](http://www.ohchr.org/EN/ProfessionalInterest/Pages/CESCR.aspx), 1966\n\
    .\u2022\_\_\_\_\_[The International Convention on the Elimination of All Forms\
    \ of Racial Discrimination](http://www.ohchr.org/EN/ProfessionalInterest/Pages/CERD.aspx),\
    \ 1965.\n\u2022\_\_\_\_\_T[he Convention on the Rights of the Child,](http://www.ohchr.org/en/professionalinterest/pages/crc.aspx)\
    \ 1990.\n\u2022\_\_\_\_\_T[he Convention on the Elimination of All Forms of Discrimination\
    \ against Women](http://www.un.org/womenwatch/daw/cedaw/), 1979.\n\u2022\_\_\_\
    \_\_[The Convention on the Rights of Persons with Disabilities](https://www.un.org/development/desa/disabilities/convention-on-the-rights-of-persons-with-disabilities.html),\
    \ 2006.\n\u2022\_\_\_\_\_[The Geneva Conventions and Additional Protocols](https://www.icrc.org/eng/war-and-law/treaties-customary-law/geneva-conventions/overview-geneva-conventions.htm),\
    \ 1949.\n\u2022\_\_\_\_\_[IRTF\u2019s Research into Human Rights Protocol Considerations,](https://tools.ietf.org/html/draft-irtf-hrpc-research)\
    \ 2018.\n\u2022\_\_\_\_\_[The UN Guiding Principles on Business and Human Rights,\
    \ 2011.](http://www.ohchr.org/Documents/Publications/GuidingPrinciplesBusinessHR_EN.pdf)\n\
    \u2022\_\_\_\_\_British Standards Institute BS8611:2016, Robots and Robotic Devices.\
    \ [Guide to the Ethical Design and Application of Robots and ](http://shop.bsigroup.com/ProductDetail?pid=000000000030320089)Robotic\
    \ Systems\"\np.21-22\n"
  Sources:
  - recpXl48pJdKDhc6f
  airtable_createdTime: '2023-05-28T19:19:19.000Z'
  airtable_id: recxc8SQN09R985HI
  childOf:
  - recSwTdeEk6XbEgXU
  - rec9uueW1gq31CcBo
  title: Respect for human rights
- Challenges:
  - recdmBNNa98cN8Sda
  Description: "\u201CExplicability is crucial for building and maintaining users\u2019\
    \ trust in AI systems. This means that processes need to be transparent, the capabilities\
    \ and purpose of AI systems openly communicated, and decisions \u2013 to the extent\
    \ possible \u2013 explainable to those directly and indirectly affected. Without\
    \ such information, a decision cannot be duly contested. An explanation as to\
    \ why a model has generated a particular output or decision (and what combination\
    \ of input factors contributed to that) is not always possible. These cases are\
    \ referred to as \u2018black box\u2019 algorithms and require special attention.\
    \ In those circumstances, other explicability measures (e.g. traceability, auditability\
    \ and transparent communication on system capabilities) may be required, provided\
    \ that the system as a whole respects fundamental rights. The degree to which\
    \ explicability is needed is highly dependent on the context and the severity\
    \ of the consequences if that output is erroneous or otherwise inaccurate.33\u201D\
    \ (\\[High-Level Expert Group on AI, 2019, p. 13]\\(zotero://select/groups/4907410/items/XPCD8D3T))\
    \ (\\[pdf]\\(zotero://open-pdf/groups/4907410/items/CPFPH28M?page=15&annotation=J8F447TV))\n"
  Sources:
  - recnCULdYQ36cpZR7
  Strategies:
  - rec03QV2RUJkP3dfo
  - recdtW2BdWmY6WSP5
  - recEHwRaLD44KPk8v
  - reczFKqCos9f1opXO
  - recJyzFLE9ry4YEbb
  - rec81gtnlFS5W2BBF
  airtable_createdTime: '2023-05-25T18:07:49.000Z'
  airtable_id: recxcFmvPG5wrCqpO
  childOf:
  - recOHnq45Fq7YWsRO
  title: Explicability
- Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - reczG9x5YfScZJdCo
  - recTWhZ88TbQLcNaQ
  airtable_createdTime: '2023-05-18T14:28:04.000Z'
  airtable_id: recy4stJ6Y4e2Fezp
  childOf:
  - recOHnq45Fq7YWsRO
  title: and grounded in literature and prior knowledge
- Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - recKWkdYO98PeEKDz
  airtable_createdTime: '2023-05-19T10:57:55.000Z'
  airtable_id: recy6hrMpKZ7TOn3Q
  childOf:
  - rec7n2TGrH9RHYpQj
  title: Do no harm with these technologies and minimise the risks of their misuse
    or abuse
- Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T11:00:08.000Z'
  airtable_id: recyigniIRfB6DPTu
  childOf:
  - recZToVrPeFlFq0Aw
  equivalentTo:
  - recNB5h9bK4gEE9uc
  title: Use AI to empower and to advance the interests and well-being of as many
    individuals as possible
- Challenges:
  - recefglLZ3oJWw2SZ
  - recCpTJXuuowqsqQa
  - recHHr97jsyNDnlsJ
  - recKzhZVabDuYM6rG
  Sources:
  - recZRK4rseqW5VsRL
  Strategies:
  - recY9yr9vYcOAUSEA
  - recPynxbe7x5wOs5E
  - recmhwo8kmYkBZ7Sy
  - recgswAsiepwEclOd
  - recNzXJwCfbwBLmVU
  - recAhcg8OdusJvk43
  - recB7MF7TeUKH3chO
  - rec35PeHdUmtalypk
  - reciw4r1bRvx6A6Fq
  - rec7m69DQyCw3rlFg
  - recJyzFLE9ry4YEbb
  airtable_createdTime: '2023-05-18T14:20:33.000Z'
  airtable_id: reczVPIH1y2OMpAJH
  childOf:
  - recLHILkx2JDFsLbX
  title: Protection of vulnerable persons
- Cases:
  - recrVkbG0XGe2Ca0v
  - recmS3zSMbR3ofAR5
  - recSXcY4cnofb4zTP
  Description: "\u201CAccountability including auditability, minimisation and reporting\
    \ of negative impact, trade-offs, and redress. The considerations and requirements\
    \ can help educators, school leaders and technology providers to adequately assess\
    \ the impact, address the potential risks, and realise the benefits of an AI system\
    \ deployed and used in education. As such they guide the development, deployment\
    \ and use of trustworthy AI systems.\u201D (European Commission, 2022, p. 19)\n"
  Sources:
  - rec9jnxuHOioQn4DC
  Strategies:
  - recRTVqtvPcBS6zps
  airtable_createdTime: '2023-06-08T06:34:38.000Z'
  airtable_id: reczcRriFbQQpn8iX
  title: Accountability (Edu)
