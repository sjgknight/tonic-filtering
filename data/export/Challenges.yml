- Description: "Are moral and ethical boundaries crossed when the design of affective\
    \ systems allows them to develop intimate relationships with their users?\n##\
    \ Background\n There are many robots in development or production designed to\
    \ focus on intimate care of children, adults, and the elderly2. While robots capable\
    \ of participating fully in intimate relationships are not currently available,\
    \ the potential use of such robots routinely captures the attention of the media.\
    \ It is important that professional communities, policy makers, and the general\
    \ public participate in development of guidelines for appropriate use of A/IS\
    \ in this area. Those guidelines should acknowledge fundamental human rights to\
    \ highlight potential ethical benefits and risks that may emerge, if\_and when\
    \ affective systems interact intimately with users. Among the many areas of concern\
    \ are the representation of care, embodiment of caring\_A/IS, and the sensitivity\
    \ of data generated through intimate and caring relationships with\_A/IS. The\
    \ literature suggests that there are some potential benefits to individuals and\
    \ to society from the incorporation of caring A/IS, along with duly cautionary\
    \ notes concerning the possibility that these systems could negatively impact\
    \ human-to-human intimate relations3.\n## Recommendations\nAs this technology\
    \ develops, it is important to monitor research into the development of intimate\
    \ relationships between A/IS and humans. Research should emphasize any technical\
    \ and normative developments that reflect use of\_A/IS in positive and therapeutic\
    \ ways while also creating appropriate safeguards to mitigate against uses that\
    \ contribute to problematic individual or social relationships:\n1\\.\_\_\_Intimate\
    \ systems must not be designed or deployed in ways that contribute to stereotypes,\
    \ gender or racial inequality,\_or the exacerbation of human misery.\n2\\.\_\_\
    \_Intimate systems must not be designed to explicitly engage in the psychological\
    \ manipulation of the users of these systems unless the user is made aware they\
    \ are being manipulated and consents to this behavior. Any manipulation should\
    \ be governed\_through an opt-in system.\n3\\.\_\_\_Caring A/IS should be designed\
    \ to avoid contributing to user isolation from society.\_\n4\\.\_\_\_Designers\
    \ of affective robotics must publicly acknowledge, for example, within a notice\
    \ associated with the product, that these systems can have side effects, such\
    \ as interfering with the relationship dynamics between human partners, causing\
    \ attachments between the user and the A/IS that are distinct from human partnership.\n\
    5\\.\_\_Commercially marketed A/IS for caring applications should not be presented\
    \ to be a person in a legal sense, nor marketed as a person. Rather its artifactual,\
    \ that is, authored, designed, and built deliberately, nature should always be\
    \ made as transparent as possible, at least at point of sale and in available\
    \ documentation, as noted in Section 4, Systems Supporting Human Potential.6.\_\
    \_\_Existing laws regarding personal imagery need to be reconsidered in light\
    \ of caring A/IS.\_In addition to other ethical considerations, it will also be\
    \ necessary to establish conformance with local laws and mores in the context\
    \ of caring A/IS systems.\n## Further Resources\n\u2022\_\_\_\_\_M. Boden, J.\
    \ Bryson, D. Caldwell, K. Dautenhahn, L. Edwards, S. Kember, P.\nNewman, V. Parry,\
    \ G. Pegman, T. Rodden and T. Sorrell, Principles of robotics: regulating robots\
    \ in the real world. Connection Science, vol. 29, no. 2, pp. 124-129, April 2017.\n\
    \u2022\_\_\_\_\_J. J. Bryson, M. E. Diamantis, and T. D. Grant, \u201COf, For,\
    \ and By the People: The Legal Lacuna of Synthetic Persons.\u201D _Artificial\
    \ Intelligence & Law_, vol. 25, no. 3, pp. 273\u2013291, Sept. 2017.\n\u2022\_\
    \_\_\_\_M. Scheutz, \u201CThe Inherent Dangers of\nUnidirectional Emotional Bonds\
    \ between Humans and Social Robots,\u201D in _Robot Ethics: The Ethical and Social\
    \ Implications of Robotics,_ P. Lin, K. Abney, and G. Bekey, Eds., pp. 205. Cambridge,\
    \ MA: MIT Press, 2011.\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec5CFheImo8onTcd
  Tags:
  - affective-computing
  airtable_createdTime: '2023-06-05T06:05:11.000Z'
  airtable_id: rec2ULcHUjSbbSnHL
  title: How might AI deployed in care settings to foster intimate relationships impact
    on relationships among humans?
- Description: "\"Should affective systems be designed to nudge people\_for the user\u2019\
    s personal benefit and/or for the benefit of others?\n## Background\nManipulation\
    \ can be defined as an exercise of influence by one person or group, with the\
    \ intention to attempt to control or modify the actions of another person or group.\
    \ Thaler and Sunstein (2008) call the tactic of subtly modifying behavior a \u201C\
    nudge4\u201D. Nudging mainly operates through the affective elements of a human\
    \ rational system. Making use of a nudge might be considered appropriate in situations\
    \ like teaching children, treating drug dependency, and in some healthcare settings.\
    \ While nudges can be deployed to encourage individuals to express behaviors that\
    \ have community benefits, a nudge could have unanticipated consequences for people\
    \ whose backgrounds were not well considered in the development of the nudging\
    \ system5. Likewise, nudges may encourage behaviors with unanticipated long-term\
    \ effects, whether positive or negative, for the\_individual and/or society. The\
    \ effect of\_A/IS nudging a person, such as potentially eroding or encouraging\
    \ individual liberty, or expressing behaviors that are for the benefit others,\
    \ should be well characterized in the design of A/IS.\n## Recommendations\n1\\\
    .\_\_\_Systematic analyses are needed that examine the ethics and behavioral consequences\
    \ of designing affective systems to nudge human beings prior to deployment.\n\
    2\\.\_\_\_The user should be empowered, through an explicit opt-in system and\
    \ readily available, comprehensible information, to recognize different types\
    \ of A/IS nudges, regardless of whether they seek to promote beneficial social\
    \ manipulation or to enhance consumer acceptance of commercial goals. The user\
    \ should be able to access and check facts behind the nudges and then make a conscious\
    \ decision to accept or reject a nudge. Nudging systems must be transparent, with\
    \ a clear chain of accountability that includes human agents: data logging is\
    \ required so users can know how, why, and by whom they were nudged.\n3\\.\_\_\
    \_A/IS nudging must not become coercive and should always have an opt-in system\
    \ policy with explicit consent.\_\n4\\.\_\_\_Additional protections against unwanted\
    \ nudging must be put in place for vulnerable populations, such as children, or\
    \ when informed consent cannot be obtained. Protections against unwanted nudging\
    \ should be encouraged when nudges alter long-term behavior or when consent alone\
    \ may not be\_a sufficient safeguard against coercion\_or exploitation.\n5\\.\_\
    \_\_Data gathered which could reveal an individual or groups\u2019 susceptibility\
    \ to a nudge or their emotional reaction to a nudge should not be collected or\
    \ distributed without opt-in consent, and should only be retained transparently,\
    \ with access restrictions in compliance with the highest requirements of data\
    \ privacy and law.\n## Further Resources\n\u2022\_\_\_\_\_R. Thaler, and C. R.\
    \ Sunstein, _Nudge: Improving Decision about Health, Wealth and Happiness_, New\
    \ Haven, CT: Yale University Press, 2008.\n\u2022\_\_\_\_\_L. Bovens, \u201CThe\
    \ Ethics of Nudge,\u201D in _Preference change: Approaches from Philosophy, Economics\
    \ and Psychology_, T. Gr\xFCne-Yanoff and S. O. Hansson, Eds., Berlin, Germany:\
    \ Springer, 2008 pp. 207\u2013219.\n\u2022\_\_\_\_\_S. D. Hunt and S. Vitell.\
    \ \"A General Theory of Marketing Ethics.\" Journal of Macromarketing, vol.6,\
    \ no. 1, pp. 5-16, June 1986.\n\u2022\_\_\_\_\_A. McStay, [Empathic Media and\
    \ Advertising: Industry, Policy, Legal and Citizen Perspectives (the Case for\
    \ Intimacy)](http://journals.sagepub.com/doi/pdf/10.1177/2053951716666868), Big\
    \ Data & Society, pp. 1-11, December 2016.\n\u2022\_\_\_\_\_J. de Quintana Medina\
    \ and P. Hermida Justo, \u201CNot All Nudges Are Automatic: Freedom of Choice\
    \ and Informative Nudges.\u201D Working paper presented to the European Consortium\
    \ for Political Research, Joint Session of Workshops, 2016 Behavioral Change and\
    \ Public Policy, Pisa, Italy, 2016.\n\u2022\_\_\_\_\_ M. D. White, _[The Manipulation\
    \ of Choice. Ethics and Libertarian Paternalism. ](http://www.palgraveconnect.com/doifinder/10.1057/9781137313577)_New\
    \ York: Palgrave Macmillan, 2013\n\u2022\_\_\_\_\_C.R. Sunstein, The Ethics of\
    \ Influence: Government in the Age of Behavioral Science. New York: Cambridge,\
    \ 2016\n\u2022\_\_\_\_\_M. Scheutz, \u201C[The Affect Dilemma for Artificial Agents:\
    \ Should We Develop Affective Artificial Agents? ](http://ieeexplore.ieee.org/document/6296668/)\u201D\
    \ _IEEE Transactions on Affective Computing, _vol._ _3, no. 4,pp. 424\u2013433,\_\
    Sept. 2012.\n\u2022\_\_\_\_\_A. Grinbaum, R. Chatila, L. Devillers, J.G. Ganascia,\
    \ C. Tessier and M. Dauchet. \u201C[Ethics in Robotics Research: CERNA Recommendations,](http://ieeexplore.ieee.org/document/7822928/)\u201D\
    \ _IEEE Robotics and Automation Magazine, _vol._ _24, no. 3,pp. 139\u2013145,\
    \ Sept. 2017.\n\u201CDesigning Moral Technologies: Theoretical, Practical, and\
    \ Ethical Issues\u201D Conference July 10\u201315, 2016, Monte Verit\xE0, Switzerland\"\
    \n\np.96-97\n\n\"Governmental entities may potentially use nudging strategies,\
    \ for example to promote the performance of charitable acts. Does the practice\
    \ of nudging for the benefit\_of society, including nudges\_by affective systems,\
    \ raise\_ethical concerns?\n## Background\nA few scholars have noted a potentially\
    \ controversial practice of the future: allowing a robot or another affective\
    \ system to nudge a user for the good of society6. For instance, if it is possible\
    \ that a well-designed robot could effectively encourage humans to perform charitable\
    \ acts, would it be ethically appropriate for the robot to do so? This design\
    \ possibility illustrates just one behavioral outcome that a robot could potentially\
    \ elicit from a user.\nGiven the persuasive power that an affective system may\
    \ have over a user, ethical concerns related to nudging must be examined. This\
    \ includes the significant potential for misuse.\n## Recommendations\n1\\.\_\_\
    \_As more and more computing devices subtly and overtly influence human behavior,\
    \ it is important to draw attention to whether it is ethically appropriate to\
    \ pursue this type of design pathway in the context of governmental actions.\n\
    2\\.\_\_\_ There needs to be transparency regarding who the intended beneficiaries\
    \ are, and whether any form of deception or manipulation is going to be used to\
    \ accomplish the intended goal.\n## Further Resources\n\u2022\_\_\_\_\_J. Borenstein\
    \ and R. Arkin, \u201C[Robotic Nudges: Robotic Nudges: The Ethics of Engineering\
    \ a More Socially Just Human Being Just Human Being.](https://link.springer.com/article/10.1007/s11948-015-9636-2?no-access=true)\u201D\
    \ _Science and Engineering Ethics, _vol._ _22, no. 1,pp. 31\u201346, Feb. 2016.\n\
    \u2022\_\_\_\_\_J. Borenstein and R. Arkin. \u201C[Nudging for Good: Robots and\
    \ the Ethical Appropriateness of Nurturing Empathy and Charitable Behavior ](https://link.springer.com/article/10.1007/s00146-016-0684-1?no-access=true).\u201D\
    \ _AI and Society, _vol._ _32, no. 4, pp. 499\u2013507, Nov. 2016.\"\np.97-98\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec9TbOu2ZXUZG4A5
  Tags:
  - nudge-deception
  airtable_createdTime: '2023-06-05T06:13:01.000Z'
  airtable_id: rec2ajglpzbFYRivi
  title: Should affective AI nudge users for personal or societal benefit?
- Description: "\"Will extensive use of\_A/IS in society make our organizations more\
    \ brittle by reducing human autonomy within organizations, and by replacing creative,\
    \ affective, empathetic components\_of management chains?\n## Background\nIf human\
    \ workers are replaced by A/IS, the possibility of corporations, governments,\
    \ employees, and customers discovering new equilibria outside the scope of what\
    \ the organizations\u2019 past leadership originally foresaw may be unduly limited.\
    \ A lack of empathy based on shared needs, abilities, and disadvantages between\
    \ organizations and customers causes disequilibria between the individuals and\
    \ corporations and governments that exist to serve them. Opportunities for useful\
    \ innovation may therefore be lost through automation. Collaboration requires\
    \ enough commonality\_of collaborating intelligences to create empathy\u2014 the\
    \ capacity to model the other\u2019s goals based\_on one\u2019s own.\nAccording\
    \ to scientists within several fields, autonomy is a psychological need. Without\
    \ it, humans fail to thrive, create, and innovate.\nEthically aligned design should\
    \ support, not hinder, human autonomy or its expression.\n## Recommendations\n\
    1\\.\_\_\_It is important that human workers\u2019 interaction with other workers\
    \ not always be intermediated by affective systems (or other technology) which\
    \ may filter out autonomy, innovation, and communication.\n2\\.\_\_\_Human points\
    \ of contact should remain available to customers and other organizations when\
    \ using A/IS.\n3\\.\_\_\_Affective systems should be designed to support human\
    \ autonomy, sense of competence, and meaningful relationships as these are necessary\
    \ to support a flourishing life.\n4\\.\_\_\_Even where A/IS are less expensive,\
    \ more predictable, and easier to control than human employees, a core network\
    \ of human employees should be maintained at every level of decision-making in\
    \ order to ensure preservation of human autonomy, communication, and innovation.\n\
    5\\.\_\_\_Management and organizational theorists should consider appropriate\
    \ use of affective and autonomous systems to enhance their business models and\
    \ the efficacy of their workforce within the limits of the preservation of human\
    \ autonomy.\n## Further reading\n\u2022\_\_\_\_\_J. J. Bryson, \u201CArtificial\
    \ Intelligence and Pro-Social Behavior,\u201D in _Collective Agency and Cooperation\
    \ in Natural and Artificial Systems, _C. Misselhorn, Ed., pp. 281\u2013306, Springer,\
    \ 2015.\n\u2022\_\_\_\_\_D. Peters, R.A. Calvo, and R.M. Ryan,\u201C[Designing\
    \ for Motivation, Engagement and  Wellbeing in Digital Experience](https://www.frontiersin.org/articles/10.3389/fpsyg.2018.00797/full),\u201D\
    _ Frontiers in Psychology_\u2013 Human Media Interaction, vol. 9, pp 797, 2018.\"\
    \"\n\np.100-101\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recrBZOfrDC2lKpRM
  Tags:
  - human-potential
  airtable_createdTime: '2023-06-05T06:13:18.000Z'
  airtable_id: rec3Fm8dyG49YU137
  title: Will AI reduce autonomy through reducing creative, affective, and empathetic
    elements of management?
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  ChallengeInstances:
  - recpoXmwIiqv3BMWJ
  - recT8ABqanoxK9Qu0
  - recRU6VBHZccmYrln
  - recp8G9ek0g3RAnEC
  - recbjinwvxQkFttqg
  - rec3XoC08SiG83eK0
  - recg4TZqdeqZcnd1w
  - recu8eBgTi3OTRRij
  - recAZ41hiDOn9aTOl
  - recv7IjfbiXBr4A5q
  - recfGEm2rcOTFEZVZ
  Description: "**Considerations for ethical AI include clarity or accountability\
    \ regarding the purposes of technology, and its role in decision processes.**\
    \ **Clarity** underpins responsible use of technology, and **informed engagement\
    \ (and consent)** with it. **Accountability** of AI's use by humans, to humans\
    \ underpins **respect for persons**. However, achieving clarity and accountability\
    \ may be challenging where there are different levels of expertise regarding the\
    \ technology, and understandings of the contexts into which technology may be\
    \ deployed. An aim of learning environments should be to develop agency, but this\
    \ may be stymied by systems that - however accurate - may not adequately explain\
    \ decisions so they are understood to a wide range of learners, or that limit\
    \ choices for either teachers or learners.\n\nAreas of technology development\
    \ and use, as other areas of applied research, inherently involve understanding\
    \ both of the technical features of research (methods, tools, etc.), and its practical\
    \ context including stakeholders. This kind of research requires engagement of\
    \ expertise from stakeholders in the contexts into which AI will be deployed,\
    \ and of research expertise from both technical and social disciplines. This involvement\
    \ should not be siloed, instead there should be engagement across those involved.\
    \ This can be challenging given the different areas and levels of expertise each\
    \ group may have. \nUnderstanding of the ethical issues arising from research\
    \ is one area where this transdisciplinary work is important. Effective development\
    \ of AI for use in society requires a level of 'AI literacy' among stakeholders,\
    \ engagement with transparency and explanation among providers, and an understanding\
    \ of the - dynamic - social context into which any technology may be deployed.\
    \ \n\n\n\"More institutional resources and incentive structures are necessary\
    \ to bring A/IS engineers and designers into sustained and constructive contact\
    \ with ethicists, legal scholars, and social scientists, both in academia and\
    \ industry. This contact is necessary as it can enable meaningful interdisciplinary\
    \ collaboration and shape the future of technological innovation. More could be\
    \ done to develop methods, shared knowledge, and lexicons that would facilitate\_\
    such collaboration.\nThis issue relates, among other things, to funding models\
    \ as well as the lack of diversity of backgrounds and perspectives in A/IS-related\
    \ institutions and companies, which limit cross-pollination between disciplines.\
    \ To help bridge this gap, additional translation work and resource sharing, including\
    \ websites and Massive Open Online Courses (MOOCs), need to happen among technologists\
    \ and other relevant experts, e.g., in medicine, architecture, law, philosophy,\
    \ psychology, and cognitive science. Furthermore, there is a need for more cross-disciplinary\
    \ conversation and multi-disciplinary research, as is being done, for instance,\
    \ at the annual ACM Fairness, Accountability, and Transparency (FAT\\*) conference\
    \ or the work done by the Canadian Institute For Advanced Research (CIFAR), which\_\
    is developing Canada\u2019s AI strategy.\nFunding models and institutional incentive\
    \ structures should be reviewed and revised to prioritize projects with interdisciplinary\
    \ ethics components to encourage integration of ethics into projects at all levels.\n\
    ### Further Resources\n- S. Barocas, Course Material for Ethics and Policy in\
    \ Data Science, Cornell University, 2017.\n- L. Floridi, and M. Taddeo. \u201C\
    What Is Data Ethics?\u201D _Philosophical Transactions of the Royal Society, _vol._\
    \ _374, no. 2083, 1\u20134. DOI[10.1098/ rsta.2016.0360,](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124072/)\
    \ 2016.\n- S. Spiekermann, Ethical IT Innovation: A ValueBased System Design Approach.\
    \ Boca Raton, FL: Auerbach Publications, 2015.\n- K. Crawford, \u201C[Artificial\
    \ Intelligence\u2019s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1)\u201D\
    , _New York Times_, July 25, 2016. [Online]. Available: [http://www.nytimes. com/2016/06/26/opinion/sunday/artificialintelligences-white-guy-problem.html?\\\
    _r=1](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1).\
    \ [Accessed October 28, 2018].\"\np.123-124\n\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recsonQhKLmX4D1ao
  Tags:
  - research
  airtable_createdTime: '2023-06-18T14:17:02.000Z'
  airtable_id: rec3T1WLC4dg63qyI
  title: Effective use of AI inherently involves multiple stakeholder and disciplinary
    expertise, including both AI literacy and contextual awareness across cultures
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recpFE7h6QhaEpNAQ
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  Principles:
  - recLHILkx2JDFsLbX
  airtable_createdTime: '2023-05-18T14:51:53.000Z'
  airtable_id: rec5VzvnIZcaNKqDh
  title: Tyranny of averages
- Description: "**\"Issue:** Need for better\_technical documentation \n## Background\n\
    A/IS are often construed as fundamentally opaque and inscrutable. However, lack\
    \ of transparency is often the result of human decision. The problem can be traced\
    \ to a\_variety of sources, including poor documentation that excludes vital information\
    \ about the limitations and assumptions of a system.\_Better documentation combined\
    \ with\_internal and external auditing are crucial to\_understanding a system\u2019\
    s ethical impact.\n## Recommendation\nEngineers should be required to thoroughly\
    \ document the end product and related data flows, performance, limitations, and\
    \ risks of\_A/IS. Behaviors and practices that have been prominent in the engineering\
    \ processes should also be explicitly presented, as well as empirical evidence\
    \ of compliance and methodology used, such as training data used in predictive\
    \ systems, algorithms and components used, and results of behavior monitoring.\
    \ Criteria for such documentation could be: auditability, accessibility, meaningfulness,\
    \ and readability.\nCompanies should make their systems auditable and should explore\
    \ novel methods for external and internal auditing.\_\n## Further reading\n\u2022\
    \_\_\_\_\_S. Wachter, B. Mittelstadt, and L. Floridi. \u201C[Transparent, Explainable,\
    \ and Accountable AI for Robotics](http://robotics.sciencemag.org/content/2/6/eaan6080).\u201D\
    \ _[Science Robotics, v](http://robotics.sciencemag.org/content/2/6/eaan6080)ol.\
    \ _2, no. 6, May 31, 2017. [Online]. Available: DOI: 10.1126/scirobotics.aan6080.\
    \ [Accessed Nov.\n\u2022\_\_\_\_\_S. Barocas, and A. D. Selbst, \u201C[Big Data\u2019\
    s Disparate Impact.](http://www.californialawreview.org/wp-content/uploads/2016/06/2Barocas-Selbst.pdf)\u201D\
    \ _California Law Review_ 104, 671-732, 2016.\n\u2022\_\_\_\_\_J. A. Kroll, J.\
    \ Huey, S. Barocas, E. W. Felten, J. R. Reidenberg, D. G. Robinson, and H. Yu.\
    \ \u201C[Accountable Algorithms.](https://www.pennlawreview.com/print/165-U-Pa-L-Rev-633.pdf)\u201D\
    \ _University of Pennsylvania Law Review _165, no. 1, 633\u2013 705, 2017.\n\u2022\
    \_\_\_\_\_J. M. Balkin, \u201C[Free Speech in the Algorithmic Society: Big Data,\
    \ Private Governance, and New School Speech Regulation.](https://ssrn.com/abstract%3D3038939)\u201D\
    \ _UC Davis Law Review_, 2017.\"\n\np.135\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec81gtnlFS5W2BBF
  Tags:
  - corporate-ethics
  airtable_createdTime: '2023-06-05T10:57:55.000Z'
  airtable_id: rec9Cuz3HWc9lWW23
  title: How do we ensure assumptions and limitations are clear in technical documentation?
- Description: "\"How can A/IS creators incorporate well-being into\_their work?\n\
    ## Background\nWithout practical ways of incorporating well-being metrics to guide,\
    \ measure, and monitor impact, A/IS will likely lack fall short of its potential\
    \ to avoid harm and promote well-being. Incorporating well-being thinking into\
    \ typical organizational processes of design, prototyping, marketing, etc., suggests\
    \ a variety of adaptations.\nOrganizations and A/IS creators should consider clearly\
    \ defining the type of A/IS product or service that they are developing, including\
    \ articulating its intended stakeholders and uses. By defining typical uses, possible\
    \ uses, and finally unacceptable uses of the technology, creators will help to\
    \ spell out the context of well-being. This can help to identify possible harms\
    \ and risks given the different possible uses and end users, as well as intended\
    \ and unintended positive consequences.\nAdditionally, internal and external stakeholders\
    \ should be extensively consulted to ensure that impacts are thoroughly considered\
    \ through an iterative and learning stakeholder engagement process. After consultation,\
    \ A/IS creators should select appropriate well-being indicators based on the possible\
    \ scope and impact of their A/IS product or service. These well-being indicators\
    \ can be drawn from mainstream sources and models and adapted as necessary. They\
    \ can be used to engage in pre-assessment of the intended user population, projection\
    \ of possible impacts, and post-assessment. Development of a well-being indicator\
    \ measurement plan and relevant data infrastructure will support a robust integration\
    \ of well-being. A/IS models can also be trained to explicitly include well-being\
    \ indicators as subgoals.\nData and discussions on well-being impacts can be used\
    \ to suggest improvements and modifications to existing A/IS products and services\
    \ throughout their lifecycle. For example, a [team](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)\
    \ [seeking to increase the well-being o](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)f\
    \ people using wheelchairs found that when provided the opportunity to use a smart\
    \ wheelchair, some users were delighted with the opportunity for more mobility,\
    \ while others felt it would decrease their opportunities for social contact,\
    \ increase their sense of isolation, and lead to an overall decrease in their\
    \ well-being. Therefore, even though a product modification may increase well-being\
    \ according to one indicator or set of A/IS stakeholders, it does not mean that\
    \ this modification should automatically be adopted.\nFinally, organizational\
    \ processes can be modified to incorporate the above strategies. Appointment of\
    \ an organizational lead person for well-being impacts, e.g., a well-being lead,\
    \ ombudsman,\_or officer can help to facilitate this effort.\n## Recommendation\n\
    A/IS creators should adjust their existing development, marketing, and assessment\
    \ cycles to incorporate well-being concerns throughout their processes. This includes\
    \ identification of an A/IS lead ombudsperson or officer; identification of stakeholders\
    \ and end users; determination of possible uses, harm and risk assessment; robust\
    \ stakeholder engagement; selection of well-being indicators; development of a\
    \ well-being indicator measurement plan; and ongoing improvement of A/IS products\
    \ and services throughout the lifecycle.\n## Further Resources\n\u2022\_\_\_\_\
    \_[Peter Senge and the Learning Organization](http://infed.org/mobi/peter-senge-and-the-learning-organization/)[\
    \ -](https://api.ag.purdue.edu/api/depotws/File.ashx?t=f&i=11736)\n(synopsis)\
    \ Purdue University\n\u2022\_\_\_\_\_Stakeholder Engagement: A Good Practice Handbook\
    \ for Companies Doing Business in Emerging Markets. International Finance Corporation,\
    \ May 2007.\n\u2022\_\_\_\_\_[Global Reporting Initiative](https://www.globalreporting.org/Pages/default.aspx)\n\
    \u2022\_\_\_\_\_ [GNH Certification](http://www.bhutanstudies.org.bt/gnh-certification/),\
    \ Centre for Bhutan\_and GNH Studies, 2018.\u2022\_\_\_\_\_J. Helliwell, R. Layard,\
    \ and J. Sachs, Eds., \u201CThe Objective Benefits of Subjective Well-Being,\u201D\
    \ in [World Happiness Report ](http://worldhappiness.report/ed/2013/)2013. New\
    \ York: UN Sustainable Development Solutions Network, pp. 54-79, 2013.\n\u2022\
    \_\_\_\_\_[Global Happiness and Well-being Policy Report](http://www.happinesscouncil.org/)\
    \ by the Global Happiness Council, 2018.\"\n\np.78-79\n"
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  - recfcXzM3foqFNNGN
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:53:34.000Z'
  airtable_id: recA7Kh502s4UKWGo
  title: How do we incorporate wellbeing considerations into AI impact measurement
    and monitoring?
- Cases:
  - recSXcY4cnofb4zTP
  ChallengeInstances:
  - recHHvfADKIkX9idP
  - rec284Ax8lKHt4ljQ
  - recfjoQZIVhT0C5pW
  - recTaaKAtPIfbenZv
  - recVGVVfuoL5sr3oo
  - recI3S7M3KOMg2C4m
  Description: "Privacy and confidentiality expectations are bound up in cultural\
    \ norms, and other aspects of particular contexts, with emerging challenges regarding\
    \ potential for re-identification of participant data. \nData quality, integrity,\
    \ and governance are a consideration of respect for persons. \n- **Data quality\
    \ **represents the reliability and validity of the data, key features in respecting\
    \ persons through how we represent them. \n- **Data integrity **represents the\
    \ security of the data from manipulation or corruption, ensuring data can be used\
    \ for its purpose.\n\n\u201CThreats to privacy are posed by AI systems both as\
    \ a result of their design and development processes, and as a result of their\
    \ deployment. As AI projects are anchored in the structuring and processing of\
    \ data, the development of AI technologies will frequently involve the utilisation\
    \ of personal data. This data is sometimes captured and extracted without gaining\
    \ the proper consent of the data subject or is handled in a way that reveals (or\
    \ places under risk the revelation of) personal information. On the deployment\
    \ end, AI systems that target, profile, or nudge data subjects without their knowledge\
    \ or consent could in some circumstances be interpreted as infringing upon their\
    \ ability to lead a private life in which they are able to intentionally manage\
    \ the transformative effects of the technologies that influence and shape their\
    \ development. This sort of privacy invasion can consequently harm a person\u2019\
    s more basic right to pursue their goals and life plans free from unchosen influence.\u201D\
    \ (Leslie, 2019, p. 5) \n"
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  Principles:
  - recPg7Ov0priGGtLm
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-05-18T19:10:38.000Z'
  airtable_id: recBc3GCNokDL220T
  title: 'Privacy, confidentiality, data integrity and cultural norms '
- OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  - recLHILkx2JDFsLbX
  - recmzjcGKv3yNOxbl
  Principles:
  - recU6u0AZbcNj1ik9
  - reczVPIH1y2OMpAJH
  - rec42P8U9usfYCtv9
  Tags:
  - AI
  airtable_createdTime: '2023-05-18T13:41:32.000Z'
  airtable_id: recCpTJXuuowqsqQa
  title: Incidental findings
- Description: "\"How can A/IS creators influence A/IS goals to ensure well-being,\
    \ and what can A/IS creators learn or borrow from existing models in the well-being\
    \ and other arenas?\n## Background\nAnother way to incorporate considerations\
    \ of well-being is to include well-being measures\_in the development, goal setting,\
    \ and training\_of the A/IS systems themselves.\nIdentified metrics of well-being\
    \ could be formulated as auxiliary objectives of the A/IS. As these auxiliary\
    \ well-being objectives will be only a subset of the intended goals of the system,\
    \ the architecture will need to balance multiple objectives. Each of these auxiliary\
    \ objectives may be expressed as a goal, set of rules, set of values, or as a\
    \ set of preferences, which can be weighted and combined using established methodologies\
    \ from intelligent systems engineering.\_\nFor example, an educational A/IS tool\
    \ could not only optimize learning outcomes, but also incorporate measures of\
    \ student social and emotional education, learning, and thriving.\nA/IS-related\
    \ data relates both to the individual\u2014 through personalized algorithms, in\
    \ conjunction with affective sensors measuring and influencing emotion, and other\
    \ aspects of individual well-being \u2014and to society as large data sets representing\
    \ aggregate individual subjective and objective data. As the exchange of this\
    \ data becomes more widely available via establishing tracking methodologies,\
    \ the data can be aligned within A/IS products and services to increase human\
    \ well-being. For example, robots like [Pepper](https://www.sbs.com.au/news/dateline/article/2017/04/11/love-intimacy-and-companionship-tale-robots-japan)\
    \ are equipped to share data regarding their usage and interaction with humans\
    \ to the cloud. This allows almost instantaneous innovation, as once an action\
    \ is validated as useful for one Pepper robot, all other Pepper units (and ostensibly\
    \ their owners) benefit as well. As long as this data exchange happens with the\
    \ predetermined consent of the robots\u2019 owners, this innovation in real time\
    \ model can be emulated for the large-scale aggregation of information relating\
    \ to existing well-being metrics.\nA/IS creators can also help to operationalize\
    \ well-being metrics by providing stakeholders with reports on the expected or\
    \ actual outcomes of the A/IS and the values and objectives embedded in the systems.\
    \ This transparency will help creators, users, and third parties assess the state\
    \ of well-being produced by A/IS and make improvements in A/IS. In addition, A/IS\
    \ creators should consider allowing end users to layer on their own preferences,\
    \ such as allowing users to limit their use of an A/IS product if it leads to\
    \ increased sustained stress levels, sustained isolation, development of unhealthy\
    \ habits, or other decreases to well-being.\_\nIncorporating well-being goals\
    \ and metrics into broader organizational values and processes would support the\
    \ use of well-being metrics as there would be institutional support. A key factor\
    \ in industrial, corporate, and societal progress is cross-dissemination of concepts\
    \ and models from one industry or field to another. To date, a number of successful\
    \ concepts and models exist in the fields of sustainability, economics, industrial\
    \ design and manufacturing, architecture and urban development, and governmental\
    \ policy. These concepts and models can provide a foundation\_for building a metrics\
    \ standard and the use of wellbeing metrics by A/IS creators, from conception\
    \ and design to marketing, product updates, and improvements to the user experience.\_\
    \n## Recommendation\nCreate technical standards for representing goals, metrics,\
    \ and evaluation guidelines for well-being metrics and their precursors and components\
    \ within A/IS that include:\n\u2022\_\_\_\_\_[O](https://en.wikipedia.org/wiki/Ontology_(information_science))ntologies\
    \ for representing technological requirements.\n\u2022\_\_\_\_\_A testing framework\
    \ for validating adherence to well-being metrics and ethical principles such as\
    \ [IEEE P7010\u2122 Standards Project for Wellbeing Metric for Autonomous and\
    \ Intelligent Systems](https://standards.ieee.org/project/7010.html).\nabove as\
    \ well as others as a basis for a wellbeing metrics standard for A/IS creators.\
    \ _(See page 191, [Additional Resources: Additional Resources: Standards Development\
    \ Models and Frameworks)](https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead1e_standards_development_models_frameworks.pdf)_\n\
    \u2022\_\_\_\_\_The development of a well-being metrics standard for A/IS that\
    \ encompasses an understanding of well-being as holistic and interlinked to social,\
    \ economic, and ecological systems.\n\_\n## Further Resources\n\u2022\_\_\_\_\_\
    A.F.T Winfield, C. Blum, and W. Liu. \u201C[Towards an Ethical Robot: Internal\
    \ Models, Consequences and Ethical Action Selection](https://link.springer.com/chapter/10.1007/978-3-319-10401-0_8),\u201D\
    \ in Advances in Autonomous Robotics Systems. Springer, 2014, pp. 85\u201396\n\
    \u2022\_\_\_\_\_R. A. Calvo, and D. Peters. [Positive Computing: Technology for\
    \ Well-Being and Human Potential](https://mitpress.mit.edu/books/positive-computing)._\
    \ _Cambridge MA: MIT Press, 2014.\n\u2022\_\_\_\_\_Y. Collette, and P. Slarry.\
    \ [Multiobjective Optimization: Principles and Case Studies ](https://link.springer.com/book/10.1007%2F978-3-662-08883-8)\n\
    (Decision Engineering Series). Berlin, Germany:\nSpringer, 2004. doi: 10.1007/978-3-662-08883-8.\n\
    \u2022\_\_\_\_\_J. Greene, et al. \u201C[Embedding Ethical Principles in Collective\
    \ Decision Support Systems](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12457),\u201D\
    \ in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence_,\
    \ _4147\u20134151. Palo Alto, CA: AAAI Press, 2016.\n\u2022\_\_\_\_\_L. Li, I.\
    \ Yevseyeva, V. Basto-Fernandes, H. Trautmann, N. Jing, and M. Emmerich,\u201C\
    [Building and Using an Ontology of Preference-Based Multiobjective Evolutionary\
    \ Algorithms.](https://dl.acm.org/citation.cfm?id=3088704)\u201D In 9th International\
    \ Conference on Evolutionary Multi-Criterion Optimization\u2014Volume 10173 (EMO\
    \ O. Sch\xFCtze, M. Wiecek, Y. Jin, and C. Grimme, Eds., Vol. 10173. Springer-Verlag,\
    \ Berlin, Heidelberg, 406-421, 2017.\n\u2022\_\_\_\_\_[PositiveSocialImpact:](https://invis.io/9874GSJS6)\
    \ Empowering people, organizations and planet with information and knowledge to\
    \ make a positive impact to sustainable development, 2017.\n\u2022\_\_\_\_\_D.K.\
    \ Ura, Bhutan\u2019s [Gross National Happiness Policy Screening Tool](http://www.grossnationalhappiness.com/docs/GNH/PDFs/PoliSTools.pdf).\n\
    \"\np.79-81\n"
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:54:42.000Z'
  airtable_id: recGRpoF7DA23ODSj
  title: How do we incorporate wellbeing considerations into AI design/development/use?
- ChallengeInstances:
  - recX9rdsAGiONXTVd
  - recQWEzfzmzmfstG9
  - recsYgGzgIK80qUCT
  - recQmyVULN0OuFA2s
  - recQtuMpX4WaAoHhG
  - rec5l10QTYprjeewa
  - recJOwTAhuoamQM7C
  - recz5LeVOgbgic8Jk
  - recBfwOfoB68ghQAV
  Description: "AI and associated infrastructure has shifted relationships of researchers\
    \ and participants through greater secondary use of data, online platforms that\
    \ connect (sometimes invisibly) participants to researchers, heightened risks\
    \ of re-identification, and tools that may be used in unanticipated contexts.\
    \ \nIn some cases, research may be conducted under the auspices of 'quality improvement'\
    \ or operational research. In such cases the research is carried out to improve\
    \ existing practices within the research site; there may be alternative ethics\
    \ approval processes for such research. This kind of research has the advantage\
    \ of being located at the site of implementation. Complex power dynamics should\
    \ be considered between researchers (who may fulfil dual roles), and other stakeholders\
    \ such as teachers, students, administrators, and technology providers.\n"
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  - recLHILkx2JDFsLbX
  Principles:
  - recKdujFoPJr4ZAhZ
  - recPg7Ov0priGGtLm
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'franzke, aline shakti, Bechmann, A., Zimmer, M., Ess, C., & Association of Internet
    Researchers (AoIR). (2020). Internet Research: Ethical Guidelines 3.0 Association
    of Internet Researchers. AoIR. https://aoir.org/reports/ethics3.pdf'
  - 'Markham, A., & Buchanan, E. (2012). Ethical Decision-Making and Internet Research:
    Recommendations from the AoIR Ethics Working Committee (Version 2.0). AoIR. https://aoir.org/reports/ethics2.pdf'
  - Fedoruk, L. (2017b). Ethics in The Scholarship of Teaching and Learning. University
    of Calgary Taylor Institute for Teaching and Learning. https://taylorinstitute.ucalgary.ca/resources/ethics-scholarship-teaching-and-learning
  Sources:
  - recpXl48pJdKDhc6f
  - rec6r8OkE2Q2EdiM3
  - recQiVQ7CTC72xp6O
  - recQzldmBLByP78Uu
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:17:55.000Z'
  airtable_id: recJ6khG2kY2Tx5ae
  title: Interactions and distance between researchers and participants are central
    to research, both when proximal, and when mediated by technologies.
- Description: "\"**Issue:** The right to truthful information is key to a democratic\
    \ society and to achieving sustainable development and a more equal world, but\
    \ A/IS poses risks to this right that must be managed.\n## Background\nSocial\
    \ media have become the dominant technological infrastructure for the dissemination\
    \ of information such as news, opinion, advertising, etc., and are currently in\
    \ the vanguard of the movement toward customized/targeted information based on\
    \ user profiling that involves significant use of A/IS techniques. Analysis of\
    \ opinion polls and trends in social networks, blogs, etc., and of the emotional\
    \ response to news items can be used for the purposes of manipulation, facilitating\
    \ both the selection of news that guides public opinion in the desired direction\
    \ and the practice of sensationalism.\nThe \"personalization of the consumer experience\"\
    , that is, the adaptation of articles to the interests, political vision, cultural\
    \ level, education, and geographic location of the reader, is a new challenge\
    \ for the journalism profession that expands the possibilities of manipulation.\n\
    The information infrastructure is currently lacking in transparency, such that\
    \ it is difficult or impossible to know (except perhaps for the infrastructure\
    \ operator):\n\u2022\_\_\_\_\_what private information is being collected for\n\
    user profiling and by whom,\n\u2022\_\_\_\_\_which groups are targeted and by\
    \ whom,\n\u2022\_\_\_\_\_what information has been received by any given targeted\
    \ group,\n\u2022\_\_\_\_\_who financed the creation and dissemination of this\
    \ information,\n\u2022\_\_\_\_\_the percentage of the information being disseminated\
    \ by bots, and\n\u2022\_\_\_\_\_who is financing these bots.\nMany actors have\
    \ found this opaque infrastructure ideal for spreading politically motivated disinformation,\
    \ which has a negative effect on the creation of a more equal world, democracy,\
    \ and the respect for fundamental rights. This disinformation can have tragic\
    \ consequences. For instance, human rights groups have unearthed evidence that\
    \ the military authorities of Myanmar used Facebook for inciting hatred against\
    \ the Rohingya Muslim minority, hatred which facilitated an ethnic cleansing campaign\
    \ and the murder of up to 50,000 people.14 The UN determined that these actions\
    \ constituted genocide, crimes against humanity, and war crimes.15\n## Recommendations\n\
    To protect democracy, respect fundamental rights, and promote sustainable development,\
    \ governments should implement a legislative agenda which prevents the spread\
    \ of misinformation and hate speech, by:\n\u2022\_\_\_\_\_Ensuring more control\
    \ and transparency in the use of A/IS techniques for user profiling in order to\
    \ protect privacy and prevent user manipulation.\n\u2022\_\_\_\_\_Using A/IS techniques\
    \ to detect untruthful information circulating in the infrastructures, overseen\
    \ by a democratic body to prevent potential censorship.\n\u2022\_\_\_\_\_Obliging\
    \ companies owning A/IS infrastructures to provide more transparency regarding\
    \ their algorithms, sources of funding, services, and clients.\n\u2022\_\_\_\_\
    \_Defining a new legal status somewhere between \"platforms\" and \"content providers\"\
    \ for A/IS infrastructures.\n\u2022\_\_\_\_\_ Reformulating the deontological\
    \ codes of the journalistic profession to take into account the intensive use\
    \ of A/IS techniques foreseen\_in the future. \u2022\_\_\_\_\_Promoting the right\
    \ to information in official documents, and developing A/IS techniques to automate\
    \ journalistic tasks such as verification of sources and checking the accuracy\
    \ of the information in official documents, or in the selection, hierarchy, assessment,\
    \ and development of news, thereby contributing to objectivity and reliability.\n\
    ## Further Resources\n\u2022\_\_\_\_\_M. Broussard, \u201CArtificial Iintelligence\
    \ for Investigative Reporting: Using an expert system to enhance journalists\u2019\
    \ ability to discover original public affairs stories.\u201D Digital Journalism,\
    \ vol. 3, no. 6, pp. 814-831, 2015.\n\u2022\_\_\_\_\_M. Carlson, \u201CThe robotic\
    \ reporter: Automated journalism and the redefinition of labor, compositional\
    \ forms, and journalistic authority.\u201D Digital Journalism, vol. 3, no. 3,\
    \ pp. 416-431, 2015.\n\u2022\_\_\_\_\_A. L\xF3pez Barriuso, F. de la Prieta Pintado,\
    \ \xC1. Lozano Murciego, , D. Hern\xE1ndez de la Iglesia and J. Revuelta Herrero,\
    \ JOUR-MAS: A Multiagent System Approach to Help Journalism Management, vol. 4,\
    \ no. 4, 2015.\n\u2022\_\_\_\_\_P. Mozur, \u201DA Genocide Incited on Facebook\
    \ with Posts from Myanmar\u2019s Military,\u201D _The New York Times,_ Oct. 15\
    \ 2018. [https:// www.nytimes.com/2018/10/15/technology/ myanmar-faceboo.k-genocide.html](https://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html)\n\
    \u2022\_\_\_\_\_UK Parliament, House of Commons, Digital, Culture, Media and Sport\
    \ Committee Disinformation and \u2018fake news\u2019: Interim Report, Fifth Report\
    \ of Session 2017\u201319UK Parliament, Published on July 29, 2018\"\np.142-144\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recqJAVTtqOUfypNI
  airtable_createdTime: '2023-06-05T11:18:00.000Z'
  airtable_id: recJV8yTX0MnF3rGD
  title: AI poses risks to the right to truthful information
- Description: "\u201CBecause of their statistical basis, all ML systems have error\
    \ rates. Even though in many cases ML systems are far more accurate than human\
    \ beings, there is danger in assuming that simply because a system\u2019s predictions\
    \ are more accurate than a human\u2019s, the outcome is necessarily better. Even\
    \ if the error rate is close to zero, in a tool with millions of users, thousands\
    \ could be affected by error rates. Consider the example of Google Photos. In\
    \ 2015 Google Photos\u2019 image recognition software was found to have a terribly\
    \ prejudicial and offensive error: it was occasionally labeling photos of black\
    \ people as gorillas. Because the system used a complex ML model, engineers were\
    \ unable to figure out why this was happening. The only \u201Csolution\u201D they\
    \ could work out to this \u201Cracist\u201D ML was merely a band-aid: they removed\
    \ any monkey-related words from the list of image tags. \nNow, imagine a similar\
    \ software system used by U.S Customs and Border Patrol that photographs every\
    \ person who enters and exits the U.S. and cross-references it with a database\
    \ of photos of known or suspected criminals and terrorists. In 2016, an estimated\
    \ 75.9 million people arrived in the United States.31 Even if the facial recognition\
    \ system was 99.9% accurate, the 0.1% error rate would result in 75,900 people\
    \ being misidentified. How many of these people would be falsely identified as\
    \ wanted criminals and detained? And what would the impact be on their lives?\
    \ Conversely, how many known criminals would get away? Even relatively narrow\
    \ error rates in cases such as these can have severe consequences.\u201D (Access\
    \ Now, 2018, p. 13)\n"
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  Reference:
  - Access Now. (2018). HUMAN RIGHTS IN THE AGE OF ARTIFICIAL INTELLIGENCE. Access
    Now. https://www.accessnow.org/cms/assets/uploads/2018/11/AI-and-Human-Rights.pdf
  Sources:
  - recH8KmnURSknCr5y
  airtable_createdTime: '2023-05-29T07:17:18.000Z'
  airtable_id: recJjTMjpfE0WHSWu
  title: Accuracy paradox and the risks of false positives
- ChallengeInstances:
  - recuFqYoT6MFNqspL
  - recwl0AdKj2HLIpDB
  - rec3wCdnHy3TpLuya
  - rec4F8A2UI0uvFh3O
  - reccjN6q8gegWbrUE
  - rec16WOKdMVKAiBSJ
  - recUMRucTbQ7tySEW
  - reciceYsMfOtPdaaA
  Description: "AI has potential to have impact beyond just on the participants involved\
    \ into society, and it may not be clear what these impacts will be.\nImmediate\
    \ or proximal impacts are those experienced in the immediate context, for example\
    \ in interactions of researcher-participant groups. Indirect, long-range, and\
    \ dual-use impacts relate to the potential for:\n- secondary impacts that are\
    \ not a direct use of a tool but may relate to system changes that occur as a\
    \ result;\n- that these impacts may occur over a longer period than the immediate\
    \ context of research, which is ordinarily the context for which ethics approval\
    \ is provided\n- and that some effects may arise from unintended uses of dual-use\
    \ technologies, for example facial recognition developed for one purpose may be\
    \ used for surveillance or military purposes.\n\n**\"Issue: **A/IS are often viewed\
    \ only as having impact in market contexts, yet these technologies also have an\
    \ impact on social relations and culture.\nA/IS are expected to have an impact\
    \ beyond market domains and business models, diffusing throughout the global society.\
    \ For instance,\_A/IS have and will impact social relationships\_in a way similar\
    \ to how mobile phones changed our daily lives, reflecting directly on our culture,\
    \ customs, and language. The extent and direction of this impact is not yet clear,\
    \ but documented experience in HIC and high internet-penetration environments\
    \ of trolls, \u201Cfake news,\u201D and cyberbullying on social media offer a\
    \ cautionary tale.11 Depression, social isolation, aggression, and the dissemination\
    \ of violent behavior with damage to human relations, so extreme that, in some\
    \ cases, it has resulted in suicide, are all correlated with the internet.12 As\
    \ an example, the technology for \u201Csmart homes\u201D has been used for inflicting\
    \ domestic violence by remotely locking doors, turning off heat/AC, and otherwise\
    \ harassing a partner. This problem could be easily extended to include elder\
    \ and child abuse.13 Measures need to be developed to prevent A/IS from contributing\
    \ to the emergence or amplification of social disorders.\" (IEEE, 2019, p.141-142)\n"
  OverarchingPrinciples (from Principles):
  - recNB5h9bK4gEE9uc
  Principles:
  - recNB5h9bK4gEE9uc
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  - recK1gdkh8c01WaXx
  - rec7daqDHSCuc70yS
  Tags:
  - AI
  - indirect-impacts
  - wellbeing
  airtable_createdTime: '2023-05-18T18:54:26.000Z'
  airtable_id: recWPbL5kB1Yh5OPf
  title: Research produces both direct impact, on participants and then society, while
    also giving rise to indirect, long-range, and dual-use impacts
- Description: "**Issue:** Oversight for algorithms\n## Background\nThe algorithms\
    \ behind A/IS are not subject to consistent oversight. This lack of assessment\
    \ causes concern because end users have no account of how a certain algorithm\
    \ or system came to its conclusions. These recommendations are similar to those\
    \ made in the \u201CGeneral Principles\u201D and \u201CEmbedding Values into Autonomous\
    \ and Intelligent Systems\u201D chapters of _Ethically Aligned Design_, but here\
    \ the recommendations are used as they apply to the narrow scope of this chapter\
    \ .\n## Recommendations\nAccountability: As touched on in the General Principles\
    \ chapter of _Ethically Aligned Design_, algorithmic transparency is an issue\
    \ of concern. It is understood that specifics relating to algorithms or systems\
    \ contain intellectual property that cannot, or will not, be released to the general\
    \ public. Nonetheless, standards providing oversight of the manufacturing process\
    \ of A/IS technologies need to be created to avoid harm and negative consequences.\
    \ We can look to other technical domains, such as biomedical, civil, and aerospace\
    \ engineering, where commercial protections for proprietary technology are routinely\
    \ and effectively balanced with the need for appropriate oversight standards and\
    \ mechanisms to safeguard the public.Human rights and algorithmic impact assessments\
    \ should be explored as a meaningful way to improve the accountability of A/IS.\_\
    These need to be paired with public consultations, and the final impact\_assessments\
    \ must be made public.\n## Further Resources\n\u2022\_\_\_\_\_F. Pasquale, The\
    \ Black Box Society: The Secret Algorithms That Control Money and Information.\
    \ Cambridge, MA: Harvard University Press, 2016.\n\u2022\_\_\_\_\_R. Calo, \u201C\
    Artificial Intelligence Policy: A Primer and Roadmap,\u201D _UC Davis Law Review,_\
    \ 52: pp. 399\u2013435, 2017.\n\u2022\_\_\_\_\_ARTICLE 19. \u201CPrivacy and Freedom\
    \ of Expression in the Age of Artificial Intelligence,\u201D Privacy International,\
    \ April 2018. [Online]. Available: [https://www.article19.org/wpcontent/uploads/2018/04/Privacy-andFreedom-of-Expression-In-the-Age-of-ArtificialIntelligence-1.pdf.](https://www.article19.org/wp-content/uploads/2018/04/Privacy-and-Freedom-of-Expression-In-the-Age-of-Artificial-Intelligence-1.pdf)\
    \ [Accessed October 28, 2018].\n\np.132-133\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recJyzFLE9ry4YEbb
  Tags:
  - corporate-ethics
  airtable_createdTime: '2023-06-05T10:49:39.000Z'
  airtable_id: recX6r1O4jcsp0nIM
  title: How do we provide consistent oversight of AI to ensure they are accountable
    to end-users for any conclusions?
- Description: "\"**Issue: **A/IS are changing the nature of work, disrupting employment,\
    \ while technological change is happening too fast for existing methods of (re)training\
    \ the workforce.\n## Background\nThe current pace of technological development\
    \ will heavily influence changes in employment structure. In order to properly\
    \ prepare the workforce for such evolution, actions should be proactive and not\
    \ only reactive. The wave of automation caused by the A/IS revolution will displace\
    \ a very large share of jobs across domains and value chains. The U.S. \u201C\
    automated vehicle\u201D case study analyzed in the White House 2016 report_ Artificial\
    \ Intelligence, Automation, and the Economy _is emblematic of what is at stake:\
    \ \u201C2.2 to 3.1 million existing part- and full-time U.S. jobs are exposed\
    \ over the next two decades, although the timeline remains uncertain.\u201D18\n\
    The risk of unemployment for LMIC is more serious than for developed countries.\
    \ The industry of most LMIC is labor intensive. While labor may be cheap(er) in\
    \ LMIC economies, the ripple effects of A/IS and automation will be felt much\
    \ more than in the HIC economies. The 2016 World Bank Development Report stated\
    \ that the share of occupations susceptible to automation and A/IS is higher in\
    \ LMIC than in HIC, where such jobs have already disappeared. In addition, the\
    \ qualities which made certain jobs easy to outsource to LMIC where wages are\
    \ lower are those that may make them easy to automate.19 An offsetting factor\
    \ is the reality that many LMIC lack the communication, energy, and IT infrastructure\
    \ required to support highly automated industries.20 Notwithstanding this reality,\
    \ the World Bank estimated the automatable share of employment, unadjusted for\
    \ adoption time lag, for LMIC ranges from 85% in Ethiopia to 62% in Argentina,\
    \ compared to the OECD average of 57%.21\nIn the coming decades, the automation\
    \ wave calls for higher investment and the transformation of labor market capacity\
    \ development programs. Innovative and fair ways of funding such an investment\
    \ are required; the solutions should be designed in cooperation with the companies\
    \ benefiting from the increase of profitability, thanks to automation. This should\
    \ be done in a responsible way so that the innovation cycle is not broken, and\
    \ yet workforce capacity does not fall behind the needs of 21st century employment.\
    \ At the same time, A/IS and other digital technologies offer real potential to\
    \ innovate new approaches to job-search assistance, placement, and hiring processes\
    \ in the age of personalized services. The efficiency of matching labor supply\
    \ and demand can be tremendously enhanced by the rise of multisided platforms\
    \ and predictive analytics, provided they do not entrench discrimination.22 The\
    \ case of platforms, such as LinkedIn, for instance, with its 470 million registered\
    \ users, and online job consolidators such as indeed.com and Simply Hired, are\
    \ interesting as an evolution in hiring practices,\_at least for those able to\
    \ access the internet.\nTailored counseling and integrated retraining programs\
    \ also represent promising grounds for innovation. In addition, much will have\
    \ to be done to create fair and effective lifelong skill development/training,\
    \ infrastructures, and mechanisms capable of empowering millions of people to\
    \ viably transition jobs, sectors, and potentially locations, and to address differential\
    \ geographic impacts that exacerbate income and wealth disparities. Effectively\
    \ enabling the workforce to be more mobile\u2014physically, legally, and virtually\u2014\
    will be crucial. This implies systemic policy approaches which encompass housing,\
    \ transportation, licensing, tax incentives, and crucially in the age of A/IS,\
    \ universal broadband access, especially in rural areas of both HIC\_and LMIC.\n\
    ## Recommendations\nTo thrive in the A/IS age, workers must be provided training\
    \ in skills that improve their adaptability to rapid technological changes; programs\
    \ should be available to any worker, with special attention to the low-skilled\
    \ workforce. Those programs can be private, that is, sponsored by the employer,\
    \ or publicly and freely offered through specific public channels and government\
    \ policies, and should be available regardless of whether the worker is in between\
    \ jobs or still employed. Specific measures include:\n\u2022\_\_\_\_\_ Offering\
    \ new technical programs, possibly earlier than high school, to increase the workforce\
    \ capacity to close the skills gap and thrive in employment alongside A/IS. \u2022\
    \_\_\_\_\_Creating opportunities for apprenticeships, pilot programs, and scaling\
    \ up data-driven evidence-based solutions that increase employment and earnings.\n\
    \u2022\_\_\_\_\_Supporting new forms of public-private partnerships involving\
    \ civil society, as well as new outcome-oriented financial mechanisms, e.g., social\
    \ impact bonds, that help scale up successful innovations.\n\u2022\_\_\_\_\_Supporting\
    \ partnerships between universities, innovation labs in corporations, and governments\
    \ to research and incubate startups for A/IS graduates.23\n\u2022\_\_\_\_\_Developing\
    \ regulations to hold corporations responsible for employee retraining necessary\
    \ due to increased automation and other technological applications having impact\_\
    on the workforce.\n\u2022\_\_\_\_\_Facilitating private sector initiatives by\
    \ public policy for co-investment in training and retraining programs through\
    \ tax incentives.\n\u2022\_\_\_\_\_Establishing and resourcing public policies\
    \ that assure the survival and well-being of workers, displaced by A/IS and automation,\
    \ who cannot be retrained.\n\u2022\_\_\_\_\_Researching complementary areas, to\
    \ lay solid foundations for the transformation outlined above.\n\u2022\_\_\_\_\
    \_Requiring more policy research on the dynamics of professional transitions in\
    \ different labor market conditions.\n\u2022\_\_\_\_\_Researching the fairest\
    \ and most efficient public-private options for financing labor force transformation\
    \ due to A/IS.\n\u2022\_\_\_\_\_Developing national and regional future of work\
    \ strategies based on sound research and strategic foresight.\n## Further Resources\n\
    \u2022\_\_\_\_\_V. Cerf and D. Norfors, The People-centered Economy: The New Ecosystem\
    \ for Work. California: IIIJ Foundation, 2018.\n\u2022\_\_\_\_\_Executive Office\
    \ of the President. _Artificial Intelligence, Automation, and the Economy._ December\
    \ 20, 2016.\n\u2022\_\_\_\_\_S. Kilcarr, \u201CDefining the American Dream for\
    \ Trucking ... and the Nation, Too,\u201D _FleetOwner_, April 26, 2016.\n\u2022\
    \_\_\_\_\_M. Mason, \u201CMillions of Californians\u2019 Jobs could be Affected\
    \ by Automation\u2014a Scenario the next Governor has to Address,\u201D_Los Angeles\
    \ Times_, October 14, 2018.\n\u2022\_\_\_\_\_OECD, \u201CLabor Market Programs:\
    \ Expenditure and Participants,\u201D _OECD Employment and Labor Market Statistics\
    \ _(database), 2016.\n\u2022\_\_\_\_\_M. Vivarelli, \u201CInnovation and Employment:\
    \ ASurvey,\u201D Institute for the Study of Labor (IZA) Discussion Paper No. 2621,\
    \ February 2007.\n\"\np.147-149\n\n\"**Issue: **Analysis of the\_A/IS impact on\
    \ employment is too focused on the number and category of jobs affected, whereas\
    \ more attention should be addressed to the complexities of changing the task\
    \ content\_of jobs.\n## Background\nCurrent attention on automation and employment\
    \ tends to focus on the sheer number of jobs lost or gained. It is important to\
    \ focus the analysis on how employment structures will be changed by A/IS, rather\
    \ than solely dwelling on the number of jobs that might be impacted. For example,\
    \ rather than carrying out a task themselves, workers will need to shift to supervision\
    \ of robots performing that task. Other concerns include changes in traditional\
    \ employment structures, with an increase in flexible, contract-based temporary\
    \ jobs, without employee protection, and a shift in task composition away from\
    \ routine/repetitive and toward complex decision-making. This is in addition to\
    \ the enormous need for the aforementioned retraining. Given the extent of disruption,\
    \ workforce trends will need to measure time spent unemployed or underemployed,\
    \ labor force participation rates, and other factors beyond simple unemployment\
    \ numbers.\nThe _Future of Jobs 2018 _report of the World Economic Forum highlights:\_\
    \n\u201C...the potential of new technologies to create as well as disrupt jobs\
    \ and to improve the quality and productivity of the existing work of human employees.\
    \ Our findings indicate that, by 2022, _augmentation _of existing jobs through\
    \ technology may free up workers from the majority of data processing and information\
    \ search tasks\u2014and may also increasingly support them in high-value tasks\
    \ such as reasoning and decision-making as augmentation becomes increasingly common\
    \ over the coming years as a way to supplement and complement human labour.\n\
    The report predicts the shift in skill demand between today and 2022 will be significant\
    \ and that \u201Cproactive, strategic and targeted efforts will be needed to map\
    \ and incentivize workforce redeployment\u2026 [and therefore]... investment decisions\
    \ [on] whether to prioritize automation or augmentation and the question of whether\
    \ or not to invest in workforce reskilling.\n## Recommendations\nWhile there is\
    \ evidence that robots and automation are taking jobs away in various sectors,\
    \ a more balanced, granular, analytical, and objective treatment of A/IS impact\
    \ on the workforce is needed to effectively inform policy making and essential\
    \ workforce reskilling. Specifics to accomplish this include:\n\u2022\_\_\_\_\_\
    Creating an international and independent agency able to properly disseminate\
    \ objective statistics and inform the media, as well as the general public, about\
    \ the impact of robotics and A/IS on jobs, tax revenue, growth,26 and well-being.\n\
    \u2022\_\_\_\_\_Analyzing and disseminating data on how current task content of\
    \ jobs have changed, based on a clear assessment of the automatability of the\
    \ occupational\_description of such jobs.\n\u2022\_\_\_\_\_Promoting automation\
    \ with augmentation, as recommended in the _Future of Jobs Report 2018_ (see chart\
    \ on page 154), to maximize the benefit of A/IS to employment and meaningful work.\n\
    \u2022\_\_\_\_\_Integrating more granulated dynamic mapping of the future jobs,\
    \ tasks, activities, workplace-structures, associated work-habits, and skills\
    \ base spurred by the A/IS revolution, in order to innovate, align, and synchronize\
    \ skill development and training programs with future requirements. This workforce\
    \ mapping is needed at the macro, but also crucially at the micro, levels where\
    \ labor market programs\_are deployed.\n\u2022\_\_\_\_\_Considering both product\
    \ and process innovation, and looking at them from a global perspective in order\
    \ to understand properly the global impact of A/IS on employment.\n\u2022\_\_\_\
    \_\_Proposing mechanisms for redistribution of productivity increases and developing\
    \ an adaptation plan for the evolving labor market.\n## Further Resources\n\u2022\
    \_\_\_\_\_E. Brynjolfsson and A. McAfee. The Second Age of Machine Intelligence:\
    \ Work Progress and Prosperity in a Time of Brilliant Technologies. New York,\
    \ NY: W. W. Norton & Company, 2014.\n\u2022\_\_\_\_\_P.R. Daugherty, and H.J.\
    \ Wilson, Human + Machine: Reimagining Work in the Age of AI_. _Watertown, MA:_\
    \ _Harvard Business Review Press, 2018.\n\u2022\_\_\_\_\_International Federation\
    \ of Robotics. \u201CThe Impact of Robots on Productivity, Employment and Jobs,\u201D\
    \ A positioning paper by the International Federation of Robotics, April 2017.\n\
    \u2022\_\_\_\_\_RockEU. \u201CRobotics Coordination Action for Europe Report on\
    \ Robotics and Employment,\u201D Deliverable D3.4.1, June 30, 2016.\n\u2022\_\_\
    \_\_\_World Economic Forum, Centre for the New Economy and Society, _The Future\
    \ of Jobs 2018_, Geneva: WEF 2018.\"\n150-152\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recg2u6ZXSRiUO8uF
  airtable_createdTime: '2023-06-05T11:48:28.000Z'
  airtable_id: recb50cfuQUWDAHZW
  title: AI poses threats to labour
- Cases:
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recpFE7h6QhaEpNAQ
  Description: "\u201CMany machine learning models generate their results by operating\
    \ on high dimensional correlations that are beyond the interpretive capabilities\
    \ of human scale reasoning. In these cases, the rationale of algorithmically produced\
    \ outcomes that directly affect decision subjects remains opaque to those subjects.\
    \ While in some use cases, this lack of explainability may be acceptable, in some\
    \ applications, where the processed data could harbour traces of discrimination,\
    \ bias, inequity, or unfairness, the opaqueness of the model may be deeply problematic.\u201D\
    \ (Leslie, 2019, p. 4-5)\n"
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recOHnq45Fq7YWsRO
  - recxcFmvPG5wrCqpO
  - recKdujFoPJr4ZAhZ
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  Strategies:
  - rechaQXedBh3OsMjZ
  - rec81gtnlFS5W2BBF
  - recgn2UvSD4OhzGI4
  airtable_createdTime: '2023-05-19T09:30:45.000Z'
  airtable_id: recdmBNNa98cN8Sda
  title: Decisions with unclear grounding
- Description: "Will deployment of synthetic emotions into affective systems increase\
    \ the accessibility of A/IS? Will increased accessibility prompt unforeseen patterns\
    \ of identification with A/IS?\n## Background\nDeliberately constructed emotions\
    \ are designed to create empathy between humans and artifacts, which may be useful\
    \ or even essential for human-A/IS collaboration. Synthetic emotions\_are essential\
    \ for humans to collaborate with the\_A/IS but can also lead to failure to recognize\
    \ that synthetic emotions can be compartmentalized and even entirely removed.\
    \ Potential consequences for humans include different\npatterns of bonding, guilt,\
    \ and trust, whether between the human and A/IS or between other humans. There\
    \ is no coherent sense in which A/IS can be made to suffer emotional loss, because\
    \ any such affect, even if possible, could be avoided at the stage of engineering,\
    \ or reengineered. As such, it is not possible to allocate moral agency or responsibility\
    \ in the senses that have been developed for human emotional bonding and thus\
    \ sociality.\n## Recommendations\n1\\.\_\_\_Commercially marketed A/IS should\
    \ not be persons in a legal sense, nor marketed as persons. Rather their artifactual\
    \ (authored, designed, and built deliberately) nature should always be made as\
    \ transparent as possible, at least at point of sale and in available documentation.\n\
    2\\.\_\_\_Some systems will, due to their application, require opaqueness in some\
    \ contexts, e.g., emotional therapy. Transparency in such systems should be available\
    \ to inspection by responsible parties but may be withdrawn for operational needs.\n\
    ## Further Resources\n\u2022\_\_\_\_\_R. C. Arkin, P. Ulam and A. R. Wagner, \u201C\
    Moral Decision-making in Autonomous Systems: Enforcement, Moral Emotions, Dignity,\
    \ Trust and Deception,\u201D _Proceedings of the IEEE, _vol._ _100, no. 3, pp.\
    \ 571\u2013589, 2012.\n\u2022\_\_\_\_\_R. Arkin, M. Fujita, T. Takagi and R. Hasegawa.\
    \ \u201CAn Ethological and Emotional Basis for Human-Robot Interaction,\u201D\
    \ _Robotics and Autonomous Systems, _vol.42, no. 3\u20134, pp.191\u2013201, 2003.\n\
    \u2022\_\_\_\_\_R. C. Arkin, \u201CMoving up the Food Chain: Motivation and Emotion\
    \ in Behavior-based Robots,\u201D in _Who Needs Emotions: The Brain Meets the\
    \ Robot_, J. Fellous and M. Arbib., Eds., New York: Oxford University Press, 2005.\n\
    \u2022\_\_\_\_\_M. Boden, J. Bryson, D. Caldwell, et al. \u201CPrinciples of Robotics:\
    \ Regulating Robots in the Real World.\u201D _Connection Science, _vol. 29, no.\
    \ 2, pp. 124\u2013129, 2017.\n\u2022\_\_\_\_\_J. J Bryson, M. E. Diamantis and\
    \ T. D. Grant. \u201COf, For, and By the People: The Legal Lacuna of Synthetic\
    \ Persons,\u201D _Artificial Intelligence & Law, _vol._ _25, no. 3, pp. 273\u2013\
    291, Sept. 2017.\n\u2022\_\_\_\_\_J. Novikova, and L. Watts, \u201CTowards Artificial\
    \ Emotions to Assist Social Coordination in HRI,\u201D _International Journal\
    \ of Social Robotics, _vol._ _7, no. 1, pp. 77\u201388, 2015.\u2022\_\_\_\_\_\
    M. Scheutz, \u201CThe Affect Dilemma for Artificial Agents: Should We Develop\
    \ Affective Artificial Agents?\u201D _IEEE Transactions on Affective Computing,\
    \ _vol. 3, no. 4, pp. 424\u2013433, 2012.\n\u2022\_\_\_\_\_A. Sharkey and N. Sharkey.\
    \ \u201CChildren, the Elderly, and Interactive Robots.\u201D _IEEE Robotics &\
    \ Automation Magazine, _vol. 18, no. 1, pp. 32\u201338, 2011.\"\n\np.103-102\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Tags:
  - synthetic-emotion
  airtable_createdTime: '2023-06-05T06:51:34.000Z'
  airtable_id: recebQ2NgeBCmafoX
  title: Will 'emotional AI' increase accessibility of AI and what impact might such
    increased identification with AI have?
- Cases:
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recDAvfsflBF0WKpf
  ChallengeInstances:
  - rec7aGSPdkdUuZ42O
  - reczbN2QKYqG695ec
  - recHUlZ9OQfNwD6fg
  - recJvXzs5QMTqWzUF
  - recftbldoHqhBBcrk
  Description: "**Respect for diversity, non-discrimination, and fairness** respect\
    \ for persons includes respect for difference, non-discrimination, and fairness\
    \ in treatment of persons with particular protection for vulnerable populations.\
    \ This concern is particularly salient in the context of AI because models built\
    \ on historic data may reflect existing societal biases in a way that makes them\
    \ opaque or unaccountable. Systems should thus provide for stakeholder participation\
    \ and use regardless of their characteristics.\nNew technologies including AI\
    \ have potential for bias at multiple phases of a project (problem identification,\
    \ training data, modeling, implementation), and in multiple ways including through\
    \ use of data that reflects existing societal biases. While reinforcing existing\
    \ biases based on historic data is typically focal, the potential to create new\
    \ forms of bias should also be clear \n\u201CBecause they gain their insights\
    \ from the existing structures and dynamics of the societies they analyse, datadriven\
    \ technologies can reproduce, reinforce, and amplify the patterns of marginalisation,\
    \ inequality, and discrimination that exist in these societies. Likewise, because\
    \ many of the features, metrics, and analytic structures of the models that enable\
    \ data mining are chosen by their designers, these technologies can potentially\
    \ replicate their designers\u2019 preconceptions and biases. Finally, the data\
    \ samples used to train and test algorithmic systems can often be insufficiently\
    \ representative of the populations from which they are drawing inferences. This\
    \ creates real possibilities of biased and discriminatory outcomes, because the\
    \ data being fed into the systems is flawed from the start.\u201D (Leslie, 2019,\
    \ p. 4)\n\n### IEEE report\n\"**Issue 2: **A/IS can have biases that disadvantage\
    \ specific groups\n## Background\nEven when reflecting the full system of community\
    \ norms that was identified, A/IS may show operation biases that disadvantage\
    \ specific groups in the community or instill biases in users by reinforcing group\
    \ stereotypes. A system\u2019s bias can emerge in perception. For example, a passport\
    \ application AI rejected an Asian man\u2019s photo because it insisted his eyes\
    \ were closed (Griffiths 201651). Bias can emerge in information processing. For\
    \ instance, speech recognition systems are notoriously less accurate for female\
    \ speakers than for male speakers (Tatman 201652). System bias can affect decisions,\
    \ such as a criminal risk assessment device which overpredicts recidivism by African\
    \ Americans (Angwin et al. 201653). The system\u2019s bias can present itself\
    \ even in its own appearance and presentation: the vast majority of humanoid robots\
    \ have white \u201Cskin\u201D color and use female voices (Riek and Howard 201454).\n\
    The norm identification process detailed in Section 1 is intended to minimize\
    \ individual designers\u2019 biases because the community norms are assessed empirically.\
    \ The identification process also seeks to incorporate norms against prejudice\
    \ and discrimination. However, biases may still emerge from imperfections in the\
    \ norm identification process itself, from unrepresentative training sets for\
    \ machine learning systems, and from programmers\u2019 and designers\u2019 unconscious\
    \ assumptions. Therefore, unanticipated or undetected biases should be further\
    \ reduced by including members of diverse social groups in both the planning and\
    \ evaluation of A/IS and integrating community outreach into the evaluation process,\
    \ e.g., [DO-IT ](http://www.washington.edu/doit/)program and [RRI](http://www.orbit-rri.org/)\
    \ framework. Behavioral scientists and members of the target populations will\
    \ be particularly valuable when devising criterion tasks for system evaluation\
    \ and assessing the success of evaluating the A/IS performance on those tasks.\
    \ Such tasks would assess, for example, whether the A/IS apply norms in discriminatory\
    \ ways to different races, ethnicities, genders, ages, body shapes, or to people\
    \ who use wheelchairs\_or prosthetics, and so on.\"\np.184, IEEE, 2019\n"
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  - recmzjcGKv3yNOxbl
  Principles:
  - reczVPIH1y2OMpAJH
  - rec42P8U9usfYCtv9
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recpXl48pJdKDhc6f
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  airtable_createdTime: '2023-05-18T13:41:32.000Z'
  airtable_id: recefglLZ3oJWw2SZ
  title: Respect for diversity, non-discrimination, and fairness
- Description: "\"Will use of A/IS adversely affect human psychological and emotional\
    \ well-being in ways not otherwise foreseen?\n## Background\nA/IS may be given\
    \ unprecedented access to human culture and human spaces\u2014both physical and\
    \ intellectual. A/IS may communicate via natural language, may move with humanlike\
    \ form, and may express humanlike identity, but they are not, and should not be\
    \ regarded as, human. Incorporation of A/IS into daily life may affect human well-being\
    \ in ways not yet anticipated. Incorporation of A/IS may alter patterns of trust\
    \ and capability assessment between humans, and between humans and A/IS.\_\n##\
    \ Recommendations\n1\\.\_\_\_Vigilance and robust, interdisciplinary, on-going\
    \ research on identifying situations where\_A/IS affect human well-being, both\
    \ positively and negatively, is necessary. Evidence of correlations between the\
    \ increased use of\_A/IS and positive or negative individual or social outcomes\
    \ must be explored.\_\n2\\.\_\_\_  Design restrictions should be placed on the\
    \ systems themselves to avoid machine decisions that may alter a person\u2019\
    s life in unknown ways. Explanations should be available on demand in systems\
    \ that may affect human well-being.\n## Further Resources\n\u2022\_\_\_\_\_K.\
    \ Kamewari, M. Kato, T. Kanda, H. Ishiguro and K. Hiraki. \u201CSix-and-a-Half-Month-Old\
    \ Children Positively Attribute Goals to Human Action and to Humanoid-Robot Motion,\u201D\
    \ _Cognitive Development, _vol._ _20, no. 2, pp. 303\u2013320, 2005.\n\u2022\_\
    \_\_\_\_R.A. Calvo and D. Peters, Positive Computing: Technology for Wellbeing\
    \ and Human Potential. Cambridge, MA: MIT Press, 2014.\"\np.102\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Tags:
  - human-potential
  airtable_createdTime: '2023-06-05T06:51:31.000Z'
  airtable_id: recg7BIZZsvZ57fvV
  title: Will AI adversely affect human psychological and emotional wellbeing?
- Description: "Removal of embedded tools can cause harms through: (1) failure to\
    \ address changes that have been made that rely on the tool; and (2) failure to\
    \ adequately address the ongoing impacts a tool may have on wider systems. \n\n\
    'Removal' may mean actually taking a tool out of a context, but it could also\
    \ mean no longer supporting an existing tool, increasing resource needs resulting\
    \ in a tool becoming unaffordable (financially or otherwise), incompatabilities\
    \ with new tools, etc. \n\nAn example of the first kind of harm is e.g. a company\
    \ no longer supporting a medically implanted device for vision loss patients <https://spectrum.ieee.org/bionic-eye-obsolete>\n\
    \nAn example of the second kind of harm is the ongoing impacts from the UK Exam\
    \ moderation algorithm in 2020, which had knock-on impacts internationally even\
    \ after the algorithm itself was removed <https://dl.acm.org/doi/abs/10.1145/3531146.3533186>\
    \ \n\n"
  OverarchingPrinciples (from Principles):
  - recmzjcGKv3yNOxbl
  Principles:
  - rec42P8U9usfYCtv9
  airtable_createdTime: '2023-05-18T18:53:45.000Z'
  airtable_id: recgZrgA8K7MmIzdF
  title: Risks in removal of systems and algorithmic imprints
- OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  airtable_createdTime: '2023-05-18T18:54:44.000Z'
  airtable_id: rech9r2f3QX8ZvmkP
  title: Live A/B testing and validity towards aims
- Description: "Will A/IS nudging systems that are not fully relevant to the sociotechnical\
    \ context in which they are operating cause behaviors with adverse unintended\
    \ consequences?\n## Background\nA well-designed nudging or suggestion system will\
    \ have sophisticated enough technical capabilities for recognizing the context\
    \ in which it is applying nudging actions. Assessment of the context requires\
    \ perception of the scope or impact of the actions to be taken, the consequences\
    \ of incorrectly or incompletely applied nudges, and acknowledgement of the uncertainties\
    \ that may stem from long term consequences of a nudge7.\n## Recommendations\n\
    1\\.\_\_\_Consideration should be given to the development of a system of technical\
    \ licensing (\u201Cpermits\u201D) or other certification from governments or non-governmental\
    \ organizations (NGOs) that can aid users to understand the nudges from A/IS in\
    \ their lives.\n2\\.\_\_\_User autonomy is a key and essential consideration that\
    \ must be taken into account when addressing whether affective systems should\
    \ be permitted to nudge human beings.\n3\\.\_\_\_Design features of an affective\
    \ system that nudges human beings should include the ability to accurately distinguish\
    \ between users, including detecting characteristics such as whether the user\
    \ is an adult or a child.\n4\\.\_\_\_Affective systems with nudging strategies\
    \ should incorporate a design system of evaluation, monitoring, and control for\
    \ unintended consequences.\n## Further Resources\n\u2022\_\_\_\_\_J. Borenstein\
    \ and R. Arkin, \u201C[Robotic Nudges: ](https://link.springer.com/article/10.1007/s11948-015-9636-2?no-access=true)\n\
    [Robotic Nudges: The Ethics of Engineering a ](https://link.springer.com/article/10.1007/s11948-015-9636-2?no-access=true)\n\
    [More Socially Just Human Being Just Human Being.](https://link.springer.com/article/10.1007/s11948-015-9636-2?no-access=true)\u201D\
    \ _Science and Engineering Ethics, _vol._ _22, no. 1, pp. 31\u201346, 2016.\n\u2022\
    \_\_\_\_\_R. C. Arkin, M. Fujita, T. Takagi, and R. Hasegawa, \u201C[An Ethological\
    \ and Emotional Basis for Human- Robot Interaction.](http://www.sciencedirect.com/science/article/pii/S0921889002003755)\u201D\
    \ _Robotics and Autonomous Systems, _vol._ _42, no. 3\u20134 pp.191\u2013201,\
    \ March 2003.\n\u2022\_\_\_\_\_S. Omohundro \u201C[Autonomous Technology and the\
    \ Greater Human Good.](http://www.tandfonline.com/doi/abs/10.1080/0952813X.2014.895111?journalCode=teta20)\u201D\
    \ _Journal of Experimental and Theoretical Artificial Intelligence, vol. _26,\
    \ no. 3, pp. 303\u2013315, 2014.\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec9TbOu2ZXUZG4A5
  Tags:
  - nudge-deception
  airtable_createdTime: '2023-06-05T06:13:16.000Z'
  airtable_id: reciH69D8oIGI1p93
  title: How do we ensure AI nudges are deployed appropriately and address their target
    outcome?
- Description: "Human rights law is related to, but distinct from, the pursuit of\
    \ well-being. Incorporating a human-rights framework as an essential basis for\
    \ A/IS creators means A/IS creators honor existing law as part of their well-being\
    \ analysis and implementation.\n## Background\nInternational human rights law\
    \ has been firmly established for decades in order to protect various guarantees\
    \ and freedoms as enshrined in charters such as the United Nations\u2019[ Universal\
    \ Declaration of Human Rights ](http://www.un.org/en/universal-declaration-human-rights/)and\
    \ the Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention).\
    \ In 2018, the[ Toronto Declaration ](https://www.accessnow.org/the-toronto-declaration-protecting-the-rights-to-equality-and-non-discrimination-in-machine-learning-systems/)on\
    \ machine learning standards was released, calling on both governments and technology\
    \ companies to ensure that algorithms respect basic principles of equality and\
    \ non-discrimination. The Toronto Declaration sets forth an obligation to prevent\
    \ machine learning systems from discriminating, and in some cases violating, existing\
    \ human rights law.\nWell-being initiatives are typically undertaken for the sake\
    \ of public interest. However, any metric, including well-being metrics, can be\
    \ misused to justify human rights violations. Encampment and mistreatment of refugees\
    \ and ethnic cleansing undertaken to preserve a nation\u2019s culture (an aspect\
    \ of well-being) is one example. Imprisonment or assassination of journalists\
    \ or researchers to ensure the stability of a government is another. The use of\
    \ wellbeing metrics to justify human rights violations is an unconscionable perversion\
    \ of the nature of any well-being metric. It should be noted that these same practices\
    \ happen today in relation to GDP. For instance, in 2012, according to the [International\
    \ Labour Organization (](http://www.ilo.org/global/about-the-ilo/newsroom/news/WCMS_181961/lang--en/index.htm)ILO),\
    \ approximately 21 million people are victims of forced labor (slavery), representing\
    \ 9% to 56% of GDP income for various countries. These clear human rights violations,\
    \ from sex trafficking and use of children in armies, to indentured farming or\
    \ manufacturing labor, can increase a country\u2019s GDP while obviously harming\
    \ human well-being.\n## Recommendations\nWell-being metrics are designed to measure\
    \ the efficacy of efforts related to individual and societal flourishing. Well-being\
    \ as a value complements justice, equality, and freedom. Well-designed application\
    \ of well-being considerations by A/IS creators should not displace other issues\
    \ of human rights or ethical methodologies, but rather complement them.\nA human\
    \ rights framework should represent the floor, and not the ceiling, for the standards\
    \ to which A/IS creators must adhere. Developers and users of well-being metrics\
    \ should be aware these metrics will not always adequately address human rights.\n\
    ## Further Resources\n\u2022\_\_\_\_\_United Nations[ Universal Declaration of\
    \ Human Rights,](http://www.un.org/en/universal-declaration-human-rights/) 1948.\n\
    \u2022\_\_\_\_\_Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention),\
    \ 2018.\n\u2022\_\_\_\_\_International Labor Organization (ILO) [Declaration on\
    \ Fundamental Principles and Rights at Work,](https://www.ilo.org/declaration/lang--en/index.htm)\
    \ 1998.\n\u2022\_\_\_\_\_The regularly updated [University of Minnesota Human\
    \ Rights Library ](http://hrlibrary.umn.edu/)provides a wealth of material on\
    \ human rights laws, its history, and the organizations engaged in promoting them.\n\
    The [Oxford Human Rights Hub ](http://ohrh.law.ox.ac.uk/why-artificial-intelligence-is-already-a-human-rights-issue/)reports\
    \ on how and why technologies surrounding artificial intelligence raise human\
    \ rights issues\"\np.76-77\n"
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  - recOHnq45Fq7YWsRO
  Principles:
  - receFm7cGasHwpJZO
  - recQ9DIFEsOEkCx3O
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:47:17.000Z'
  airtable_id: reciNc7OeTUmnsLqg
  title: How do we incorporate a human-rights framework into AI design/development/use?
- Description: "**\"Issue: **Current roadmaps for development and deployment of A/IS\
    \ are not aligned with or guided by their impact in the most important challenges\
    \ of humanity, defined in the seventeen United Nations Sustainable Development\
    \ Goals (SDGs), which collectively aspire to create a more equal world of prosperity,\
    \ peace, planet protection, and human dignity\_for all people.4\n## Background\n\
    \ SDGs promoting prosperity, peace, planet protection, human dignity, and respect\
    \ for human rights of all, apply to HIC and LMIC alike. Yet ensuring that the\
    \ benefits of A/IS will accrue to humanity as a whole, leaving \u201Cno one behind\u201D\
    , requires an ethical commitment to global citizenship and well-being, and a conscious\
    \ effort to counter the nature of the tech economy, with its tendency to concentrate\
    \ wealth within high income populations. Implementation of the SDGs should benefit\
    \ excluded sectors of society in every country, regardless of A/IS infrastructure.\u201C\
    The Road to Dignity by 2030\u201D document of the UN Secretary General reports\
    \ on resources and methods for implementing the 2030 Agenda for Sustainable Development\
    \ and emphasizes the importance of science, technology, and innovation for a sustainable\
    \ future.5 The UN Secretary General posits that:\n\u201CA sustainable future will\
    \ require that we act now to phase out unsustainable technologies and to invest\
    \ in innovation and in the development of clean and sound technologies for sustainable\
    \ development. We must ensure that they are fairly priced, broadly disseminated\
    \ and fairly absorbed, including to and by developing countries.\u201D (para.\
    \ 120)\nA/IS are among the technologies that can play an important role in the\
    \ solution of the deep social problems plaguing our global civilization, contributing\
    \ to the transformation of society away from an unsustainable, unequal socioeconomic\
    \ system, towards one that realizes the vision of universal human dignity, peace,\
    \ and prosperity.\nHowever, with all the potential benefits of\_A/IS, there are\
    \ also risks. For example, given\_A/IS technology\u2019s immense power needs,\
    \ without new sources of sustainable energy harnessed to power A/IS in the future,\
    \ there is a risk that it will increase fossil fuel use and have a negative impact\
    \ on the environment and the climate.\nWhile 45% of the world\u2019s population\
    \ is not connected to the internet, they are not necessarily excluded from A/IS\u2019\
    \ potential benefits: in LMIC mobile networks can provide data for A/IS applications.\
    \ However, only those connected are likely to benefit from the income-producing\
    \ potential of internet technologies. In 2017, internet penetration in HIC left\
    \ behind certain portions of the population often in rural or remote areas; 12%\
    \ of U.S. residents and 20% of residents across Europe were unable to access the\
    \ internet. In Asia with its concentration of LMIC, 52% of the population, on\
    \ average, had no access, a statistic skewed by the large population of China,\
    \ where internet penetration reached 45% of the population. In numerous other\
    \ countries in the region, 99% of residents had no access. This nearly total exclusion\
    \ also exists in several countries in Africa, where the overall internet penetration\
    \ is only 35%: 2 of every 3 residents in Africa have no access.6 Those with no\
    \ internet access also do not generate data needed to \u201Ctrain\u201D A/IS,\
    \ and are thereby excluded from benefits of the technology, the development of\
    \ which risks systematic discriminatory bias, particularly against people from\
    \ minority populations, and those living in rural areas, or in low-income countries.\
    \ As a comparison, one study estimated that \u201Cin the US, just one home automation\
    \ product can generate a data point every six seconds.\u201D7 In Mozambique, where\
    \ about 90% of the population lack internet access, \u201Cthe average household\
    \ generates zero digital data points.\u201D8 With mobile phones generating much\
    \ of the data needed for developing A/IS applications in LMIC, unequal phone ownership\
    \ may build in bias. For example, there is a risk of discrimination against women,\
    \ who across LMIC are 14% less likely than men to own a mobile phone, and in South\
    \ Asia where 38% are less likely to own a mobile phone.9\n## Recommendations\n\
    The current range of A/IS applications in sectors crucial to the SDGs, and to\
    \ excluded populations everywhere, should be studied, with the strengths, weaknesses,\
    \ and potential of the most significant recent applications analyzed, and the\
    \ best ones developed at scale. Specific objectives to consider include:\n\u2022\
    \_\_\_\_\_Identifying and experimenting with\_A/IS technologies relevant to the\
    \ SDGs,\_such as: big data for development relevant to, for example, agriculture\
    \ and medical tele-diagnosis; geographic information systems needed in public\
    \ service planning, disaster prevention, emergency planning, and disease monitoring;\
    \ control systems used in, for example, naturalizing intelligent cities through\
    \ energy and traffic control and management of urban agriculture; applications\
    \ that promote human empathy focused on diminishing violence and exclusion and\
    \ increasing well-being.\n\u2022\_\_\_\_\_Promoting the potential role of A/IS\
    \ in sustainable development by collaboration between national and international\
    \ government agencies and non-governmental organizations (NGOs) in technology\
    \ sectors.\n\u2022\_\_\_\_\_Analyzing the cost of and proposing strategies for\
    \ publicly providing internet access for\_all, as a means of diminishing the gap\
    \ in\_A/IS\u2019 potential benefit to humanity, particularly between urban and\
    \ rural populations in HIC and LMIC alike.\n\u2022\_\_\_\_\_Investing in the documentation\
    \ and dissemination of innovative applications of\_A/IS that advance the resolution\
    \ of identified societal issues and the SDGs.\n\u2022\_\_\_\_\_Researching sustainable\
    \ energy to power A/IS computational capacity.\n\u2022\_\_\_\_\_Investing in the\
    \ development of transparent monitoring frameworks to track the concrete results\
    \ of donations by international organizations, corporations, independent agencies,\
    \ and the State, to ensure efficiency and accountability in applied A/IS.\n\u2022\
    \_\_\_\_\_Developing national legal, policy, and fiscal measures to encourage\
    \ competition in the\_A/IS domestic markets and the flourishing\_of scalable A/IS\
    \ applications.\n\u2022\_\_\_\_\_Integrating the SDGs into the core of private\
    \ sector business strategies and adding SDG indicators to companies\u2019 key\
    \ performance indicators, going beyond corporate social responsibility (CSR).\n\
    \u2022\_\_\_\_\_Applying the well-being indicators10 to evaluate A/IS\u2019 impact\
    \ from multiple perspectives in HIC and LMIC alike.\n## Further reading\n\u2022\
    \_\_\_\_\_R. Van Est and J.B.A. Gerritsen, with assistance of L. Kool, Human Rights\
    \ in the Robot Age: Challenges arising from the use of Robots, Artificial Intelligence\
    \ and Augmented Reality Expert Report written for the Committee on Culture, Science,\
    \ Education and Media of the Parliamentary Assembly of the Council of Europe (PACE),\
    \ The Hague: Rathenau Instituut 2017.\n\u2022\_\_\_\_\_World Economic Forum Global\
    \ Future Council on Human Rights 2016-18, \u201CWhite Paper: How to Prevent Discriminatory\
    \ Outcomes in Machine Learning,\u201D World Economic Forum, March 2018.\n\u2022\
    \_\_\_\_\_United Nations General Assembly, _Transforming Our World: The 2030 Agenda\
    \ for Sustainable Development_ (A/RES/70/1: 21 October 2015) Preamble. [http://www.un.org/\
    \ en/development/desa/population/migration/ generalassembly/docs/globalcompact/\
    \ A\\_RES\\_70\\_1\\_E.pdf](http://www.un.org/en/development/desa/population/migration/generalassembly/docs/globalcompact/A_RES_70_1_E.pdf).\n\
    \u2022\_\_\_\_\_United Nations Global Pulse, Big Data for Development: Challenges\
    \ and Opportunities, 2012.\"\n\np139-140\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recouZjokdKQz88z1
  Tags:
  - SDGs
  airtable_createdTime: '2023-06-05T10:57:55.000Z'
  airtable_id: recj64vAVJSm5B2ba
  title: AI could hamper, not foster, progress on SDGs
- Description: "\u201CWhile the capacity of AI systems to curate individual experiences\
    \ and to personalise digital services holds the promise of vastly improving consumer\
    \ life and service delivery, this benefit also comes with potential risks. Excessive\
    \ automation, for example, might reduce the need for human-to-human interaction,\
    \ while algorithmically enabled hyper-personalisation, by limiting our exposure\
    \ to worldviews different from ours, might polarise social relationships. Well-ordered\
    \ and cohesive societies are built on relations of trust, empathy, and mutual\
    \ understanding. As AI technologies become more prevalent, it is important that\
    \ these relations be preserved.\u201D (Leslie, 2019, p. 5)\n"
  OverarchingPrinciples (from Principles):
  - recLHILkx2JDFsLbX
  Principles:
  - recKdujFoPJr4ZAhZ
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:32:07.000Z'
  airtable_id: reckPjhcWwLgjX9p5
  title: Breakdown in trust in loss of exposure to diverse human-human interactions
- Description: "\"Does the increased access to personal information about other members\
    \ of our society, facilitated by A/IS, alter the human affective experience?\_\
    Does this access potentially lead to a change in human autonomy?\n## Background\n\
    Theoretical biology tells us that we should expect increased communication\u2014\
    which A/IS facilitate\u2014 to increase group-level investment8. Extensive use\
    \ of A/IS could change the expression of individual autonomy and in its place\
    \ increase group-based identities. Examples of this sort\_of social alteration\
    \ may include:\n1\\.\_\_\_Changes in the scope of monitoring and control of children\u2019\
    s lives by parents.\n2\\.\_\_\_Decreased willingness to express opinions for fear\
    \ of surveillance or long-term consequences of past expressions being used in\
    \ changed temporal contexts.\n3\\.\_\_\_Utilization of customers or other end\
    \ users to perform basic corporate business processes such as data entry as a\
    \ barter for lower prices or access, resulting potentially in reduced tax revenues.\n\
    4\\.\_\_\_Changes to the expression of individual autonomy could alter the diversity,\
    \ creativity, and cohesiveness of a society. It may also alter perceptions of\
    \ privacy and security, and social and legal liability for autonomous expressions.\n\
    ## Recommendations\n1\\.\_\_\_Organizations, including governments, must put a\
    \ high value on individuals\u2019 privacy and autonomy, including restricting\
    \ the amount and age of data held about individuals specifically.\n2\\.\_\_\_\
    Education in all forms should encourage individuation, the preservation of autonomy,\
    \ and knowledge of the appropriate uses and limits to A/IS9.\n## Further Resources\n\
    \u2022\_\_\_\_\_J. J. Bryson, \u201CArtificial Intelligence and Pro-Social Behavior,\u201D\
    \ in _Collective Agency and Cooperation in Natural and Artificial Systems, _C.\
    \ Misselhorn, Ed., pp. 281\u2013306, Springer, 2015.\n\u2022\_\_\_\_\_M. Cooke,\
    \ \u201CA Space of One\u2019s Own: Autonomy, Privacy, Liberty,\u201D _Philosophy\
    \ & Social Criticism, _Vol._ _25, no. 1, pp. 22\u201353, 1999.\n\u2022\_\_\_\_\
    \_D. Peters, R.A. Calvo, R.M. Ryan, \u201CDesigning for Motivation, Engagement\
    \ and Wellbeing in Digital Experience[\u201D _Frontiers in Psychology_](https://www.frontiersin.org/journals/psychology)\
    \ \u2013 _Human Media Interaction_, vol. 9. pp 797, 2018.\n\u2022\_\_\_\_\_J.\
    \ Roughgarden, M. Oishi and E. Ak\xE7ay,\n\u201CReproductive Social Behavior:\
    \ Cooperative Games to Replace Sexual Selection.\u201D _Science _311, no. 5763,\
    \ pp. 965\u2013969, 2006.\"\n\np.101\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Tags:
  - human-potential
  airtable_createdTime: '2023-06-05T06:13:33.000Z'
  airtable_id: reckyVWsglP8FLeUp
  title: Will increased access to personal information impact human experience and
    autonomy?
- Description: "\"When, if ever, and\_under which circumstances,\_is deception performed\
    \ by affective systems acceptable?\n## Background\nDeception is commonplace in\
    \ everyday human-human interaction. According to Kantian ethics, it is never ethically\
    \ appropriate to lie, while utilitarian frameworks indicate that it can be acceptable\
    \ when deception increases overall happiness. Given the diversity of views on\
    \ ethics and the appropriateness of deception, should affective systems be designed\
    \ to deceive? Does the non-consensual nature of deception restrict the use of\
    \ A/IS in contexts in which deception may be required?\nIt is necessary to develop\
    \ recommendations regarding the acceptability of deception performed by A/IS,\
    \ specifically with respect to when and under which circumstances, if any,\_it\
    \ is appropriate.\n1\\.\_\_\_In general, deception may be acceptable in an affective\
    \ agent when it is used for the benefit of the person being deceived, not for\
    \ the agent itself. For example, deception might be necessary in search and rescue\
    \ operations or for elder- or child-care.\_\n2\\.\_\_\_For deception to be used\
    \ under any circumstance, a logical and reasonable justification must be provided\
    \ by the designer, and this rationale should be certified by an external authority,\
    \ such as a licensing body\_or regulatory agency.\n## **Further resources**\n\_\
    \u2022\_\_\_\_\_R. C. Arkin, \u201CRobots That Need to Mislead: Biologically-inspired\
    \ Machine Deception.\u201D _IEEE Intelligent Systems _27, no. 6, pp. 60\u2013\
    75, 2012.\n\u2022\_\_\_\_\_J. Shim and R. C. Arkin, \u201COther-Oriented Robot\
    \ Deception: How Can a Robot\u2019s Deceptive Feedback Help Humans in HRI?\u201D\
    \ _Eighth International Conference on Social Robotics (ICSR 2016)_, Kansas, MO.,\
    \ November 2016.\n\u2022\_\_\_\_\_J. Shim and R. C. Arkin, \u201CThe Benefits\
    \ of Robot Deception in Search and Rescue: Computational Approach for Deceptive\
    \ Action Selection via Case-based Reasoning.\u201D _2015 IEEE International Symposium\
    \ on Safety, Security, and Rescue Robotics (SSRR 2015)_, West Lafayette, IN, October\
    \ 2015.\n\u2022\_\_\_\_\_J. Shim and R. C. Arkin, \u201CA Taxonomy of Robot Deception\
    \ and its Benefits in HRI.\u201D _Proceedings of IEEE Systems, Man and Cybernetics\
    \ Conference, _Manchester England, October 2013.\"\np.102-103\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec9TbOu2ZXUZG4A5
  Tags:
  - nudge-deception
  airtable_createdTime: '2023-06-05T06:13:17.000Z'
  airtable_id: recrVvneRZaEutaGw
  title: Should affective AI systems ever deceive?
- OverarchingPrinciples (from Principles):
  - recmzjcGKv3yNOxbl
  Principles:
  - rec42P8U9usfYCtv9
  airtable_createdTime: '2023-05-18T18:55:13.000Z'
  airtable_id: recv6cN7XSt5GW32Y
  title: Sustainability
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  Description: "\u201CIrresponsible data management, negligent design and production\
    \ processes, and questionable deployment practices can, each in their own ways,\
    \ lead to the implementation and distribution of AI systems that produce unreliable,\
    \ unsafe, or poor-quality outcomes. These outcomes can do direct damage to the\
    \ wellbeing of individual persons and the public welfare. They can also undermine\
    \ public trust in the responsible use of societally beneficial AI technologies,\
    \ and they can create harmful inefficiencies by virtue of the dedication of limited\
    \ public resources to inefficient or even detrimental AI technologies.\u201D (Leslie,\
    \ 2019, p. 5)\n"
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  airtable_createdTime: '2023-05-19T09:32:44.000Z'
  airtable_id: recvQ90DajNCwPiGP
  title: Concerns with merit of new systems
- ChallengeInstances:
  - reclJ7hlCEf4P94SA
  - recPKPxKp07OlhULb
  - recMhXPovX6fJ5ZIa
  - recdkRK64g0b4GZlP
  Description: |
    While significant AI work is derived from publicly funded research, commercial actors have significant interests and this may impact relationships between funders-technology providers-researchers-public with blured lines between these groups, and complex power dynamics
  OverarchingPrinciples (from Principles):
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:19:37.000Z'
  airtable_id: recwuiKe3bhSLw4xv
  title: Commercial interests - while significant AI work is derived from publicly
    funded research, commercial actors have significant interests and this may impact
    relationships between funders-technology providers-researchers-public with blured
    lines between these groups, and complex power dynamics
