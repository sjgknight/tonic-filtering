- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  ChallengeInstances:
  - recpoXmwIiqv3BMWJ
  - recT8ABqanoxK9Qu0
  - recRU6VBHZccmYrln
  - recp8G9ek0g3RAnEC
  - recbjinwvxQkFttqg
  - rec3XoC08SiG83eK0
  - recg4TZqdeqZcnd1w
  - recu8eBgTi3OTRRij
  - recAZ41hiDOn9aTOl
  - recv7IjfbiXBr4A5q
  - recfGEm2rcOTFEZVZ
  Description: "**Considerations for ethical AI include clarity or accountability\
    \ regarding the purposes of technology, and its role in decision processes.**\
    \ **Clarity** underpins responsible use of technology, and **informed engagement\
    \ (and consent)** with it. **Accountability** of AI's use by humans, to humans\
    \ underpins **respect for persons**. However, achieving clarity and accountability\
    \ may be challenging where there are different levels of expertise regarding the\
    \ technology, and understandings of the contexts into which technology may be\
    \ deployed. An aim of learning environments should be to develop agency, but this\
    \ may be stymied by systems that - however accurate - may not adequately explain\
    \ decisions so they are understood to a wide range of learners, or that limit\
    \ choices for either teachers or learners.\n\nAreas of technology development\
    \ and use, as other areas of applied research, inherently involve understanding\
    \ both of the technical features of research (methods, tools, etc.), and its practical\
    \ context including stakeholders. This kind of research requires engagement of\
    \ expertise from stakeholders in the contexts into which AI will be deployed,\
    \ and of research expertise from both technical and social disciplines. This involvement\
    \ should not be siloed, instead there should be engagement across those involved.\
    \ This can be challenging given the different areas and levels of expertise each\
    \ group may have. \nUnderstanding of the ethical issues arising from research\
    \ is one area where this transdisciplinary work is important. Effective development\
    \ of AI for use in society requires a level of 'AI literacy' among stakeholders,\
    \ engagement with transparency and explanation among providers, and an understanding\
    \ of the - dynamic - social context into which any technology may be deployed.\
    \ \n\n\n\"More institutional resources and incentive structures are necessary\
    \ to bring A/IS engineers and designers into sustained and constructive contact\
    \ with ethicists, legal scholars, and social scientists, both in academia and\
    \ industry. This contact is necessary as it can enable meaningful interdisciplinary\
    \ collaboration and shape the future of technological innovation. More could be\
    \ done to develop methods, shared knowledge, and lexicons that would facilitate\_\
    such collaboration.\nThis issue relates, among other things, to funding models\
    \ as well as the lack of diversity of backgrounds and perspectives in A/IS-related\
    \ institutions and companies, which limit cross-pollination between disciplines.\
    \ To help bridge this gap, additional translation work and resource sharing, including\
    \ websites and Massive Open Online Courses (MOOCs), need to happen among technologists\
    \ and other relevant experts, e.g., in medicine, architecture, law, philosophy,\
    \ psychology, and cognitive science. Furthermore, there is a need for more cross-disciplinary\
    \ conversation and multi-disciplinary research, as is being done, for instance,\
    \ at the annual ACM Fairness, Accountability, and Transparency (FAT\\*) conference\
    \ or the work done by the Canadian Institute For Advanced Research (CIFAR), which\_\
    is developing Canada\u2019s AI strategy.\nFunding models and institutional incentive\
    \ structures should be reviewed and revised to prioritize projects with interdisciplinary\
    \ ethics components to encourage integration of ethics into projects at all levels.\n\
    ### Further Resources\n- S. Barocas, Course Material for Ethics and Policy in\
    \ Data Science, Cornell University, 2017.\n- L. Floridi, and M. Taddeo. \u201C\
    What Is Data Ethics?\u201D _Philosophical Transactions of the Royal Society, _vol._\
    \ _374, no. 2083, 1\u20134. DOI[10.1098/ rsta.2016.0360,](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124072/)\
    \ 2016.\n- S. Spiekermann, Ethical IT Innovation: A ValueBased System Design Approach.\
    \ Boca Raton, FL: Auerbach Publications, 2015.\n- K. Crawford, \u201C[Artificial\
    \ Intelligence\u2019s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1)\u201D\
    , _New York Times_, July 25, 2016. [Online]. Available: [http://www.nytimes. com/2016/06/26/opinion/sunday/artificialintelligences-white-guy-problem.html?\\\
    _r=1](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1).\
    \ [Accessed October 28, 2018].\"\np.123-124\n\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recsonQhKLmX4D1ao
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-18T14:17:02.000Z'
  airtable_id: rec3T1WLC4dg63qyI
  title: Effective use of AI inherently involves multiple stakeholder and disciplinary
    expertise, including both AI literacy and contextual awareness across cultures
- Description: "\"How can A/IS creators incorporate well-being into\_their work?\n\
    ## Background\nWithout practical ways of incorporating well-being metrics to guide,\
    \ measure, and monitor impact, A/IS will likely lack fall short of its potential\
    \ to avoid harm and promote well-being. Incorporating well-being thinking into\
    \ typical organizational processes of design, prototyping, marketing, etc., suggests\
    \ a variety of adaptations.\nOrganizations and A/IS creators should consider clearly\
    \ defining the type of A/IS product or service that they are developing, including\
    \ articulating its intended stakeholders and uses. By defining typical uses, possible\
    \ uses, and finally unacceptable uses of the technology, creators will help to\
    \ spell out the context of well-being. This can help to identify possible harms\
    \ and risks given the different possible uses and end users, as well as intended\
    \ and unintended positive consequences.\nAdditionally, internal and external stakeholders\
    \ should be extensively consulted to ensure that impacts are thoroughly considered\
    \ through an iterative and learning stakeholder engagement process. After consultation,\
    \ A/IS creators should select appropriate well-being indicators based on the possible\
    \ scope and impact of their A/IS product or service. These well-being indicators\
    \ can be drawn from mainstream sources and models and adapted as necessary. They\
    \ can be used to engage in pre-assessment of the intended user population, projection\
    \ of possible impacts, and post-assessment. Development of a well-being indicator\
    \ measurement plan and relevant data infrastructure will support a robust integration\
    \ of well-being. A/IS models can also be trained to explicitly include well-being\
    \ indicators as subgoals.\nData and discussions on well-being impacts can be used\
    \ to suggest improvements and modifications to existing A/IS products and services\
    \ throughout their lifecycle. For example, a [team](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)\
    \ [seeking to increase the well-being o](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)f\
    \ people using wheelchairs found that when provided the opportunity to use a smart\
    \ wheelchair, some users were delighted with the opportunity for more mobility,\
    \ while others felt it would decrease their opportunities for social contact,\
    \ increase their sense of isolation, and lead to an overall decrease in their\
    \ well-being. Therefore, even though a product modification may increase well-being\
    \ according to one indicator or set of A/IS stakeholders, it does not mean that\
    \ this modification should automatically be adopted.\nFinally, organizational\
    \ processes can be modified to incorporate the above strategies. Appointment of\
    \ an organizational lead person for well-being impacts, e.g., a well-being lead,\
    \ ombudsman,\_or officer can help to facilitate this effort.\n## Recommendation\n\
    A/IS creators should adjust their existing development, marketing, and assessment\
    \ cycles to incorporate well-being concerns throughout their processes. This includes\
    \ identification of an A/IS lead ombudsperson or officer; identification of stakeholders\
    \ and end users; determination of possible uses, harm and risk assessment; robust\
    \ stakeholder engagement; selection of well-being indicators; development of a\
    \ well-being indicator measurement plan; and ongoing improvement of A/IS products\
    \ and services throughout the lifecycle.\n## Further Resources\n\u2022\_\_\_\_\
    \_[Peter Senge and the Learning Organization](http://infed.org/mobi/peter-senge-and-the-learning-organization/)[\
    \ -](https://api.ag.purdue.edu/api/depotws/File.ashx?t=f&i=11736)\n(synopsis)\
    \ Purdue University\n\u2022\_\_\_\_\_Stakeholder Engagement: A Good Practice Handbook\
    \ for Companies Doing Business in Emerging Markets. International Finance Corporation,\
    \ May 2007.\n\u2022\_\_\_\_\_[Global Reporting Initiative](https://www.globalreporting.org/Pages/default.aspx)\n\
    \u2022\_\_\_\_\_ [GNH Certification](http://www.bhutanstudies.org.bt/gnh-certification/),\
    \ Centre for Bhutan\_and GNH Studies, 2018.\u2022\_\_\_\_\_J. Helliwell, R. Layard,\
    \ and J. Sachs, Eds., \u201CThe Objective Benefits of Subjective Well-Being,\u201D\
    \ in [World Happiness Report ](http://worldhappiness.report/ed/2013/)2013. New\
    \ York: UN Sustainable Development Solutions Network, pp. 54-79, 2013.\n\u2022\
    \_\_\_\_\_[Global Happiness and Well-being Policy Report](http://www.happinesscouncil.org/)\
    \ by the Global Happiness Council, 2018.\"\n\np.78-79\n"
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  - sustainability
  airtable_createdTime: '2023-06-05T05:53:34.000Z'
  airtable_id: recA7Kh502s4UKWGo
  title: 'Sustainability (including social and environmental sustainability): How
    do we incorporate wellbeing considerations into AI impact measurement and monitoring?'
- Cases:
  - recSXcY4cnofb4zTP
  ChallengeInstances:
  - recHHvfADKIkX9idP
  - rec284Ax8lKHt4ljQ
  - recfjoQZIVhT0C5pW
  - recTaaKAtPIfbenZv
  - recVGVVfuoL5sr3oo
  - recI3S7M3KOMg2C4m
  Description: "Privacy and confidentiality expectations are bound up in cultural\
    \ norms, and other aspects of particular contexts, with emerging challenges regarding\
    \ potential for re-identification of participant data. \nData quality, integrity,\
    \ and governance are a consideration of respect for persons. \n- **Data quality\
    \ **represents the reliability and validity of the data, key features in respecting\
    \ persons through how we represent them. \n- **Data integrity **represents the\
    \ security of the data from manipulation or corruption, ensuring data can be used\
    \ for its purpose.\n\n\u201CThreats to privacy are posed by AI systems both as\
    \ a result of their design and development processes, and as a result of their\
    \ deployment. As AI projects are anchored in the structuring and processing of\
    \ data, the development of AI technologies will frequently involve the utilisation\
    \ of personal data. This data is sometimes captured and extracted without gaining\
    \ the proper consent of the data subject or is handled in a way that reveals (or\
    \ places under risk the revelation of) personal information. On the deployment\
    \ end, AI systems that target, profile, or nudge data subjects without their knowledge\
    \ or consent could in some circumstances be interpreted as infringing upon their\
    \ ability to lead a private life in which they are able to intentionally manage\
    \ the transformative effects of the technologies that influence and shape their\
    \ development. This sort of privacy invasion can consequently harm a person\u2019\
    s more basic right to pursue their goals and life plans free from unchosen influence.\u201D\
    \ (Leslie, 2019, p. 5) \n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  Principles:
  - recPg7Ov0priGGtLm
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-05-18T19:10:38.000Z'
  airtable_id: recBc3GCNokDL220T
  title: 'Privacy, confidentiality, data integrity and cultural norms '
- Description: "\"How can A/IS creators influence A/IS goals to ensure well-being,\
    \ and what can A/IS creators learn or borrow from existing models in the well-being\
    \ and other arenas?\n## Background\nAnother way to incorporate considerations\
    \ of well-being is to include well-being measures\_in the development, goal setting,\
    \ and training\_of the A/IS systems themselves.\nIdentified metrics of well-being\
    \ could be formulated as auxiliary objectives of the A/IS. As these auxiliary\
    \ well-being objectives will be only a subset of the intended goals of the system,\
    \ the architecture will need to balance multiple objectives. Each of these auxiliary\
    \ objectives may be expressed as a goal, set of rules, set of values, or as a\
    \ set of preferences, which can be weighted and combined using established methodologies\
    \ from intelligent systems engineering.\_\nFor example, an educational A/IS tool\
    \ could not only optimize learning outcomes, but also incorporate measures of\
    \ student social and emotional education, learning, and thriving.\nA/IS-related\
    \ data relates both to the individual\u2014 through personalized algorithms, in\
    \ conjunction with affective sensors measuring and influencing emotion, and other\
    \ aspects of individual well-being \u2014and to society as large data sets representing\
    \ aggregate individual subjective and objective data. As the exchange of this\
    \ data becomes more widely available via establishing tracking methodologies,\
    \ the data can be aligned within A/IS products and services to increase human\
    \ well-being. For example, robots like [Pepper](https://www.sbs.com.au/news/dateline/article/2017/04/11/love-intimacy-and-companionship-tale-robots-japan)\
    \ are equipped to share data regarding their usage and interaction with humans\
    \ to the cloud. This allows almost instantaneous innovation, as once an action\
    \ is validated as useful for one Pepper robot, all other Pepper units (and ostensibly\
    \ their owners) benefit as well. As long as this data exchange happens with the\
    \ predetermined consent of the robots\u2019 owners, this innovation in real time\
    \ model can be emulated for the large-scale aggregation of information relating\
    \ to existing well-being metrics.\nA/IS creators can also help to operationalize\
    \ well-being metrics by providing stakeholders with reports on the expected or\
    \ actual outcomes of the A/IS and the values and objectives embedded in the systems.\
    \ This transparency will help creators, users, and third parties assess the state\
    \ of well-being produced by A/IS and make improvements in A/IS. In addition, A/IS\
    \ creators should consider allowing end users to layer on their own preferences,\
    \ such as allowing users to limit their use of an A/IS product if it leads to\
    \ increased sustained stress levels, sustained isolation, development of unhealthy\
    \ habits, or other decreases to well-being.\_\nIncorporating well-being goals\
    \ and metrics into broader organizational values and processes would support the\
    \ use of well-being metrics as there would be institutional support. A key factor\
    \ in industrial, corporate, and societal progress is cross-dissemination of concepts\
    \ and models from one industry or field to another. To date, a number of successful\
    \ concepts and models exist in the fields of sustainability, economics, industrial\
    \ design and manufacturing, architecture and urban development, and governmental\
    \ policy. These concepts and models can provide a foundation\_for building a metrics\
    \ standard and the use of wellbeing metrics by A/IS creators, from conception\
    \ and design to marketing, product updates, and improvements to the user experience.\_\
    \n## Recommendation\nCreate technical standards for representing goals, metrics,\
    \ and evaluation guidelines for well-being metrics and their precursors and components\
    \ within A/IS that include:\n\u2022\_\_\_\_\_[O](https://en.wikipedia.org/wiki/Ontology_(information_science))ntologies\
    \ for representing technological requirements.\n\u2022\_\_\_\_\_A testing framework\
    \ for validating adherence to well-being metrics and ethical principles such as\
    \ [IEEE P7010\u2122 Standards Project for Wellbeing Metric for Autonomous and\
    \ Intelligent Systems](https://standards.ieee.org/project/7010.html).\nabove as\
    \ well as others as a basis for a wellbeing metrics standard for A/IS creators.\
    \ _(See page 191, [Additional Resources: Additional Resources: Standards Development\
    \ Models and Frameworks)](https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead1e_standards_development_models_frameworks.pdf)_\n\
    \u2022\_\_\_\_\_The development of a well-being metrics standard for A/IS that\
    \ encompasses an understanding of well-being as holistic and interlinked to social,\
    \ economic, and ecological systems.\n\_\n## Further Resources\n\u2022\_\_\_\_\_\
    A.F.T Winfield, C. Blum, and W. Liu. \u201C[Towards an Ethical Robot: Internal\
    \ Models, Consequences and Ethical Action Selection](https://link.springer.com/chapter/10.1007/978-3-319-10401-0_8),\u201D\
    \ in Advances in Autonomous Robotics Systems. Springer, 2014, pp. 85\u201396\n\
    \u2022\_\_\_\_\_R. A. Calvo, and D. Peters. [Positive Computing: Technology for\
    \ Well-Being and Human Potential](https://mitpress.mit.edu/books/positive-computing)._\
    \ _Cambridge MA: MIT Press, 2014.\n\u2022\_\_\_\_\_Y. Collette, and P. Slarry.\
    \ [Multiobjective Optimization: Principles and Case Studies ](https://link.springer.com/book/10.1007%2F978-3-662-08883-8)\n\
    (Decision Engineering Series). Berlin, Germany:\nSpringer, 2004. doi: 10.1007/978-3-662-08883-8.\n\
    \u2022\_\_\_\_\_J. Greene, et al. \u201C[Embedding Ethical Principles in Collective\
    \ Decision Support Systems](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12457),\u201D\
    \ in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence_,\
    \ _4147\u20134151. Palo Alto, CA: AAAI Press, 2016.\n\u2022\_\_\_\_\_L. Li, I.\
    \ Yevseyeva, V. Basto-Fernandes, H. Trautmann, N. Jing, and M. Emmerich,\u201C\
    [Building and Using an Ontology of Preference-Based Multiobjective Evolutionary\
    \ Algorithms.](https://dl.acm.org/citation.cfm?id=3088704)\u201D In 9th International\
    \ Conference on Evolutionary Multi-Criterion Optimization\u2014Volume 10173 (EMO\
    \ O. Sch\xFCtze, M. Wiecek, Y. Jin, and C. Grimme, Eds., Vol. 10173. Springer-Verlag,\
    \ Berlin, Heidelberg, 406-421, 2017.\n\u2022\_\_\_\_\_[PositiveSocialImpact:](https://invis.io/9874GSJS6)\
    \ Empowering people, organizations and planet with information and knowledge to\
    \ make a positive impact to sustainable development, 2017.\n\u2022\_\_\_\_\_D.K.\
    \ Ura, Bhutan\u2019s [Gross National Happiness Policy Screening Tool](http://www.grossnationalhappiness.com/docs/GNH/PDFs/PoliSTools.pdf).\n\
    \"\np.79-81\n"
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  - sustainability
  airtable_createdTime: '2023-06-05T05:54:42.000Z'
  airtable_id: recGRpoF7DA23ODSj
  title: 'Sustainability (including social and environmental sustainability): How
    do we incorporate wellbeing considerations into AI design/development/use?'
- ChallengeInstances:
  - recX9rdsAGiONXTVd
  - recQWEzfzmzmfstG9
  - recsYgGzgIK80qUCT
  - recQmyVULN0OuFA2s
  - recQtuMpX4WaAoHhG
  - rec5l10QTYprjeewa
  - recJOwTAhuoamQM7C
  - recz5LeVOgbgic8Jk
  - recBfwOfoB68ghQAV
  Description: "AI and associated infrastructure has shifted relationships of researchers\
    \ and participants through greater secondary use of data, online platforms that\
    \ connect (sometimes invisibly) participants to researchers, heightened risks\
    \ of re-identification, and tools that may be used in unanticipated contexts.\
    \ \nIn some cases, research may be conducted under the auspices of 'quality improvement'\
    \ or operational research. In such cases the research is carried out to improve\
    \ existing practices within the research site; there may be alternative ethics\
    \ approval processes for such research. This kind of research has the advantage\
    \ of being located at the site of implementation. Complex power dynamics should\
    \ be considered between researchers (who may fulfil dual roles), and other stakeholders\
    \ such as teachers, students, administrators, and technology providers.\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recLHILkx2JDFsLbX
  Principles:
  - recKdujFoPJr4ZAhZ
  - recPg7Ov0priGGtLm
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'franzke, aline shakti, Bechmann, A., Zimmer, M., Ess, C., & Association of Internet
    Researchers (AoIR). (2020). Internet Research: Ethical Guidelines 3.0 Association
    of Internet Researchers. AoIR. https://aoir.org/reports/ethics3.pdf'
  - 'Markham, A., & Buchanan, E. (2012). Ethical Decision-Making and Internet Research:
    Recommendations from the AoIR Ethics Working Committee (Version 2.0). AoIR. https://aoir.org/reports/ethics2.pdf'
  - Fedoruk, L. (2017b). Ethics in The Scholarship of Teaching and Learning. University
    of Calgary Taylor Institute for Teaching and Learning. https://taylorinstitute.ucalgary.ca/resources/ethics-scholarship-teaching-and-learning
  Sources:
  - recpXl48pJdKDhc6f
  - rec6r8OkE2Q2EdiM3
  - recQiVQ7CTC72xp6O
  - recQzldmBLByP78Uu
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:17:55.000Z'
  airtable_id: recJ6khG2kY2Tx5ae
  title: Interactions and distance between researchers and participants are central
    to research, both when proximal, and when mediated by technologies.
- ChallengeInstances:
  - recC8IlVKWmMHOorw
  - rec1UyKLba4O7X6ax
  Description: "Through the inception, design, development, implementation, evaluation,\
    \ and decommissioning human control of technology is central to considerations\
    \ of autonomy, accountability, and human oversight of AI. That is because AI has\
    \ the potential to diminish autonomy and thus influence democratic participation\
    \ and human flourishing.\_\nTechnologies may automate aspects of human decision\
    \ making in ways that may diminish human autonomy, and where it is not always\
    \ transparent what basis decisions are made on, or the evidence that systems perform\
    \ to an acceptable level in these decisions.\n"
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-18T18:10:44.000Z'
  airtable_id: recSONq7KetYgyg6K
  title: Human control of technology and accountability for technology use
- ChallengeInstances:
  - recuFqYoT6MFNqspL
  - recwl0AdKj2HLIpDB
  - rec3wCdnHy3TpLuya
  - rec4F8A2UI0uvFh3O
  - reccjN6q8gegWbrUE
  - rec16WOKdMVKAiBSJ
  - recUMRucTbQ7tySEW
  - reciceYsMfOtPdaaA
  Description: "AI has potential to have impact beyond just on the participants involved\
    \ into society, and it may not be clear what these impacts will be.\nImmediate\
    \ or proximal impacts are those experienced in the immediate context, for example\
    \ in interactions of researcher-participant groups. Indirect, long-range, and\
    \ dual-use impacts relate to the potential for:\n- secondary impacts that are\
    \ not a direct use of a tool but may relate to system changes that occur as a\
    \ result;\n- that these impacts may occur over a longer period than the immediate\
    \ context of research, which is ordinarily the context for which ethics approval\
    \ is provided\n- and that some effects may arise from unintended uses of dual-use\
    \ technologies, for example facial recognition developed for one purpose may be\
    \ used for surveillance or military purposes.\n\n**\"Issue: **A/IS are often viewed\
    \ only as having impact in market contexts, yet these technologies also have an\
    \ impact on social relations and culture.\nA/IS are expected to have an impact\
    \ beyond market domains and business models, diffusing throughout the global society.\
    \ For instance,\_A/IS have and will impact social relationships\_in a way similar\
    \ to how mobile phones changed our daily lives, reflecting directly on our culture,\
    \ customs, and language. The extent and direction of this impact is not yet clear,\
    \ but documented experience in HIC and high internet-penetration environments\
    \ of trolls, \u201Cfake news,\u201D and cyberbullying on social media offer a\
    \ cautionary tale.11 Depression, social isolation, aggression, and the dissemination\
    \ of violent behavior with damage to human relations, so extreme that, in some\
    \ cases, it has resulted in suicide, are all correlated with the internet.12 As\
    \ an example, the technology for \u201Csmart homes\u201D has been used for inflicting\
    \ domestic violence by remotely locking doors, turning off heat/AC, and otherwise\
    \ harassing a partner. This problem could be easily extended to include elder\
    \ and child abuse.13 Measures need to be developed to prevent A/IS from contributing\
    \ to the emergence or amplification of social disorders.\" (IEEE, 2019, p.141-142)\n"
  OverarchingPrinciples:
  - recNB5h9bK4gEE9uc
  Principles:
  - recNB5h9bK4gEE9uc
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  - recK1gdkh8c01WaXx
  - rec7daqDHSCuc70yS
  Tags:
  - AI
  - indirect-impacts
  - education
  airtable_createdTime: '2023-05-18T18:54:26.000Z'
  airtable_id: recWPbL5kB1Yh5OPf
  title: Research produces both direct impact, on participants and then society, while
    also giving rise to indirect, long-range, and dual-use impacts
- ChallengeInstances:
  - recxWhAXTqxMscDqr
  - recx5eWOlkkg11NJX
  - recVWprITnDX6u0QB
  - rec0d9XwyvbDuuuN6
  - rec1ldHV74MQeRllz
  - reck3lUFUtAhNes3Y
  - recPW66Z54lKwa7hR
  - recwVOVXU6zbH6KZ7
  - rec5nljdN28sNoK3X
  - recWNlnhyOUXmOo0Q
  - recg821VxieIJvgRO
  Description: |
    **Respect for human-human relationships, at individual and collective levels** AI has the potential to impact on how we connect and talk together, and the structure of societies. AI should avoid harms and promote pro-social engagement, recognising that both the benefits and harms of research (and broader engagement with technology) may accrue over groups.
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-18T18:55:37.000Z'
  airtable_id: recWxPEkLYUdWhd2q
  title: Respect for human-human relationships, at individual and collective levels
- Cases:
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recDAvfsflBF0WKpf
  ChallengeInstances:
  - rec7aGSPdkdUuZ42O
  - reczbN2QKYqG695ec
  - recHUlZ9OQfNwD6fg
  - recJvXzs5QMTqWzUF
  - recftbldoHqhBBcrk
  Description: "**Respect for diversity, non-discrimination, and fairness** respect\
    \ for persons includes respect for difference, non-discrimination, and fairness\
    \ in treatment of persons with particular protection for vulnerable populations.\
    \ This concern is particularly salient in the context of AI because models built\
    \ on historic data may reflect existing societal biases in a way that makes them\
    \ opaque or unaccountable. Systems should thus provide for stakeholder participation\
    \ and use regardless of their characteristics.\nNew technologies including AI\
    \ have potential for bias at multiple phases of a project (problem identification,\
    \ training data, modeling, implementation), and in multiple ways including through\
    \ use of data that reflects existing societal biases. While reinforcing existing\
    \ biases based on historic data is typically focal, the potential to create new\
    \ forms of bias should also be clear \n\u201CBecause they gain their insights\
    \ from the existing structures and dynamics of the societies they analyse, datadriven\
    \ technologies can reproduce, reinforce, and amplify the patterns of marginalisation,\
    \ inequality, and discrimination that exist in these societies. Likewise, because\
    \ many of the features, metrics, and analytic structures of the models that enable\
    \ data mining are chosen by their designers, these technologies can potentially\
    \ replicate their designers\u2019 preconceptions and biases. Finally, the data\
    \ samples used to train and test algorithmic systems can often be insufficiently\
    \ representative of the populations from which they are drawing inferences. This\
    \ creates real possibilities of biased and discriminatory outcomes, because the\
    \ data being fed into the systems is flawed from the start.\u201D (Leslie, 2019,\
    \ p. 4)\n\n### IEEE report\n\"**Issue 2: **A/IS can have biases that disadvantage\
    \ specific groups\n## Background\nEven when reflecting the full system of community\
    \ norms that was identified, A/IS may show operation biases that disadvantage\
    \ specific groups in the community or instill biases in users by reinforcing group\
    \ stereotypes. A system\u2019s bias can emerge in perception. For example, a passport\
    \ application AI rejected an Asian man\u2019s photo because it insisted his eyes\
    \ were closed (Griffiths 201651). Bias can emerge in information processing. For\
    \ instance, speech recognition systems are notoriously less accurate for female\
    \ speakers than for male speakers (Tatman 201652). System bias can affect decisions,\
    \ such as a criminal risk assessment device which overpredicts recidivism by African\
    \ Americans (Angwin et al. 201653). The system\u2019s bias can present itself\
    \ even in its own appearance and presentation: the vast majority of humanoid robots\
    \ have white \u201Cskin\u201D color and use female voices (Riek and Howard 201454).\n\
    The norm identification process detailed in Section 1 is intended to minimize\
    \ individual designers\u2019 biases because the community norms are assessed empirically.\
    \ The identification process also seeks to incorporate norms against prejudice\
    \ and discrimination. However, biases may still emerge from imperfections in the\
    \ norm identification process itself, from unrepresentative training sets for\
    \ machine learning systems, and from programmers\u2019 and designers\u2019 unconscious\
    \ assumptions. Therefore, unanticipated or undetected biases should be further\
    \ reduced by including members of diverse social groups in both the planning and\
    \ evaluation of A/IS and integrating community outreach into the evaluation process,\
    \ e.g., [DO-IT ](http://www.washington.edu/doit/)program and [RRI](http://www.orbit-rri.org/)\
    \ framework. Behavioral scientists and members of the target populations will\
    \ be particularly valuable when devising criterion tasks for system evaluation\
    \ and assessing the success of evaluating the A/IS performance on those tasks.\
    \ Such tasks would assess, for example, whether the A/IS apply norms in discriminatory\
    \ ways to different races, ethnicities, genders, ages, body shapes, or to people\
    \ who use wheelchairs\_or prosthetics, and so on.\"\np.184, IEEE, 2019\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recmzjcGKv3yNOxbl
  Principles:
  - reczVPIH1y2OMpAJH
  - rec42P8U9usfYCtv9
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recpXl48pJdKDhc6f
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-05-18T13:41:32.000Z'
  airtable_id: recefglLZ3oJWw2SZ
  title: Respect for diversity, non-discrimination, and fairness
- Description: "Human rights law is related to, but distinct from, the pursuit of\
    \ well-being. Incorporating a human-rights framework as an essential basis for\
    \ A/IS creators means A/IS creators honor existing law as part of their well-being\
    \ analysis and implementation.\n## Background\nInternational human rights law\
    \ has been firmly established for decades in order to protect various guarantees\
    \ and freedoms as enshrined in charters such as the United Nations\u2019[ Universal\
    \ Declaration of Human Rights ](http://www.un.org/en/universal-declaration-human-rights/)and\
    \ the Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention).\
    \ In 2018, the[ Toronto Declaration ](https://www.accessnow.org/the-toronto-declaration-protecting-the-rights-to-equality-and-non-discrimination-in-machine-learning-systems/)on\
    \ machine learning standards was released, calling on both governments and technology\
    \ companies to ensure that algorithms respect basic principles of equality and\
    \ non-discrimination. The Toronto Declaration sets forth an obligation to prevent\
    \ machine learning systems from discriminating, and in some cases violating, existing\
    \ human rights law.\nWell-being initiatives are typically undertaken for the sake\
    \ of public interest. However, any metric, including well-being metrics, can be\
    \ misused to justify human rights violations. Encampment and mistreatment of refugees\
    \ and ethnic cleansing undertaken to preserve a nation\u2019s culture (an aspect\
    \ of well-being) is one example. Imprisonment or assassination of journalists\
    \ or researchers to ensure the stability of a government is another. The use of\
    \ wellbeing metrics to justify human rights violations is an unconscionable perversion\
    \ of the nature of any well-being metric. It should be noted that these same practices\
    \ happen today in relation to GDP. For instance, in 2012, according to the [International\
    \ Labour Organization (](http://www.ilo.org/global/about-the-ilo/newsroom/news/WCMS_181961/lang--en/index.htm)ILO),\
    \ approximately 21 million people are victims of forced labor (slavery), representing\
    \ 9% to 56% of GDP income for various countries. These clear human rights violations,\
    \ from sex trafficking and use of children in armies, to indentured farming or\
    \ manufacturing labor, can increase a country\u2019s GDP while obviously harming\
    \ human well-being.\n## Recommendations\nWell-being metrics are designed to measure\
    \ the efficacy of efforts related to individual and societal flourishing. Well-being\
    \ as a value complements justice, equality, and freedom. Well-designed application\
    \ of well-being considerations by A/IS creators should not displace other issues\
    \ of human rights or ethical methodologies, but rather complement them.\nA human\
    \ rights framework should represent the floor, and not the ceiling, for the standards\
    \ to which A/IS creators must adhere. Developers and users of well-being metrics\
    \ should be aware these metrics will not always adequately address human rights.\n\
    ## Further Resources\n\u2022\_\_\_\_\_United Nations[ Universal Declaration of\
    \ Human Rights,](http://www.un.org/en/universal-declaration-human-rights/) 1948.\n\
    \u2022\_\_\_\_\_Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention),\
    \ 2018.\n\u2022\_\_\_\_\_International Labor Organization (ILO) [Declaration on\
    \ Fundamental Principles and Rights at Work,](https://www.ilo.org/declaration/lang--en/index.htm)\
    \ 1998.\n\u2022\_\_\_\_\_The regularly updated [University of Minnesota Human\
    \ Rights Library ](http://hrlibrary.umn.edu/)provides a wealth of material on\
    \ human rights laws, its history, and the organizations engaged in promoting them.\n\
    The [Oxford Human Rights Hub ](http://ohrh.law.ox.ac.uk/why-artificial-intelligence-is-already-a-human-rights-issue/)reports\
    \ on how and why technologies surrounding artificial intelligence raise human\
    \ rights issues\"\np.76-77\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recOHnq45Fq7YWsRO
  Principles:
  - receFm7cGasHwpJZO
  - recQ9DIFEsOEkCx3O
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recTr6cDE4OBKV0wv
  - rec7daqDHSCuc70yS
  - recK1gdkh8c01WaXx
  - recHEUOqkzQTNsAMw
  Tags:
  - wellbeing
  - sustainability
  airtable_createdTime: '2023-06-05T05:47:17.000Z'
  airtable_id: reciNc7OeTUmnsLqg
  title: 'Sustainability (including social and environmental sustainability): How
    do we incorporate a human-rights framework into AI design/development/use?'
- Description: "**\"Issue: **Current roadmaps for development and deployment of A/IS\
    \ are not aligned with or guided by their impact in the most important challenges\
    \ of humanity, defined in the seventeen United Nations Sustainable Development\
    \ Goals (SDGs), which collectively aspire to create a more equal world of prosperity,\
    \ peace, planet protection, and human dignity\_for all people.4\n## Background\n\
    SDGs promoting prosperity, peace, planet protection, human dignity, and respect\
    \ for human rights of all, apply to HIC and LMIC alike. Yet ensuring that the\
    \ benefits of A/IS will accrue to humanity as a whole, leaving \u201Cno one behind\u201D\
    , requires an ethical commitment to global citizenship and well-being, and a conscious\
    \ effort to counter the nature of the tech economy, with its tendency to concentrate\
    \ wealth within high income populations. Implementation of the SDGs should benefit\
    \ excluded sectors of society in every country, regardless of A/IS infrastructure.\u201C\
    The Road to Dignity by 2030\u201D document of the UN Secretary General reports\
    \ on resources and methods for implementing the 2030 Agenda for Sustainable Development\
    \ and emphasizes the importance of science, technology, and innovation for a sustainable\
    \ future.5 The UN Secretary General posits that:\n\u201CA sustainable future will\
    \ require that we act now to phase out unsustainable technologies and to invest\
    \ in innovation and in the development of clean and sound technologies for sustainable\
    \ development. We must ensure that they are fairly priced, broadly disseminated\
    \ and fairly absorbed, including to and by developing countries.\u201D (para.\
    \ 120)\nA/IS are among the technologies that can play an important role in the\
    \ solution of the deep social problems plaguing our global civilization, contributing\
    \ to the transformation of society away from an unsustainable, unequal socioeconomic\
    \ system, towards one that realizes the vision of universal human dignity, peace,\
    \ and prosperity.\nHowever, with all the potential benefits of\_A/IS, there are\
    \ also risks. For example, given\_A/IS technology\u2019s immense power needs,\
    \ without new sources of sustainable energy harnessed to power A/IS in the future,\
    \ there is a risk that it will increase fossil fuel use and have a negative impact\
    \ on the environment and the climate.\nWhile 45% of the world\u2019s population\
    \ is not connected to the internet, they are not necessarily excluded from A/IS\u2019\
    \ potential benefits: in LMIC mobile networks can provide data for A/IS applications.\
    \ However, only those connected are likely to benefit from the income-producing\
    \ potential of internet technologies. In 2017, internet penetration in HIC left\
    \ behind certain portions of the population often in rural or remote areas; 12%\
    \ of U.S. residents and 20% of residents across Europe were unable to access the\
    \ internet. In Asia with its concentration of LMIC, 52% of the population, on\
    \ average, had no access, a statistic skewed by the large population of China,\
    \ where internet penetration reached 45% of the population. In numerous other\
    \ countries in the region, 99% of residents had no access. This nearly total exclusion\
    \ also exists in several countries in Africa, where the overall internet penetration\
    \ is only 35%: 2 of every 3 residents in Africa have no access.6 Those with no\
    \ internet access also do not generate data needed to \u201Ctrain\u201D A/IS,\
    \ and are thereby excluded from benefits of the technology, the development of\
    \ which risks systematic discriminatory bias, particularly against people from\
    \ minority populations, and those living in rural areas, or in low-income countries.\
    \ As a comparison, one study estimated that \u201Cin the US, just one home automation\
    \ product can generate a data point every six seconds.\u201D7 In Mozambique, where\
    \ about 90% of the population lack internet access, \u201Cthe average household\
    \ generates zero digital data points.\u201D8 With mobile phones generating much\
    \ of the data needed for developing A/IS applications in LMIC, unequal phone ownership\
    \ may build in bias. For example, there is a risk of discrimination against women,\
    \ who across LMIC are 14% less likely than men to own a mobile phone, and in South\
    \ Asia where 38% are less likely to own a mobile phone.9\n## Recommendations\n\
    The current range of A/IS applications in sectors crucial to the SDGs, and to\
    \ excluded populations everywhere, should be studied, with the strengths, weaknesses,\
    \ and potential of the most significant recent applications analyzed, and the\
    \ best ones developed at scale. Specific objectives to consider include:\n\u2022\
    \_\_\_\_\_Identifying and experimenting with\_A/IS technologies relevant to the\
    \ SDGs,\_such as: big data for development relevant to, for example, agriculture\
    \ and medical tele-diagnosis; geographic information systems needed in public\
    \ service planning, disaster prevention, emergency planning, and disease monitoring;\
    \ control systems used in, for example, naturalizing intelligent cities through\
    \ energy and traffic control and management of urban agriculture; applications\
    \ that promote human empathy focused on diminishing violence and exclusion and\
    \ increasing well-being.\n\u2022\_\_\_\_\_Promoting the potential role of A/IS\
    \ in sustainable development by collaboration between national and international\
    \ government agencies and non-governmental organizations (NGOs) in technology\
    \ sectors.\n\u2022\_\_\_\_\_Analyzing the cost of and proposing strategies for\
    \ publicly providing internet access for\_all, as a means of diminishing the gap\
    \ in\_A/IS\u2019 potential benefit to humanity, particularly between urban and\
    \ rural populations in HIC and LMIC alike.\n\u2022\_\_\_\_\_Investing in the documentation\
    \ and dissemination of innovative applications of\_A/IS that advance the resolution\
    \ of identified societal issues and the SDGs.\n\u2022\_\_\_\_\_Researching sustainable\
    \ energy to power A/IS computational capacity.\n\u2022\_\_\_\_\_Investing in the\
    \ development of transparent monitoring frameworks to track the concrete results\
    \ of donations by international organizations, corporations, independent agencies,\
    \ and the State, to ensure efficiency and accountability in applied A/IS.\n\u2022\
    \_\_\_\_\_Developing national legal, policy, and fiscal measures to encourage\
    \ competition in the\_A/IS domestic markets and the flourishing\_of scalable A/IS\
    \ applications.\n\u2022\_\_\_\_\_Integrating the SDGs into the core of private\
    \ sector business strategies and adding SDG indicators to companies\u2019 key\
    \ performance indicators, going beyond corporate social responsibility (CSR).\n\
    \u2022\_\_\_\_\_Applying the well-being indicators10 to evaluate A/IS\u2019 impact\
    \ from multiple perspectives in HIC and LMIC alike.\n## Further reading\n\u2022\
    \_\_\_\_\_R. Van Est and J.B.A. Gerritsen, with assistance of L. Kool, Human Rights\
    \ in the Robot Age: Challenges arising from the use of Robots, Artificial Intelligence\
    \ and Augmented Reality Expert Report written for the Committee on Culture, Science,\
    \ Education and Media of the Parliamentary Assembly of the Council of Europe (PACE),\
    \ The Hague: Rathenau Instituut 2017.\n\u2022\_\_\_\_\_World Economic Forum Global\
    \ Future Council on Human Rights 2016-18, \u201CWhite Paper: How to Prevent Discriminatory\
    \ Outcomes in Machine Learning,\u201D World Economic Forum, March 2018.\n\u2022\
    \_\_\_\_\_United Nations General Assembly, _Transforming Our World: The 2030 Agenda\
    \ for Sustainable Development_ (A/RES/70/1: 21 October 2015) Preamble. [http://www.un.org/\
    \ en/development/desa/population/migration/ generalassembly/docs/globalcompact/\
    \ A\\_RES\\_70\\_1\\_E.pdf](http://www.un.org/en/development/desa/population/migration/generalassembly/docs/globalcompact/A_RES_70_1_E.pdf).\n\
    \u2022\_\_\_\_\_United Nations Global Pulse, Big Data for Development: Challenges\
    \ and Opportunities, 2012.\"\n\np139-140\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  Principles:
  - recLHILkx2JDFsLbX
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recouZjokdKQz88z1
  - recK1gdkh8c01WaXx
  - rec7daqDHSCuc70yS
  - rec0WScLo6sUnoOQN
  - recGS9OVQ7qAjvIYE
  - recJMrMEZnz9rYlnD
  Tags:
  - SDGs
  - sustainability
  airtable_createdTime: '2023-06-05T10:57:55.000Z'
  airtable_id: recj64vAVJSm5B2ba
  title: 'Sustainability (including social and environmental sustainability): AI could
    hamper, not foster, progress on SDGs'
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recpFE7h6QhaEpNAQ
  ChallengeInstances:
  - recpxk9KZ2adMWrnD
  - recfzbgUna1vE1wtt
  - rec5facmXBZUPH3es
  - recKFOQ4CcT6PhQoe
  - recbsVGBRocMgkD2G
  - recISbGibFUeCXoRj
  - rec2OEPHyKNR33lW6
  Description: "**Inappropriate use **\"New technologies give rise to greater risk\
    \ of deliberate or accidental misuse, and this is especially true for A/IS. A/IS\
    \ increases the impact of risks such as hacking, misuse of personal data, system\
    \ manipulation, or exploitation of vulnerable users by unscrupulous parties. Cases\
    \ of A/IS hacking have already been widely reported, with driverless cars, for\
    \ example. The Microsoft Tay AI chatbot was famously manipulated when it mimicked\
    \ deliberately offensive users. In an age where these powerful tools are easily\
    \ available, there is a need for a new kind of education for citizens to be sensitized\
    \ to risks associated with the misuse of A/IS. The EU\u2019s General Data Protection\
    \ Regulation (GDPR) provides measures to remedy the misuse of personal data.Responsible\
    \ innovation requires A/IS creators to anticipate, reflect, and engage with users\
    \ of A/IS. Thus, citizens, lawyers, governments, etc., all have a role to play\
    \ through education and awareness in developing accountability structures (see\
    \ Principle 6), in addition to guiding new technology proactively toward beneficial\
    \ ends.\" [(IEEE, 2019, p.32-33)](https://ethics-guides.netlify.app/reccfsnzpjvw0pcue)\n"
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-18T18:56:46.000Z'
  airtable_id: recuUWIu0ofVYHLKA
  title: New technologies give rise to new potential for misuse
- ChallengeInstances:
  - reclJ7hlCEf4P94SA
  - recPKPxKp07OlhULb
  - recMhXPovX6fJ5ZIa
  - recdkRK64g0b4GZlP
  Description: |
    While significant AI work is derived from publicly funded research, commercial actors have significant interests and this may impact relationships between funders-technology providers-researchers-public with blured lines between these groups, and complex power dynamics
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:19:37.000Z'
  airtable_id: recwuiKe3bhSLw4xv
  title: Commercial interests - while significant AI work is derived from publicly
    funded research, commercial actors have significant interests and this may impact
    relationships between funders-technology providers-researchers-public with blured
    lines between these groups, and complex power dynamics
