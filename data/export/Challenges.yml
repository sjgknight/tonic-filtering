- Description: "Are moral and ethical boundaries crossed when the design of affective\
    \ systems allows them to develop intimate relationships with their users?\n##\
    \ Background\n There are many robots in development or production designed to\
    \ focus on intimate care of children, adults, and the elderly2. While robots capable\
    \ of participating fully in intimate relationships are not currently available,\
    \ the potential use of such robots routinely captures the attention of the media.\
    \ It is important that professional communities, policy makers, and the general\
    \ public participate in development of guidelines for appropriate use of A/IS\
    \ in this area. Those guidelines should acknowledge fundamental human rights to\
    \ highlight potential ethical benefits and risks that may emerge, if\_and when\
    \ affective systems interact intimately with users. Among the many areas of concern\
    \ are the representation of care, embodiment of caring\_A/IS, and the sensitivity\
    \ of data generated through intimate and caring relationships with\_A/IS. The\
    \ literature suggests that there are some potential benefits to individuals and\
    \ to society from the incorporation of caring A/IS, along with duly cautionary\
    \ notes concerning the possibility that these systems could negatively impact\
    \ human-to-human intimate relations3.\n## Recommendations\nAs this technology\
    \ develops, it is important to monitor research into the development of intimate\
    \ relationships between A/IS and humans. Research should emphasize any technical\
    \ and normative developments that reflect use of\_A/IS in positive and therapeutic\
    \ ways while also creating appropriate safeguards to mitigate against uses that\
    \ contribute to problematic individual or social relationships:\n1\\.\_\_\_Intimate\
    \ systems must not be designed or deployed in ways that contribute to stereotypes,\
    \ gender or racial inequality,\_or the exacerbation of human misery.\n2\\.\_\_\
    \_Intimate systems must not be designed to explicitly engage in the psychological\
    \ manipulation of the users of these systems unless the user is made aware they\
    \ are being manipulated and consents to this behavior. Any manipulation should\
    \ be governed\_through an opt-in system.\n3\\.\_\_\_Caring A/IS should be designed\
    \ to avoid contributing to user isolation from society.\_\n4\\.\_\_\_Designers\
    \ of affective robotics must publicly acknowledge, for example, within a notice\
    \ associated with the product, that these systems can have side effects, such\
    \ as interfering with the relationship dynamics between human partners, causing\
    \ attachments between the user and the A/IS that are distinct from human partnership.\n\
    5\\.\_\_Commercially marketed A/IS for caring applications should not be presented\
    \ to be a person in a legal sense, nor marketed as a person. Rather its artifactual,\
    \ that is, authored, designed, and built deliberately, nature should always be\
    \ made as transparent as possible, at least at point of sale and in available\
    \ documentation, as noted in Section 4, Systems Supporting Human Potential.6.\_\
    \_\_Existing laws regarding personal imagery need to be reconsidered in light\
    \ of caring A/IS.\_In addition to other ethical considerations, it will also be\
    \ necessary to establish conformance with local laws and mores in the context\
    \ of caring A/IS systems.\n## Further Resources\n\u2022\_\_\_\_\_M. Boden, J.\
    \ Bryson, D. Caldwell, K. Dautenhahn, L. Edwards, S. Kember, P.\nNewman, V. Parry,\
    \ G. Pegman, T. Rodden and T. Sorrell, Principles of robotics: regulating robots\
    \ in the real world. Connection Science, vol. 29, no. 2, pp. 124-129, April 2017.\n\
    \u2022\_\_\_\_\_J. J. Bryson, M. E. Diamantis, and T. D. Grant, \u201COf, For,\
    \ and By the People: The Legal Lacuna of Synthetic Persons.\u201D _Artificial\
    \ Intelligence & Law_, vol. 25, no. 3, pp. 273\u2013291, Sept. 2017.\n\u2022\_\
    \_\_\_\_M. Scheutz, \u201CThe Inherent Dangers of\nUnidirectional Emotional Bonds\
    \ between Humans and Social Robots,\u201D in _Robot Ethics: The Ethical and Social\
    \ Implications of Robotics,_ P. Lin, K. Abney, and G. Bekey, Eds., pp. 205. Cambridge,\
    \ MA: MIT Press, 2011.\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec5CFheImo8onTcd
  Tags:
  - affective-computing
  airtable_createdTime: '2023-06-05T06:05:11.000Z'
  airtable_id: rec2ULcHUjSbbSnHL
  title: How might AI deployed in care settings to foster intimate relationships impact
    on relationships among humans?
- Description: "\"Should affective systems be designed to nudge people\_for the user\u2019\
    s personal benefit and/or for the benefit of others?\n## Background\nManipulation\
    \ can be defined as an exercise of influence by one person or group, with the\
    \ intention to attempt to control or modify the actions of another person or group.\
    \ Thaler and Sunstein (2008) call the tactic of subtly modifying behavior a \u201C\
    nudge4\u201D. Nudging mainly operates through the affective elements of a human\
    \ rational system. Making use of a nudge might be considered appropriate in situations\
    \ like teaching children, treating drug dependency, and in some healthcare settings.\
    \ While nudges can be deployed to encourage individuals to express behaviors that\
    \ have community benefits, a nudge could have unanticipated consequences for people\
    \ whose backgrounds were not well considered in the development of the nudging\
    \ system5. Likewise, nudges may encourage behaviors with unanticipated long-term\
    \ effects, whether positive or negative, for the\_individual and/or society. The\
    \ effect of\_A/IS nudging a person, such as potentially eroding or encouraging\
    \ individual liberty, or expressing behaviors that are for the benefit others,\
    \ should be well characterized in the design of A/IS.\n## Recommendations\n1\\\
    .\_\_\_Systematic analyses are needed that examine the ethics and behavioral consequences\
    \ of designing affective systems to nudge human beings prior to deployment.\n\
    2\\.\_\_\_The user should be empowered, through an explicit opt-in system and\
    \ readily available, comprehensible information, to recognize different types\
    \ of A/IS nudges, regardless of whether they seek to promote beneficial social\
    \ manipulation or to enhance consumer acceptance of commercial goals. The user\
    \ should be able to access and check facts behind the nudges and then make a conscious\
    \ decision to accept or reject a nudge. Nudging systems must be transparent, with\
    \ a clear chain of accountability that includes human agents: data logging is\
    \ required so users can know how, why, and by whom they were nudged.\n3\\.\_\_\
    \_A/IS nudging must not become coercive and should always have an opt-in system\
    \ policy with explicit consent.\_\n4\\.\_\_\_Additional protections against unwanted\
    \ nudging must be put in place for vulnerable populations, such as children, or\
    \ when informed consent cannot be obtained. Protections against unwanted nudging\
    \ should be encouraged when nudges alter long-term behavior or when consent alone\
    \ may not be\_a sufficient safeguard against coercion\_or exploitation.\n5\\.\_\
    \_\_Data gathered which could reveal an individual or groups\u2019 susceptibility\
    \ to a nudge or their emotional reaction to a nudge should not be collected or\
    \ distributed without opt-in consent, and should only be retained transparently,\
    \ with access restrictions in compliance with the highest requirements of data\
    \ privacy and law.\n## Further Resources\n\u2022\_\_\_\_\_R. Thaler, and C. R.\
    \ Sunstein, _Nudge: Improving Decision about Health, Wealth and Happiness_, New\
    \ Haven, CT: Yale University Press, 2008.\n\u2022\_\_\_\_\_L. Bovens, \u201CThe\
    \ Ethics of Nudge,\u201D in _Preference change: Approaches from Philosophy, Economics\
    \ and Psychology_, T. Gr\xFCne-Yanoff and S. O. Hansson, Eds., Berlin, Germany:\
    \ Springer, 2008 pp. 207\u2013219.\n\u2022\_\_\_\_\_S. D. Hunt and S. Vitell.\
    \ \"A General Theory of Marketing Ethics.\" Journal of Macromarketing, vol.6,\
    \ no. 1, pp. 5-16, June 1986.\n\u2022\_\_\_\_\_A. McStay, [Empathic Media and\
    \ Advertising: Industry, Policy, Legal and Citizen Perspectives (the Case for\
    \ Intimacy)](http://journals.sagepub.com/doi/pdf/10.1177/2053951716666868), Big\
    \ Data & Society, pp. 1-11, December 2016.\n\u2022\_\_\_\_\_J. de Quintana Medina\
    \ and P. Hermida Justo, \u201CNot All Nudges Are Automatic: Freedom of Choice\
    \ and Informative Nudges.\u201D Working paper presented to the European Consortium\
    \ for Political Research, Joint Session of Workshops, 2016 Behavioral Change and\
    \ Public Policy, Pisa, Italy, 2016.\n\u2022\_\_\_\_\_ M. D. White, _[The Manipulation\
    \ of Choice. Ethics and Libertarian Paternalism. ](http://www.palgraveconnect.com/doifinder/10.1057/9781137313577)_New\
    \ York: Palgrave Macmillan, 2013\n\u2022\_\_\_\_\_C.R. Sunstein, The Ethics of\
    \ Influence: Government in the Age of Behavioral Science. New York: Cambridge,\
    \ 2016\n\u2022\_\_\_\_\_M. Scheutz, \u201C[The Affect Dilemma for Artificial Agents:\
    \ Should We Develop Affective Artificial Agents? ](http://ieeexplore.ieee.org/document/6296668/)\u201D\
    \ _IEEE Transactions on Affective Computing, _vol._ _3, no. 4,pp. 424\u2013433,\_\
    Sept. 2012.\n\u2022\_\_\_\_\_A. Grinbaum, R. Chatila, L. Devillers, J.G. Ganascia,\
    \ C. Tessier and M. Dauchet. \u201C[Ethics in Robotics Research: CERNA Recommendations,](http://ieeexplore.ieee.org/document/7822928/)\u201D\
    \ _IEEE Robotics and Automation Magazine, _vol._ _24, no. 3,pp. 139\u2013145,\
    \ Sept. 2017.\n\u201CDesigning Moral Technologies: Theoretical, Practical, and\
    \ Ethical Issues\u201D Conference July 10\u201315, 2016, Monte Verit\xE0, Switzerland\"\
    \n\np.96-97\n\n\"Governmental entities may potentially use nudging strategies,\
    \ for example to promote the performance of charitable acts. Does the practice\
    \ of nudging for the benefit\_of society, including nudges\_by affective systems,\
    \ raise\_ethical concerns?\n## Background\nA few scholars have noted a potentially\
    \ controversial practice of the future: allowing a robot or another affective\
    \ system to nudge a user for the good of society6. For instance, if it is possible\
    \ that a well-designed robot could effectively encourage humans to perform charitable\
    \ acts, would it be ethically appropriate for the robot to do so? This design\
    \ possibility illustrates just one behavioral outcome that a robot could potentially\
    \ elicit from a user.\nGiven the persuasive power that an affective system may\
    \ have over a user, ethical concerns related to nudging must be examined. This\
    \ includes the significant potential for misuse.\n## Recommendations\n1\\.\_\_\
    \_As more and more computing devices subtly and overtly influence human behavior,\
    \ it is important to draw attention to whether it is ethically appropriate to\
    \ pursue this type of design pathway in the context of governmental actions.\n\
    2\\.\_\_\_ There needs to be transparency regarding who the intended beneficiaries\
    \ are, and whether any form of deception or manipulation is going to be used to\
    \ accomplish the intended goal.\n## Further Resources\n\u2022\_\_\_\_\_J. Borenstein\
    \ and R. Arkin, \u201C[Robotic Nudges: Robotic Nudges: The Ethics of Engineering\
    \ a More Socially Just Human Being Just Human Being.](https://link.springer.com/article/10.1007/s11948-015-9636-2?no-access=true)\u201D\
    \ _Science and Engineering Ethics, _vol._ _22, no. 1,pp. 31\u201346, Feb. 2016.\n\
    \u2022\_\_\_\_\_J. Borenstein and R. Arkin. \u201C[Nudging for Good: Robots and\
    \ the Ethical Appropriateness of Nurturing Empathy and Charitable Behavior ](https://link.springer.com/article/10.1007/s00146-016-0684-1?no-access=true).\u201D\
    \ _AI and Society, _vol._ _32, no. 4, pp. 499\u2013507, Nov. 2016.\"\np.97-98\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - rec9TbOu2ZXUZG4A5
  Tags:
  - nudge-deception
  airtable_createdTime: '2023-06-05T06:13:01.000Z'
  airtable_id: rec2ajglpzbFYRivi
  title: Should affective AI nudge users for personal or societal benefit?
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  ChallengeInstances:
  - recpoXmwIiqv3BMWJ
  - recT8ABqanoxK9Qu0
  - recRU6VBHZccmYrln
  - recp8G9ek0g3RAnEC
  - recbjinwvxQkFttqg
  - rec3XoC08SiG83eK0
  - recg4TZqdeqZcnd1w
  - recu8eBgTi3OTRRij
  - recAZ41hiDOn9aTOl
  - recv7IjfbiXBr4A5q
  - recfGEm2rcOTFEZVZ
  Description: "**Considerations for ethical AI include clarity or accountability\
    \ regarding the purposes of technology, and its role in decision processes.**\
    \ **Clarity** underpins responsible use of technology, and **informed engagement\
    \ (and consent)** with it. **Accountability** of AI's use by humans, to humans\
    \ underpins **respect for persons**. However, achieving clarity and accountability\
    \ may be challenging where there are different levels of expertise regarding the\
    \ technology, and understandings of the contexts into which technology may be\
    \ deployed. An aim of learning environments should be to develop agency, but this\
    \ may be stymied by systems that - however accurate - may not adequately explain\
    \ decisions so they are understood to a wide range of learners, or that limit\
    \ choices for either teachers or learners.\n\nAreas of technology development\
    \ and use, as other areas of applied research, inherently involve understanding\
    \ both of the technical features of research (methods, tools, etc.), and its practical\
    \ context including stakeholders. This kind of research requires engagement of\
    \ expertise from stakeholders in the contexts into which AI will be deployed,\
    \ and of research expertise from both technical and social disciplines. This involvement\
    \ should not be siloed, instead there should be engagement across those involved.\
    \ This can be challenging given the different areas and levels of expertise each\
    \ group may have. \nUnderstanding of the ethical issues arising from research\
    \ is one area where this transdisciplinary work is important. Effective development\
    \ of AI for use in society requires a level of 'AI literacy' among stakeholders,\
    \ engagement with transparency and explanation among providers, and an understanding\
    \ of the - dynamic - social context into which any technology may be deployed.\
    \ \n\n\n\"More institutional resources and incentive structures are necessary\
    \ to bring A/IS engineers and designers into sustained and constructive contact\
    \ with ethicists, legal scholars, and social scientists, both in academia and\
    \ industry. This contact is necessary as it can enable meaningful interdisciplinary\
    \ collaboration and shape the future of technological innovation. More could be\
    \ done to develop methods, shared knowledge, and lexicons that would facilitate\_\
    such collaboration.\nThis issue relates, among other things, to funding models\
    \ as well as the lack of diversity of backgrounds and perspectives in A/IS-related\
    \ institutions and companies, which limit cross-pollination between disciplines.\
    \ To help bridge this gap, additional translation work and resource sharing, including\
    \ websites and Massive Open Online Courses (MOOCs), need to happen among technologists\
    \ and other relevant experts, e.g., in medicine, architecture, law, philosophy,\
    \ psychology, and cognitive science. Furthermore, there is a need for more cross-disciplinary\
    \ conversation and multi-disciplinary research, as is being done, for instance,\
    \ at the annual ACM Fairness, Accountability, and Transparency (FAT\\*) conference\
    \ or the work done by the Canadian Institute For Advanced Research (CIFAR), which\_\
    is developing Canada\u2019s AI strategy.\nFunding models and institutional incentive\
    \ structures should be reviewed and revised to prioritize projects with interdisciplinary\
    \ ethics components to encourage integration of ethics into projects at all levels.\n\
    ### Further Resources\n- S. Barocas, Course Material for Ethics and Policy in\
    \ Data Science, Cornell University, 2017.\n- L. Floridi, and M. Taddeo. \u201C\
    What Is Data Ethics?\u201D _Philosophical Transactions of the Royal Society, _vol._\
    \ _374, no. 2083, 1\u20134. DOI[10.1098/ rsta.2016.0360,](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124072/)\
    \ 2016.\n- S. Spiekermann, Ethical IT Innovation: A ValueBased System Design Approach.\
    \ Boca Raton, FL: Auerbach Publications, 2015.\n- K. Crawford, \u201C[Artificial\
    \ Intelligence\u2019s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1)\u201D\
    , _New York Times_, July 25, 2016. [Online]. Available: [http://www.nytimes. com/2016/06/26/opinion/sunday/artificialintelligences-white-guy-problem.html?\\\
    _r=1](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?_r=1).\
    \ [Accessed October 28, 2018].\"\np.123-124\n\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recsonQhKLmX4D1ao
  Tags:
  - research
  - AI
  airtable_createdTime: '2023-06-18T14:17:02.000Z'
  airtable_id: rec3T1WLC4dg63qyI
  title: Effective use of AI inherently involves multiple stakeholder and disciplinary
    expertise, including both AI literacy and contextual awareness across cultures
- Description: "\"How can A/IS creators incorporate well-being into\_their work?\n\
    ## Background\nWithout practical ways of incorporating well-being metrics to guide,\
    \ measure, and monitor impact, A/IS will likely lack fall short of its potential\
    \ to avoid harm and promote well-being. Incorporating well-being thinking into\
    \ typical organizational processes of design, prototyping, marketing, etc., suggests\
    \ a variety of adaptations.\nOrganizations and A/IS creators should consider clearly\
    \ defining the type of A/IS product or service that they are developing, including\
    \ articulating its intended stakeholders and uses. By defining typical uses, possible\
    \ uses, and finally unacceptable uses of the technology, creators will help to\
    \ spell out the context of well-being. This can help to identify possible harms\
    \ and risks given the different possible uses and end users, as well as intended\
    \ and unintended positive consequences.\nAdditionally, internal and external stakeholders\
    \ should be extensively consulted to ensure that impacts are thoroughly considered\
    \ through an iterative and learning stakeholder engagement process. After consultation,\
    \ A/IS creators should select appropriate well-being indicators based on the possible\
    \ scope and impact of their A/IS product or service. These well-being indicators\
    \ can be drawn from mainstream sources and models and adapted as necessary. They\
    \ can be used to engage in pre-assessment of the intended user population, projection\
    \ of possible impacts, and post-assessment. Development of a well-being indicator\
    \ measurement plan and relevant data infrastructure will support a robust integration\
    \ of well-being. A/IS models can also be trained to explicitly include well-being\
    \ indicators as subgoals.\nData and discussions on well-being impacts can be used\
    \ to suggest improvements and modifications to existing A/IS products and services\
    \ throughout their lifecycle. For example, a [team](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)\
    \ [seeking to increase the well-being o](https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf)f\
    \ people using wheelchairs found that when provided the opportunity to use a smart\
    \ wheelchair, some users were delighted with the opportunity for more mobility,\
    \ while others felt it would decrease their opportunities for social contact,\
    \ increase their sense of isolation, and lead to an overall decrease in their\
    \ well-being. Therefore, even though a product modification may increase well-being\
    \ according to one indicator or set of A/IS stakeholders, it does not mean that\
    \ this modification should automatically be adopted.\nFinally, organizational\
    \ processes can be modified to incorporate the above strategies. Appointment of\
    \ an organizational lead person for well-being impacts, e.g., a well-being lead,\
    \ ombudsman,\_or officer can help to facilitate this effort.\n## Recommendation\n\
    A/IS creators should adjust their existing development, marketing, and assessment\
    \ cycles to incorporate well-being concerns throughout their processes. This includes\
    \ identification of an A/IS lead ombudsperson or officer; identification of stakeholders\
    \ and end users; determination of possible uses, harm and risk assessment; robust\
    \ stakeholder engagement; selection of well-being indicators; development of a\
    \ well-being indicator measurement plan; and ongoing improvement of A/IS products\
    \ and services throughout the lifecycle.\n## Further Resources\n\u2022\_\_\_\_\
    \_[Peter Senge and the Learning Organization](http://infed.org/mobi/peter-senge-and-the-learning-organization/)[\
    \ -](https://api.ag.purdue.edu/api/depotws/File.ashx?t=f&i=11736)\n(synopsis)\
    \ Purdue University\n\u2022\_\_\_\_\_Stakeholder Engagement: A Good Practice Handbook\
    \ for Companies Doing Business in Emerging Markets. International Finance Corporation,\
    \ May 2007.\n\u2022\_\_\_\_\_[Global Reporting Initiative](https://www.globalreporting.org/Pages/default.aspx)\n\
    \u2022\_\_\_\_\_ [GNH Certification](http://www.bhutanstudies.org.bt/gnh-certification/),\
    \ Centre for Bhutan\_and GNH Studies, 2018.\u2022\_\_\_\_\_J. Helliwell, R. Layard,\
    \ and J. Sachs, Eds., \u201CThe Objective Benefits of Subjective Well-Being,\u201D\
    \ in [World Happiness Report ](http://worldhappiness.report/ed/2013/)2013. New\
    \ York: UN Sustainable Development Solutions Network, pp. 54-79, 2013.\n\u2022\
    \_\_\_\_\_[Global Happiness and Well-being Policy Report](http://www.happinesscouncil.org/)\
    \ by the Global Happiness Council, 2018.\"\n\np.78-79\n"
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  - recfcXzM3foqFNNGN
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:53:34.000Z'
  airtable_id: recA7Kh502s4UKWGo
  title: How do we incorporate wellbeing considerations into AI impact measurement
    and monitoring?
- Cases:
  - recSXcY4cnofb4zTP
  ChallengeInstances:
  - recHHvfADKIkX9idP
  - rec284Ax8lKHt4ljQ
  - recfjoQZIVhT0C5pW
  - recTaaKAtPIfbenZv
  - recVGVVfuoL5sr3oo
  - recI3S7M3KOMg2C4m
  Description: "Privacy and confidentiality expectations are bound up in cultural\
    \ norms, and other aspects of particular contexts, with emerging challenges regarding\
    \ potential for re-identification of participant data. \nData quality, integrity,\
    \ and governance are a consideration of respect for persons. \n- **Data quality\
    \ **represents the reliability and validity of the data, key features in respecting\
    \ persons through how we represent them. \n- **Data integrity **represents the\
    \ security of the data from manipulation or corruption, ensuring data can be used\
    \ for its purpose.\n\n\u201CThreats to privacy are posed by AI systems both as\
    \ a result of their design and development processes, and as a result of their\
    \ deployment. As AI projects are anchored in the structuring and processing of\
    \ data, the development of AI technologies will frequently involve the utilisation\
    \ of personal data. This data is sometimes captured and extracted without gaining\
    \ the proper consent of the data subject or is handled in a way that reveals (or\
    \ places under risk the revelation of) personal information. On the deployment\
    \ end, AI systems that target, profile, or nudge data subjects without their knowledge\
    \ or consent could in some circumstances be interpreted as infringing upon their\
    \ ability to lead a private life in which they are able to intentionally manage\
    \ the transformative effects of the technologies that influence and shape their\
    \ development. This sort of privacy invasion can consequently harm a person\u2019\
    s more basic right to pursue their goals and life plans free from unchosen influence.\u201D\
    \ (Leslie, 2019, p. 5) \n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  Principles:
  - recPg7Ov0priGGtLm
  Reference:
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-05-18T19:10:38.000Z'
  airtable_id: recBc3GCNokDL220T
  title: 'Privacy, confidentiality, data integrity and cultural norms '
- OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recLHILkx2JDFsLbX
  - recmzjcGKv3yNOxbl
  Principles:
  - recU6u0AZbcNj1ik9
  - reczVPIH1y2OMpAJH
  - rec42P8U9usfYCtv9
  Tags:
  - AI
  airtable_createdTime: '2023-05-18T13:41:32.000Z'
  airtable_id: recCpTJXuuowqsqQa
  title: Incidental findings
- Description: "\"How can A/IS creators influence A/IS goals to ensure well-being,\
    \ and what can A/IS creators learn or borrow from existing models in the well-being\
    \ and other arenas?\n## Background\nAnother way to incorporate considerations\
    \ of well-being is to include well-being measures\_in the development, goal setting,\
    \ and training\_of the A/IS systems themselves.\nIdentified metrics of well-being\
    \ could be formulated as auxiliary objectives of the A/IS. As these auxiliary\
    \ well-being objectives will be only a subset of the intended goals of the system,\
    \ the architecture will need to balance multiple objectives. Each of these auxiliary\
    \ objectives may be expressed as a goal, set of rules, set of values, or as a\
    \ set of preferences, which can be weighted and combined using established methodologies\
    \ from intelligent systems engineering.\_\nFor example, an educational A/IS tool\
    \ could not only optimize learning outcomes, but also incorporate measures of\
    \ student social and emotional education, learning, and thriving.\nA/IS-related\
    \ data relates both to the individual\u2014 through personalized algorithms, in\
    \ conjunction with affective sensors measuring and influencing emotion, and other\
    \ aspects of individual well-being \u2014and to society as large data sets representing\
    \ aggregate individual subjective and objective data. As the exchange of this\
    \ data becomes more widely available via establishing tracking methodologies,\
    \ the data can be aligned within A/IS products and services to increase human\
    \ well-being. For example, robots like [Pepper](https://www.sbs.com.au/news/dateline/article/2017/04/11/love-intimacy-and-companionship-tale-robots-japan)\
    \ are equipped to share data regarding their usage and interaction with humans\
    \ to the cloud. This allows almost instantaneous innovation, as once an action\
    \ is validated as useful for one Pepper robot, all other Pepper units (and ostensibly\
    \ their owners) benefit as well. As long as this data exchange happens with the\
    \ predetermined consent of the robots\u2019 owners, this innovation in real time\
    \ model can be emulated for the large-scale aggregation of information relating\
    \ to existing well-being metrics.\nA/IS creators can also help to operationalize\
    \ well-being metrics by providing stakeholders with reports on the expected or\
    \ actual outcomes of the A/IS and the values and objectives embedded in the systems.\
    \ This transparency will help creators, users, and third parties assess the state\
    \ of well-being produced by A/IS and make improvements in A/IS. In addition, A/IS\
    \ creators should consider allowing end users to layer on their own preferences,\
    \ such as allowing users to limit their use of an A/IS product if it leads to\
    \ increased sustained stress levels, sustained isolation, development of unhealthy\
    \ habits, or other decreases to well-being.\_\nIncorporating well-being goals\
    \ and metrics into broader organizational values and processes would support the\
    \ use of well-being metrics as there would be institutional support. A key factor\
    \ in industrial, corporate, and societal progress is cross-dissemination of concepts\
    \ and models from one industry or field to another. To date, a number of successful\
    \ concepts and models exist in the fields of sustainability, economics, industrial\
    \ design and manufacturing, architecture and urban development, and governmental\
    \ policy. These concepts and models can provide a foundation\_for building a metrics\
    \ standard and the use of wellbeing metrics by A/IS creators, from conception\
    \ and design to marketing, product updates, and improvements to the user experience.\_\
    \n## Recommendation\nCreate technical standards for representing goals, metrics,\
    \ and evaluation guidelines for well-being metrics and their precursors and components\
    \ within A/IS that include:\n\u2022\_\_\_\_\_[O](https://en.wikipedia.org/wiki/Ontology_(information_science))ntologies\
    \ for representing technological requirements.\n\u2022\_\_\_\_\_A testing framework\
    \ for validating adherence to well-being metrics and ethical principles such as\
    \ [IEEE P7010\u2122 Standards Project for Wellbeing Metric for Autonomous and\
    \ Intelligent Systems](https://standards.ieee.org/project/7010.html).\nabove as\
    \ well as others as a basis for a wellbeing metrics standard for A/IS creators.\
    \ _(See page 191, [Additional Resources: Additional Resources: Standards Development\
    \ Models and Frameworks)](https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead1e_standards_development_models_frameworks.pdf)_\n\
    \u2022\_\_\_\_\_The development of a well-being metrics standard for A/IS that\
    \ encompasses an understanding of well-being as holistic and interlinked to social,\
    \ economic, and ecological systems.\n\_\n## Further Resources\n\u2022\_\_\_\_\_\
    A.F.T Winfield, C. Blum, and W. Liu. \u201C[Towards an Ethical Robot: Internal\
    \ Models, Consequences and Ethical Action Selection](https://link.springer.com/chapter/10.1007/978-3-319-10401-0_8),\u201D\
    \ in Advances in Autonomous Robotics Systems. Springer, 2014, pp. 85\u201396\n\
    \u2022\_\_\_\_\_R. A. Calvo, and D. Peters. [Positive Computing: Technology for\
    \ Well-Being and Human Potential](https://mitpress.mit.edu/books/positive-computing)._\
    \ _Cambridge MA: MIT Press, 2014.\n\u2022\_\_\_\_\_Y. Collette, and P. Slarry.\
    \ [Multiobjective Optimization: Principles and Case Studies ](https://link.springer.com/book/10.1007%2F978-3-662-08883-8)\n\
    (Decision Engineering Series). Berlin, Germany:\nSpringer, 2004. doi: 10.1007/978-3-662-08883-8.\n\
    \u2022\_\_\_\_\_J. Greene, et al. \u201C[Embedding Ethical Principles in Collective\
    \ Decision Support Systems](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12457),\u201D\
    \ in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence_,\
    \ _4147\u20134151. Palo Alto, CA: AAAI Press, 2016.\n\u2022\_\_\_\_\_L. Li, I.\
    \ Yevseyeva, V. Basto-Fernandes, H. Trautmann, N. Jing, and M. Emmerich,\u201C\
    [Building and Using an Ontology of Preference-Based Multiobjective Evolutionary\
    \ Algorithms.](https://dl.acm.org/citation.cfm?id=3088704)\u201D In 9th International\
    \ Conference on Evolutionary Multi-Criterion Optimization\u2014Volume 10173 (EMO\
    \ O. Sch\xFCtze, M. Wiecek, Y. Jin, and C. Grimme, Eds., Vol. 10173. Springer-Verlag,\
    \ Berlin, Heidelberg, 406-421, 2017.\n\u2022\_\_\_\_\_[PositiveSocialImpact:](https://invis.io/9874GSJS6)\
    \ Empowering people, organizations and planet with information and knowledge to\
    \ make a positive impact to sustainable development, 2017.\n\u2022\_\_\_\_\_D.K.\
    \ Ura, Bhutan\u2019s [Gross National Happiness Policy Screening Tool](http://www.grossnationalhappiness.com/docs/GNH/PDFs/PoliSTools.pdf).\n\
    \"\np.79-81\n"
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  - recLHILkx2JDFsLbX
  Principles:
  - recQ9DIFEsOEkCx3O
  - receFm7cGasHwpJZO
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:54:42.000Z'
  airtable_id: recGRpoF7DA23ODSj
  title: How do we incorporate wellbeing considerations into AI design/development/use?
- ChallengeInstances:
  - recX9rdsAGiONXTVd
  - recQWEzfzmzmfstG9
  - recsYgGzgIK80qUCT
  - recQmyVULN0OuFA2s
  - recQtuMpX4WaAoHhG
  - rec5l10QTYprjeewa
  - recJOwTAhuoamQM7C
  - recz5LeVOgbgic8Jk
  - recBfwOfoB68ghQAV
  Description: "AI and associated infrastructure has shifted relationships of researchers\
    \ and participants through greater secondary use of data, online platforms that\
    \ connect (sometimes invisibly) participants to researchers, heightened risks\
    \ of re-identification, and tools that may be used in unanticipated contexts.\
    \ \nIn some cases, research may be conducted under the auspices of 'quality improvement'\
    \ or operational research. In such cases the research is carried out to improve\
    \ existing practices within the research site; there may be alternative ethics\
    \ approval processes for such research. This kind of research has the advantage\
    \ of being located at the site of implementation. Complex power dynamics should\
    \ be considered between researchers (who may fulfil dual roles), and other stakeholders\
    \ such as teachers, students, administrators, and technology providers.\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recLHILkx2JDFsLbX
  Principles:
  - recKdujFoPJr4ZAhZ
  - recPg7Ov0priGGtLm
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'franzke, aline shakti, Bechmann, A., Zimmer, M., Ess, C., & Association of Internet
    Researchers (AoIR). (2020). Internet Research: Ethical Guidelines 3.0 Association
    of Internet Researchers. AoIR. https://aoir.org/reports/ethics3.pdf'
  - 'Markham, A., & Buchanan, E. (2012). Ethical Decision-Making and Internet Research:
    Recommendations from the AoIR Ethics Working Committee (Version 2.0). AoIR. https://aoir.org/reports/ethics2.pdf'
  - Fedoruk, L. (2017b). Ethics in The Scholarship of Teaching and Learning. University
    of Calgary Taylor Institute for Teaching and Learning. https://taylorinstitute.ucalgary.ca/resources/ethics-scholarship-teaching-and-learning
  Sources:
  - recpXl48pJdKDhc6f
  - rec6r8OkE2Q2EdiM3
  - recQiVQ7CTC72xp6O
  - recQzldmBLByP78Uu
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:17:55.000Z'
  airtable_id: recJ6khG2kY2Tx5ae
  title: Interactions and distance between researchers and participants are central
    to research, both when proximal, and when mediated by technologies.
- Description: "\"**Issue:** The right to truthful information is key to a democratic\
    \ society and to achieving sustainable development and a more equal world, but\
    \ A/IS poses risks to this right that must be managed.\n## Background\nSocial\
    \ media have become the dominant technological infrastructure for the dissemination\
    \ of information such as news, opinion, advertising, etc., and are currently in\
    \ the vanguard of the movement toward customized/targeted information based on\
    \ user profiling that involves significant use of A/IS techniques. Analysis of\
    \ opinion polls and trends in social networks, blogs, etc., and of the emotional\
    \ response to news items can be used for the purposes of manipulation, facilitating\
    \ both the selection of news that guides public opinion in the desired direction\
    \ and the practice of sensationalism.\nThe \"personalization of the consumer experience\"\
    , that is, the adaptation of articles to the interests, political vision, cultural\
    \ level, education, and geographic location of the reader, is a new challenge\
    \ for the journalism profession that expands the possibilities of manipulation.\n\
    The information infrastructure is currently lacking in transparency, such that\
    \ it is difficult or impossible to know (except perhaps for the infrastructure\
    \ operator):\n\u2022\_\_\_\_\_what private information is being collected for\n\
    user profiling and by whom,\n\u2022\_\_\_\_\_which groups are targeted and by\
    \ whom,\n\u2022\_\_\_\_\_what information has been received by any given targeted\
    \ group,\n\u2022\_\_\_\_\_who financed the creation and dissemination of this\
    \ information,\n\u2022\_\_\_\_\_the percentage of the information being disseminated\
    \ by bots, and\n\u2022\_\_\_\_\_who is financing these bots.\nMany actors have\
    \ found this opaque infrastructure ideal for spreading politically motivated disinformation,\
    \ which has a negative effect on the creation of a more equal world, democracy,\
    \ and the respect for fundamental rights. This disinformation can have tragic\
    \ consequences. For instance, human rights groups have unearthed evidence that\
    \ the military authorities of Myanmar used Facebook for inciting hatred against\
    \ the Rohingya Muslim minority, hatred which facilitated an ethnic cleansing campaign\
    \ and the murder of up to 50,000 people.14 The UN determined that these actions\
    \ constituted genocide, crimes against humanity, and war crimes.15\n## Recommendations\n\
    To protect democracy, respect fundamental rights, and promote sustainable development,\
    \ governments should implement a legislative agenda which prevents the spread\
    \ of misinformation and hate speech, by:\n\u2022\_\_\_\_\_Ensuring more control\
    \ and transparency in the use of A/IS techniques for user profiling in order to\
    \ protect privacy and prevent user manipulation.\n\u2022\_\_\_\_\_Using A/IS techniques\
    \ to detect untruthful information circulating in the infrastructures, overseen\
    \ by a democratic body to prevent potential censorship.\n\u2022\_\_\_\_\_Obliging\
    \ companies owning A/IS infrastructures to provide more transparency regarding\
    \ their algorithms, sources of funding, services, and clients.\n\u2022\_\_\_\_\
    \_Defining a new legal status somewhere between \"platforms\" and \"content providers\"\
    \ for A/IS infrastructures.\n\u2022\_\_\_\_\_ Reformulating the deontological\
    \ codes of the journalistic profession to take into account the intensive use\
    \ of A/IS techniques foreseen\_in the future. \u2022\_\_\_\_\_Promoting the right\
    \ to information in official documents, and developing A/IS techniques to automate\
    \ journalistic tasks such as verification of sources and checking the accuracy\
    \ of the information in official documents, or in the selection, hierarchy, assessment,\
    \ and development of news, thereby contributing to objectivity and reliability.\n\
    ## Further Resources\n\u2022\_\_\_\_\_M. Broussard, \u201CArtificial Iintelligence\
    \ for Investigative Reporting: Using an expert system to enhance journalists\u2019\
    \ ability to discover original public affairs stories.\u201D Digital Journalism,\
    \ vol. 3, no. 6, pp. 814-831, 2015.\n\u2022\_\_\_\_\_M. Carlson, \u201CThe robotic\
    \ reporter: Automated journalism and the redefinition of labor, compositional\
    \ forms, and journalistic authority.\u201D Digital Journalism, vol. 3, no. 3,\
    \ pp. 416-431, 2015.\n\u2022\_\_\_\_\_A. L\xF3pez Barriuso, F. de la Prieta Pintado,\
    \ \xC1. Lozano Murciego, , D. Hern\xE1ndez de la Iglesia and J. Revuelta Herrero,\
    \ JOUR-MAS: A Multiagent System Approach to Help Journalism Management, vol. 4,\
    \ no. 4, 2015.\n\u2022\_\_\_\_\_P. Mozur, \u201DA Genocide Incited on Facebook\
    \ with Posts from Myanmar\u2019s Military,\u201D _The New York Times,_ Oct. 15\
    \ 2018. [https:// www.nytimes.com/2018/10/15/technology/ myanmar-faceboo.k-genocide.html](https://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html)\n\
    \u2022\_\_\_\_\_UK Parliament, House of Commons, Digital, Culture, Media and Sport\
    \ Committee Disinformation and \u2018fake news\u2019: Interim Report, Fifth Report\
    \ of Session 2017\u201319UK Parliament, Published on July 29, 2018\"\np.142-144\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recqJAVTtqOUfypNI
  airtable_createdTime: '2023-06-05T11:18:00.000Z'
  airtable_id: recJV8yTX0MnF3rGD
  title: AI poses risks to the right to truthful information
- ChallengeInstances:
  - recC8IlVKWmMHOorw
  - rec1UyKLba4O7X6ax
  Description: "Through the inception, design, development, implementation, evaluation,\
    \ and decommissioning human control of technology is central to considerations\
    \ of autonomy, accountability, and human oversight of AI. That is because AI has\
    \ the potential to diminish autonomy and thus influence democratic participation\
    \ and human flourishing.\_\nTechnologies may automate aspects of human decision\
    \ making in ways that may diminish human autonomy, and where it is not always\
    \ transparent what basis decisions are made on, or the evidence that systems perform\
    \ to an acceptable level in these decisions.\n"
  airtable_createdTime: '2023-06-18T18:10:44.000Z'
  airtable_id: recSONq7KetYgyg6K
  title: Human control of technology and accountability for technology use
- ChallengeInstances:
  - recuFqYoT6MFNqspL
  - recwl0AdKj2HLIpDB
  - rec3wCdnHy3TpLuya
  - rec4F8A2UI0uvFh3O
  - reccjN6q8gegWbrUE
  - rec16WOKdMVKAiBSJ
  - recUMRucTbQ7tySEW
  - reciceYsMfOtPdaaA
  Description: "AI has potential to have impact beyond just on the participants involved\
    \ into society, and it may not be clear what these impacts will be.\nImmediate\
    \ or proximal impacts are those experienced in the immediate context, for example\
    \ in interactions of researcher-participant groups. Indirect, long-range, and\
    \ dual-use impacts relate to the potential for:\n- secondary impacts that are\
    \ not a direct use of a tool but may relate to system changes that occur as a\
    \ result;\n- that these impacts may occur over a longer period than the immediate\
    \ context of research, which is ordinarily the context for which ethics approval\
    \ is provided\n- and that some effects may arise from unintended uses of dual-use\
    \ technologies, for example facial recognition developed for one purpose may be\
    \ used for surveillance or military purposes.\n\n**\"Issue: **A/IS are often viewed\
    \ only as having impact in market contexts, yet these technologies also have an\
    \ impact on social relations and culture.\nA/IS are expected to have an impact\
    \ beyond market domains and business models, diffusing throughout the global society.\
    \ For instance,\_A/IS have and will impact social relationships\_in a way similar\
    \ to how mobile phones changed our daily lives, reflecting directly on our culture,\
    \ customs, and language. The extent and direction of this impact is not yet clear,\
    \ but documented experience in HIC and high internet-penetration environments\
    \ of trolls, \u201Cfake news,\u201D and cyberbullying on social media offer a\
    \ cautionary tale.11 Depression, social isolation, aggression, and the dissemination\
    \ of violent behavior with damage to human relations, so extreme that, in some\
    \ cases, it has resulted in suicide, are all correlated with the internet.12 As\
    \ an example, the technology for \u201Csmart homes\u201D has been used for inflicting\
    \ domestic violence by remotely locking doors, turning off heat/AC, and otherwise\
    \ harassing a partner. This problem could be easily extended to include elder\
    \ and child abuse.13 Measures need to be developed to prevent A/IS from contributing\
    \ to the emergence or amplification of social disorders.\" (IEEE, 2019, p.141-142)\n"
  OverarchingPrinciples:
  - recNB5h9bK4gEE9uc
  Principles:
  - recNB5h9bK4gEE9uc
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  - recK1gdkh8c01WaXx
  - rec7daqDHSCuc70yS
  Tags:
  - AI
  - indirect-impacts
  - wellbeing
  airtable_createdTime: '2023-05-18T18:54:26.000Z'
  airtable_id: recWPbL5kB1Yh5OPf
  title: Research produces both direct impact, on participants and then society, while
    also giving rise to indirect, long-range, and dual-use impacts
- ChallengeInstances:
  - recxWhAXTqxMscDqr
  - recx5eWOlkkg11NJX
  - recVWprITnDX6u0QB
  - rec0d9XwyvbDuuuN6
  - rec1ldHV74MQeRllz
  - reck3lUFUtAhNes3Y
  - recPW66Z54lKwa7hR
  - recwVOVXU6zbH6KZ7
  - rec5nljdN28sNoK3X
  - recWNlnhyOUXmOo0Q
  - recg821VxieIJvgRO
  - recEeRFQm7xXJVNyu
  Description: |
    **Respect for human-human relationships, at individual and collective levels** AI has the potential to impact on how we connect and talk together, and the structure of societies. AI should avoid harms and promote pro-social engagement, recognising that both the benefits and harms of research (and broader engagement with technology) may accrue over groups.
  airtable_createdTime: '2023-06-18T18:55:37.000Z'
  airtable_id: recWxPEkLYUdWhd2q
  title: Respect for human-human relationships, at individual and collective levels
- Description: "\"**Issue: **A/IS are changing the nature of work, disrupting employment,\
    \ while technological change is happening too fast for existing methods of (re)training\
    \ the workforce.\n## Background\nThe current pace of technological development\
    \ will heavily influence changes in employment structure. In order to properly\
    \ prepare the workforce for such evolution, actions should be proactive and not\
    \ only reactive. The wave of automation caused by the A/IS revolution will displace\
    \ a very large share of jobs across domains and value chains. The U.S. \u201C\
    automated vehicle\u201D case study analyzed in the White House 2016 report_ Artificial\
    \ Intelligence, Automation, and the Economy _is emblematic of what is at stake:\
    \ \u201C2.2 to 3.1 million existing part- and full-time U.S. jobs are exposed\
    \ over the next two decades, although the timeline remains uncertain.\u201D18\n\
    The risk of unemployment for LMIC is more serious than for developed countries.\
    \ The industry of most LMIC is labor intensive. While labor may be cheap(er) in\
    \ LMIC economies, the ripple effects of A/IS and automation will be felt much\
    \ more than in the HIC economies. The 2016 World Bank Development Report stated\
    \ that the share of occupations susceptible to automation and A/IS is higher in\
    \ LMIC than in HIC, where such jobs have already disappeared. In addition, the\
    \ qualities which made certain jobs easy to outsource to LMIC where wages are\
    \ lower are those that may make them easy to automate.19 An offsetting factor\
    \ is the reality that many LMIC lack the communication, energy, and IT infrastructure\
    \ required to support highly automated industries.20 Notwithstanding this reality,\
    \ the World Bank estimated the automatable share of employment, unadjusted for\
    \ adoption time lag, for LMIC ranges from 85% in Ethiopia to 62% in Argentina,\
    \ compared to the OECD average of 57%.21\nIn the coming decades, the automation\
    \ wave calls for higher investment and the transformation of labor market capacity\
    \ development programs. Innovative and fair ways of funding such an investment\
    \ are required; the solutions should be designed in cooperation with the companies\
    \ benefiting from the increase of profitability, thanks to automation. This should\
    \ be done in a responsible way so that the innovation cycle is not broken, and\
    \ yet workforce capacity does not fall behind the needs of 21st century employment.\
    \ At the same time, A/IS and other digital technologies offer real potential to\
    \ innovate new approaches to job-search assistance, placement, and hiring processes\
    \ in the age of personalized services. The efficiency of matching labor supply\
    \ and demand can be tremendously enhanced by the rise of multisided platforms\
    \ and predictive analytics, provided they do not entrench discrimination.22 The\
    \ case of platforms, such as LinkedIn, for instance, with its 470 million registered\
    \ users, and online job consolidators such as indeed.com and Simply Hired, are\
    \ interesting as an evolution in hiring practices,\_at least for those able to\
    \ access the internet.\nTailored counseling and integrated retraining programs\
    \ also represent promising grounds for innovation. In addition, much will have\
    \ to be done to create fair and effective lifelong skill development/training,\
    \ infrastructures, and mechanisms capable of empowering millions of people to\
    \ viably transition jobs, sectors, and potentially locations, and to address differential\
    \ geographic impacts that exacerbate income and wealth disparities. Effectively\
    \ enabling the workforce to be more mobile\u2014physically, legally, and virtually\u2014\
    will be crucial. This implies systemic policy approaches which encompass housing,\
    \ transportation, licensing, tax incentives, and crucially in the age of A/IS,\
    \ universal broadband access, especially in rural areas of both HIC\_and LMIC.\n\
    ## Recommendations\nTo thrive in the A/IS age, workers must be provided training\
    \ in skills that improve their adaptability to rapid technological changes; programs\
    \ should be available to any worker, with special attention to the low-skilled\
    \ workforce. Those programs can be private, that is, sponsored by the employer,\
    \ or publicly and freely offered through specific public channels and government\
    \ policies, and should be available regardless of whether the worker is in between\
    \ jobs or still employed. Specific measures include:\n\u2022\_\_\_\_\_ Offering\
    \ new technical programs, possibly earlier than high school, to increase the workforce\
    \ capacity to close the skills gap and thrive in employment alongside A/IS. \u2022\
    \_\_\_\_\_Creating opportunities for apprenticeships, pilot programs, and scaling\
    \ up data-driven evidence-based solutions that increase employment and earnings.\n\
    \u2022\_\_\_\_\_Supporting new forms of public-private partnerships involving\
    \ civil society, as well as new outcome-oriented financial mechanisms, e.g., social\
    \ impact bonds, that help scale up successful innovations.\n\u2022\_\_\_\_\_Supporting\
    \ partnerships between universities, innovation labs in corporations, and governments\
    \ to research and incubate startups for A/IS graduates.23\n\u2022\_\_\_\_\_Developing\
    \ regulations to hold corporations responsible for employee retraining necessary\
    \ due to increased automation and other technological applications having impact\_\
    on the workforce.\n\u2022\_\_\_\_\_Facilitating private sector initiatives by\
    \ public policy for co-investment in training and retraining programs through\
    \ tax incentives.\n\u2022\_\_\_\_\_Establishing and resourcing public policies\
    \ that assure the survival and well-being of workers, displaced by A/IS and automation,\
    \ who cannot be retrained.\n\u2022\_\_\_\_\_Researching complementary areas, to\
    \ lay solid foundations for the transformation outlined above.\n\u2022\_\_\_\_\
    \_Requiring more policy research on the dynamics of professional transitions in\
    \ different labor market conditions.\n\u2022\_\_\_\_\_Researching the fairest\
    \ and most efficient public-private options for financing labor force transformation\
    \ due to A/IS.\n\u2022\_\_\_\_\_Developing national and regional future of work\
    \ strategies based on sound research and strategic foresight.\n## Further Resources\n\
    \u2022\_\_\_\_\_V. Cerf and D. Norfors, The People-centered Economy: The New Ecosystem\
    \ for Work. California: IIIJ Foundation, 2018.\n\u2022\_\_\_\_\_Executive Office\
    \ of the President. _Artificial Intelligence, Automation, and the Economy._ December\
    \ 20, 2016.\n\u2022\_\_\_\_\_S. Kilcarr, \u201CDefining the American Dream for\
    \ Trucking ... and the Nation, Too,\u201D _FleetOwner_, April 26, 2016.\n\u2022\
    \_\_\_\_\_M. Mason, \u201CMillions of Californians\u2019 Jobs could be Affected\
    \ by Automation\u2014a Scenario the next Governor has to Address,\u201D_Los Angeles\
    \ Times_, October 14, 2018.\n\u2022\_\_\_\_\_OECD, \u201CLabor Market Programs:\
    \ Expenditure and Participants,\u201D _OECD Employment and Labor Market Statistics\
    \ _(database), 2016.\n\u2022\_\_\_\_\_M. Vivarelli, \u201CInnovation and Employment:\
    \ ASurvey,\u201D Institute for the Study of Labor (IZA) Discussion Paper No. 2621,\
    \ February 2007.\n\"\np.147-149\n\n\"**Issue: **Analysis of the\_A/IS impact on\
    \ employment is too focused on the number and category of jobs affected, whereas\
    \ more attention should be addressed to the complexities of changing the task\
    \ content\_of jobs.\n## Background\nCurrent attention on automation and employment\
    \ tends to focus on the sheer number of jobs lost or gained. It is important to\
    \ focus the analysis on how employment structures will be changed by A/IS, rather\
    \ than solely dwelling on the number of jobs that might be impacted. For example,\
    \ rather than carrying out a task themselves, workers will need to shift to supervision\
    \ of robots performing that task. Other concerns include changes in traditional\
    \ employment structures, with an increase in flexible, contract-based temporary\
    \ jobs, without employee protection, and a shift in task composition away from\
    \ routine/repetitive and toward complex decision-making. This is in addition to\
    \ the enormous need for the aforementioned retraining. Given the extent of disruption,\
    \ workforce trends will need to measure time spent unemployed or underemployed,\
    \ labor force participation rates, and other factors beyond simple unemployment\
    \ numbers.\nThe _Future of Jobs 2018 _report of the World Economic Forum highlights:\_\
    \n\u201C...the potential of new technologies to create as well as disrupt jobs\
    \ and to improve the quality and productivity of the existing work of human employees.\
    \ Our findings indicate that, by 2022, _augmentation _of existing jobs through\
    \ technology may free up workers from the majority of data processing and information\
    \ search tasks\u2014and may also increasingly support them in high-value tasks\
    \ such as reasoning and decision-making as augmentation becomes increasingly common\
    \ over the coming years as a way to supplement and complement human labour.\n\
    The report predicts the shift in skill demand between today and 2022 will be significant\
    \ and that \u201Cproactive, strategic and targeted efforts will be needed to map\
    \ and incentivize workforce redeployment\u2026 [and therefore]... investment decisions\
    \ [on] whether to prioritize automation or augmentation and the question of whether\
    \ or not to invest in workforce reskilling.\n## Recommendations\nWhile there is\
    \ evidence that robots and automation are taking jobs away in various sectors,\
    \ a more balanced, granular, analytical, and objective treatment of A/IS impact\
    \ on the workforce is needed to effectively inform policy making and essential\
    \ workforce reskilling. Specifics to accomplish this include:\n\u2022\_\_\_\_\_\
    Creating an international and independent agency able to properly disseminate\
    \ objective statistics and inform the media, as well as the general public, about\
    \ the impact of robotics and A/IS on jobs, tax revenue, growth,26 and well-being.\n\
    \u2022\_\_\_\_\_Analyzing and disseminating data on how current task content of\
    \ jobs have changed, based on a clear assessment of the automatability of the\
    \ occupational\_description of such jobs.\n\u2022\_\_\_\_\_Promoting automation\
    \ with augmentation, as recommended in the _Future of Jobs Report 2018_ (see chart\
    \ on page 154), to maximize the benefit of A/IS to employment and meaningful work.\n\
    \u2022\_\_\_\_\_Integrating more granulated dynamic mapping of the future jobs,\
    \ tasks, activities, workplace-structures, associated work-habits, and skills\
    \ base spurred by the A/IS revolution, in order to innovate, align, and synchronize\
    \ skill development and training programs with future requirements. This workforce\
    \ mapping is needed at the macro, but also crucially at the micro, levels where\
    \ labor market programs\_are deployed.\n\u2022\_\_\_\_\_Considering both product\
    \ and process innovation, and looking at them from a global perspective in order\
    \ to understand properly the global impact of A/IS on employment.\n\u2022\_\_\_\
    \_\_Proposing mechanisms for redistribution of productivity increases and developing\
    \ an adaptation plan for the evolving labor market.\n## Further Resources\n\u2022\
    \_\_\_\_\_E. Brynjolfsson and A. McAfee. The Second Age of Machine Intelligence:\
    \ Work Progress and Prosperity in a Time of Brilliant Technologies. New York,\
    \ NY: W. W. Norton & Company, 2014.\n\u2022\_\_\_\_\_P.R. Daugherty, and H.J.\
    \ Wilson, Human + Machine: Reimagining Work in the Age of AI_. _Watertown, MA:_\
    \ _Harvard Business Review Press, 2018.\n\u2022\_\_\_\_\_International Federation\
    \ of Robotics. \u201CThe Impact of Robots on Productivity, Employment and Jobs,\u201D\
    \ A positioning paper by the International Federation of Robotics, April 2017.\n\
    \u2022\_\_\_\_\_RockEU. \u201CRobotics Coordination Action for Europe Report on\
    \ Robotics and Employment,\u201D Deliverable D3.4.1, June 30, 2016.\n\u2022\_\_\
    \_\_\_World Economic Forum, Centre for the New Economy and Society, _The Future\
    \ of Jobs 2018_, Geneva: WEF 2018.\"\n150-152\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recg2u6ZXSRiUO8uF
  airtable_createdTime: '2023-06-05T11:48:28.000Z'
  airtable_id: recb50cfuQUWDAHZW
  title: AI poses threats to labour
- Cases:
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recDAvfsflBF0WKpf
  ChallengeInstances:
  - rec7aGSPdkdUuZ42O
  - reczbN2QKYqG695ec
  - recHUlZ9OQfNwD6fg
  - recJvXzs5QMTqWzUF
  - recftbldoHqhBBcrk
  Description: "**Respect for diversity, non-discrimination, and fairness** respect\
    \ for persons includes respect for difference, non-discrimination, and fairness\
    \ in treatment of persons with particular protection for vulnerable populations.\
    \ This concern is particularly salient in the context of AI because models built\
    \ on historic data may reflect existing societal biases in a way that makes them\
    \ opaque or unaccountable. Systems should thus provide for stakeholder participation\
    \ and use regardless of their characteristics.\nNew technologies including AI\
    \ have potential for bias at multiple phases of a project (problem identification,\
    \ training data, modeling, implementation), and in multiple ways including through\
    \ use of data that reflects existing societal biases. While reinforcing existing\
    \ biases based on historic data is typically focal, the potential to create new\
    \ forms of bias should also be clear \n\u201CBecause they gain their insights\
    \ from the existing structures and dynamics of the societies they analyse, datadriven\
    \ technologies can reproduce, reinforce, and amplify the patterns of marginalisation,\
    \ inequality, and discrimination that exist in these societies. Likewise, because\
    \ many of the features, metrics, and analytic structures of the models that enable\
    \ data mining are chosen by their designers, these technologies can potentially\
    \ replicate their designers\u2019 preconceptions and biases. Finally, the data\
    \ samples used to train and test algorithmic systems can often be insufficiently\
    \ representative of the populations from which they are drawing inferences. This\
    \ creates real possibilities of biased and discriminatory outcomes, because the\
    \ data being fed into the systems is flawed from the start.\u201D (Leslie, 2019,\
    \ p. 4)\n\n### IEEE report\n\"**Issue 2: **A/IS can have biases that disadvantage\
    \ specific groups\n## Background\nEven when reflecting the full system of community\
    \ norms that was identified, A/IS may show operation biases that disadvantage\
    \ specific groups in the community or instill biases in users by reinforcing group\
    \ stereotypes. A system\u2019s bias can emerge in perception. For example, a passport\
    \ application AI rejected an Asian man\u2019s photo because it insisted his eyes\
    \ were closed (Griffiths 201651). Bias can emerge in information processing. For\
    \ instance, speech recognition systems are notoriously less accurate for female\
    \ speakers than for male speakers (Tatman 201652). System bias can affect decisions,\
    \ such as a criminal risk assessment device which overpredicts recidivism by African\
    \ Americans (Angwin et al. 201653). The system\u2019s bias can present itself\
    \ even in its own appearance and presentation: the vast majority of humanoid robots\
    \ have white \u201Cskin\u201D color and use female voices (Riek and Howard 201454).\n\
    The norm identification process detailed in Section 1 is intended to minimize\
    \ individual designers\u2019 biases because the community norms are assessed empirically.\
    \ The identification process also seeks to incorporate norms against prejudice\
    \ and discrimination. However, biases may still emerge from imperfections in the\
    \ norm identification process itself, from unrepresentative training sets for\
    \ machine learning systems, and from programmers\u2019 and designers\u2019 unconscious\
    \ assumptions. Therefore, unanticipated or undetected biases should be further\
    \ reduced by including members of diverse social groups in both the planning and\
    \ evaluation of A/IS and integrating community outreach into the evaluation process,\
    \ e.g., [DO-IT ](http://www.washington.edu/doit/)program and [RRI](http://www.orbit-rri.org/)\
    \ framework. Behavioral scientists and members of the target populations will\
    \ be particularly valuable when devising criterion tasks for system evaluation\
    \ and assessing the success of evaluating the A/IS performance on those tasks.\
    \ Such tasks would assess, for example, whether the A/IS apply norms in discriminatory\
    \ ways to different races, ethnicities, genders, ages, body shapes, or to people\
    \ who use wheelchairs\_or prosthetics, and so on.\"\np.184, IEEE, 2019\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recmzjcGKv3yNOxbl
  Principles:
  - reczVPIH1y2OMpAJH
  - rec42P8U9usfYCtv9
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  - 'Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A
    guide for the responsible design and implementation of AI systems in the public
    sector. The Alan Turing Institute. https://doi.org/10.5281/ZENODO.3240529'
  Sources:
  - recpXl48pJdKDhc6f
  - recfYC5jjPmpLfSlM
  Tags:
  - AI
  airtable_createdTime: '2023-05-18T13:41:32.000Z'
  airtable_id: recefglLZ3oJWw2SZ
  title: Respect for diversity, non-discrimination, and fairness
- Description: "Human rights law is related to, but distinct from, the pursuit of\
    \ well-being. Incorporating a human-rights framework as an essential basis for\
    \ A/IS creators means A/IS creators honor existing law as part of their well-being\
    \ analysis and implementation.\n## Background\nInternational human rights law\
    \ has been firmly established for decades in order to protect various guarantees\
    \ and freedoms as enshrined in charters such as the United Nations\u2019[ Universal\
    \ Declaration of Human Rights ](http://www.un.org/en/universal-declaration-human-rights/)and\
    \ the Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention).\
    \ In 2018, the[ Toronto Declaration ](https://www.accessnow.org/the-toronto-declaration-protecting-the-rights-to-equality-and-non-discrimination-in-machine-learning-systems/)on\
    \ machine learning standards was released, calling on both governments and technology\
    \ companies to ensure that algorithms respect basic principles of equality and\
    \ non-discrimination. The Toronto Declaration sets forth an obligation to prevent\
    \ machine learning systems from discriminating, and in some cases violating, existing\
    \ human rights law.\nWell-being initiatives are typically undertaken for the sake\
    \ of public interest. However, any metric, including well-being metrics, can be\
    \ misused to justify human rights violations. Encampment and mistreatment of refugees\
    \ and ethnic cleansing undertaken to preserve a nation\u2019s culture (an aspect\
    \ of well-being) is one example. Imprisonment or assassination of journalists\
    \ or researchers to ensure the stability of a government is another. The use of\
    \ wellbeing metrics to justify human rights violations is an unconscionable perversion\
    \ of the nature of any well-being metric. It should be noted that these same practices\
    \ happen today in relation to GDP. For instance, in 2012, according to the [International\
    \ Labour Organization (](http://www.ilo.org/global/about-the-ilo/newsroom/news/WCMS_181961/lang--en/index.htm)ILO),\
    \ approximately 21 million people are victims of forced labor (slavery), representing\
    \ 9% to 56% of GDP income for various countries. These clear human rights violations,\
    \ from sex trafficking and use of children in armies, to indentured farming or\
    \ manufacturing labor, can increase a country\u2019s GDP while obviously harming\
    \ human well-being.\n## Recommendations\nWell-being metrics are designed to measure\
    \ the efficacy of efforts related to individual and societal flourishing. Well-being\
    \ as a value complements justice, equality, and freedom. Well-designed application\
    \ of well-being considerations by A/IS creators should not displace other issues\
    \ of human rights or ethical methodologies, but rather complement them.\nA human\
    \ rights framework should represent the floor, and not the ceiling, for the standards\
    \ to which A/IS creators must adhere. Developers and users of well-being metrics\
    \ should be aware these metrics will not always adequately address human rights.\n\
    ## Further Resources\n\u2022\_\_\_\_\_United Nations[ Universal Declaration of\
    \ Human Rights,](http://www.un.org/en/universal-declaration-human-rights/) 1948.\n\
    \u2022\_\_\_\_\_Council of Europe\u2019s [Convention on Human Rights](https://www.coe.int/en/web/human-rights-convention),\
    \ 2018.\n\u2022\_\_\_\_\_International Labor Organization (ILO) [Declaration on\
    \ Fundamental Principles and Rights at Work,](https://www.ilo.org/declaration/lang--en/index.htm)\
    \ 1998.\n\u2022\_\_\_\_\_The regularly updated [University of Minnesota Human\
    \ Rights Library ](http://hrlibrary.umn.edu/)provides a wealth of material on\
    \ human rights laws, its history, and the organizations engaged in promoting them.\n\
    The [Oxford Human Rights Hub ](http://ohrh.law.ox.ac.uk/why-artificial-intelligence-is-already-a-human-rights-issue/)reports\
    \ on how and why technologies surrounding artificial intelligence raise human\
    \ rights issues\"\np.76-77\n"
  OverarchingPrinciples:
  - recLHILkx2JDFsLbX
  - recOHnq45Fq7YWsRO
  Principles:
  - receFm7cGasHwpJZO
  - recQ9DIFEsOEkCx3O
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recZI7HDWKBU5T22v
  Tags:
  - wellbeing
  airtable_createdTime: '2023-06-05T05:47:17.000Z'
  airtable_id: reciNc7OeTUmnsLqg
  title: How do we incorporate a human-rights framework into AI design/development/use?
- Description: "**\"Issue: **Current roadmaps for development and deployment of A/IS\
    \ are not aligned with or guided by their impact in the most important challenges\
    \ of humanity, defined in the seventeen United Nations Sustainable Development\
    \ Goals (SDGs), which collectively aspire to create a more equal world of prosperity,\
    \ peace, planet protection, and human dignity\_for all people.4\n## Background\n\
    \ SDGs promoting prosperity, peace, planet protection, human dignity, and respect\
    \ for human rights of all, apply to HIC and LMIC alike. Yet ensuring that the\
    \ benefits of A/IS will accrue to humanity as a whole, leaving \u201Cno one behind\u201D\
    , requires an ethical commitment to global citizenship and well-being, and a conscious\
    \ effort to counter the nature of the tech economy, with its tendency to concentrate\
    \ wealth within high income populations. Implementation of the SDGs should benefit\
    \ excluded sectors of society in every country, regardless of A/IS infrastructure.\u201C\
    The Road to Dignity by 2030\u201D document of the UN Secretary General reports\
    \ on resources and methods for implementing the 2030 Agenda for Sustainable Development\
    \ and emphasizes the importance of science, technology, and innovation for a sustainable\
    \ future.5 The UN Secretary General posits that:\n\u201CA sustainable future will\
    \ require that we act now to phase out unsustainable technologies and to invest\
    \ in innovation and in the development of clean and sound technologies for sustainable\
    \ development. We must ensure that they are fairly priced, broadly disseminated\
    \ and fairly absorbed, including to and by developing countries.\u201D (para.\
    \ 120)\nA/IS are among the technologies that can play an important role in the\
    \ solution of the deep social problems plaguing our global civilization, contributing\
    \ to the transformation of society away from an unsustainable, unequal socioeconomic\
    \ system, towards one that realizes the vision of universal human dignity, peace,\
    \ and prosperity.\nHowever, with all the potential benefits of\_A/IS, there are\
    \ also risks. For example, given\_A/IS technology\u2019s immense power needs,\
    \ without new sources of sustainable energy harnessed to power A/IS in the future,\
    \ there is a risk that it will increase fossil fuel use and have a negative impact\
    \ on the environment and the climate.\nWhile 45% of the world\u2019s population\
    \ is not connected to the internet, they are not necessarily excluded from A/IS\u2019\
    \ potential benefits: in LMIC mobile networks can provide data for A/IS applications.\
    \ However, only those connected are likely to benefit from the income-producing\
    \ potential of internet technologies. In 2017, internet penetration in HIC left\
    \ behind certain portions of the population often in rural or remote areas; 12%\
    \ of U.S. residents and 20% of residents across Europe were unable to access the\
    \ internet. In Asia with its concentration of LMIC, 52% of the population, on\
    \ average, had no access, a statistic skewed by the large population of China,\
    \ where internet penetration reached 45% of the population. In numerous other\
    \ countries in the region, 99% of residents had no access. This nearly total exclusion\
    \ also exists in several countries in Africa, where the overall internet penetration\
    \ is only 35%: 2 of every 3 residents in Africa have no access.6 Those with no\
    \ internet access also do not generate data needed to \u201Ctrain\u201D A/IS,\
    \ and are thereby excluded from benefits of the technology, the development of\
    \ which risks systematic discriminatory bias, particularly against people from\
    \ minority populations, and those living in rural areas, or in low-income countries.\
    \ As a comparison, one study estimated that \u201Cin the US, just one home automation\
    \ product can generate a data point every six seconds.\u201D7 In Mozambique, where\
    \ about 90% of the population lack internet access, \u201Cthe average household\
    \ generates zero digital data points.\u201D8 With mobile phones generating much\
    \ of the data needed for developing A/IS applications in LMIC, unequal phone ownership\
    \ may build in bias. For example, there is a risk of discrimination against women,\
    \ who across LMIC are 14% less likely than men to own a mobile phone, and in South\
    \ Asia where 38% are less likely to own a mobile phone.9\n## Recommendations\n\
    The current range of A/IS applications in sectors crucial to the SDGs, and to\
    \ excluded populations everywhere, should be studied, with the strengths, weaknesses,\
    \ and potential of the most significant recent applications analyzed, and the\
    \ best ones developed at scale. Specific objectives to consider include:\n\u2022\
    \_\_\_\_\_Identifying and experimenting with\_A/IS technologies relevant to the\
    \ SDGs,\_such as: big data for development relevant to, for example, agriculture\
    \ and medical tele-diagnosis; geographic information systems needed in public\
    \ service planning, disaster prevention, emergency planning, and disease monitoring;\
    \ control systems used in, for example, naturalizing intelligent cities through\
    \ energy and traffic control and management of urban agriculture; applications\
    \ that promote human empathy focused on diminishing violence and exclusion and\
    \ increasing well-being.\n\u2022\_\_\_\_\_Promoting the potential role of A/IS\
    \ in sustainable development by collaboration between national and international\
    \ government agencies and non-governmental organizations (NGOs) in technology\
    \ sectors.\n\u2022\_\_\_\_\_Analyzing the cost of and proposing strategies for\
    \ publicly providing internet access for\_all, as a means of diminishing the gap\
    \ in\_A/IS\u2019 potential benefit to humanity, particularly between urban and\
    \ rural populations in HIC and LMIC alike.\n\u2022\_\_\_\_\_Investing in the documentation\
    \ and dissemination of innovative applications of\_A/IS that advance the resolution\
    \ of identified societal issues and the SDGs.\n\u2022\_\_\_\_\_Researching sustainable\
    \ energy to power A/IS computational capacity.\n\u2022\_\_\_\_\_Investing in the\
    \ development of transparent monitoring frameworks to track the concrete results\
    \ of donations by international organizations, corporations, independent agencies,\
    \ and the State, to ensure efficiency and accountability in applied A/IS.\n\u2022\
    \_\_\_\_\_Developing national legal, policy, and fiscal measures to encourage\
    \ competition in the\_A/IS domestic markets and the flourishing\_of scalable A/IS\
    \ applications.\n\u2022\_\_\_\_\_Integrating the SDGs into the core of private\
    \ sector business strategies and adding SDG indicators to companies\u2019 key\
    \ performance indicators, going beyond corporate social responsibility (CSR).\n\
    \u2022\_\_\_\_\_Applying the well-being indicators10 to evaluate A/IS\u2019 impact\
    \ from multiple perspectives in HIC and LMIC alike.\n## Further reading\n\u2022\
    \_\_\_\_\_R. Van Est and J.B.A. Gerritsen, with assistance of L. Kool, Human Rights\
    \ in the Robot Age: Challenges arising from the use of Robots, Artificial Intelligence\
    \ and Augmented Reality Expert Report written for the Committee on Culture, Science,\
    \ Education and Media of the Parliamentary Assembly of the Council of Europe (PACE),\
    \ The Hague: Rathenau Instituut 2017.\n\u2022\_\_\_\_\_World Economic Forum Global\
    \ Future Council on Human Rights 2016-18, \u201CWhite Paper: How to Prevent Discriminatory\
    \ Outcomes in Machine Learning,\u201D World Economic Forum, March 2018.\n\u2022\
    \_\_\_\_\_United Nations General Assembly, _Transforming Our World: The 2030 Agenda\
    \ for Sustainable Development_ (A/RES/70/1: 21 October 2015) Preamble. [http://www.un.org/\
    \ en/development/desa/population/migration/ generalassembly/docs/globalcompact/\
    \ A\\_RES\\_70\\_1\\_E.pdf](http://www.un.org/en/development/desa/population/migration/generalassembly/docs/globalcompact/A_RES_70_1_E.pdf).\n\
    \u2022\_\_\_\_\_United Nations Global Pulse, Big Data for Development: Challenges\
    \ and Opportunities, 2012.\"\n\np139-140\n"
  Reference:
  - "IEEEE, Chatila, R., & Havens, J. C. (2019). The IEEE Global Initiative on Ethics\
    \ of Autonomous and Intelligent Systems. In M. I. Aldinhas Ferreira, J. Silva\
    \ Sequeira, G. Singh Virk, M. O. Tokhi, & E. E. Kadar (Eds.), Robotics and Well-Being\
    \ (Vol. 95, pp. 11\u201316). Springer International Publishing. https://doi.org/10.1007/978-3-030-12524-0_2"
  Sources:
  - recpXl48pJdKDhc6f
  Strategies:
  - recouZjokdKQz88z1
  Tags:
  - SDGs
  airtable_createdTime: '2023-06-05T10:57:55.000Z'
  airtable_id: recj64vAVJSm5B2ba
  title: AI could hamper, not foster, progress on SDGs
- Cases:
  - reciNqxyfUgE5XM7t
  - recrVkbG0XGe2Ca0v
  - recOOmVQviRyJGvea
  - recmS3zSMbR3ofAR5
  - recpFE7h6QhaEpNAQ
  ChallengeInstances:
  - recpxk9KZ2adMWrnD
  - recfzbgUna1vE1wtt
  - rec5facmXBZUPH3es
  - recd5xGVz6jr6WUqy
  - recKFOQ4CcT6PhQoe
  - recbsVGBRocMgkD2G
  - recISbGibFUeCXoRj
  - rec2OEPHyKNR33lW6
  Description: "**Inappropriate use **\"New technologies give rise to greater risk\
    \ of deliberate or accidental misuse, and this is especially true for A/IS. A/IS\
    \ increases the impact of risks such as hacking, misuse of personal data, system\
    \ manipulation, or exploitation of vulnerable users by unscrupulous parties. Cases\
    \ of A/IS hacking have already been widely reported, with driverless cars, for\
    \ example. The Microsoft Tay AI chatbot was famously manipulated when it mimicked\
    \ deliberately offensive users. In an age where these powerful tools are easily\
    \ available, there is a need for a new kind of education for citizens to be sensitized\
    \ to risks associated with the misuse of A/IS. The EU\u2019s General Data Protection\
    \ Regulation (GDPR) provides measures to remedy the misuse of personal data.Responsible\
    \ innovation requires A/IS creators to anticipate, reflect, and engage with users\
    \ of A/IS. Thus, citizens, lawyers, governments, etc., all have a role to play\
    \ through education and awareness in developing accountability structures (see\
    \ Principle 6), in addition to guiding new technology proactively toward beneficial\
    \ ends.\" [(IEEE, 2019, p.32-33)](https://ethics-guides.netlify.app/reccfsnzpjvw0pcue)\n"
  airtable_createdTime: '2023-06-18T18:56:46.000Z'
  airtable_id: recuUWIu0ofVYHLKA
  title: New technologies give rise to new potential for misuse
- OverarchingPrinciples:
  - recmzjcGKv3yNOxbl
  Principles:
  - rec42P8U9usfYCtv9
  airtable_createdTime: '2023-05-18T18:55:13.000Z'
  airtable_id: recv6cN7XSt5GW32Y
  title: Sustainability
- ChallengeInstances:
  - reclJ7hlCEf4P94SA
  - recPKPxKp07OlhULb
  - recMhXPovX6fJ5ZIa
  - recdkRK64g0b4GZlP
  Description: |
    While significant AI work is derived from publicly funded research, commercial actors have significant interests and this may impact relationships between funders-technology providers-researchers-public with blured lines between these groups, and complex power dynamics
  OverarchingPrinciples:
  - recOHnq45Fq7YWsRO
  Principles:
  - recOHnq45Fq7YWsRO
  Tags:
  - AI
  - education
  airtable_createdTime: '2023-06-14T12:19:37.000Z'
  airtable_id: recwuiKe3bhSLw4xv
  title: Commercial interests - while significant AI work is derived from publicly
    funded research, commercial actors have significant interests and this may impact
    relationships between funders-technology providers-researchers-public with blured
    lines between these groups, and complex power dynamics
